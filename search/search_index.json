{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"Revizor","text":""},{"location":"glossary/","title":"Glossary","text":"<p>This glossary defines key terms used throughout the Revizor documentation. The entries are ordered in such a way that more fundamental concepts appear first, building up to more complex ideas. So, you can should be able to get a good understanding of the terminology by reading the glossary top-down.</p>"},{"location":"glossary/#noninterference","title":"Noninterference","text":"A formal property that captures perfect confidentiality, stating that changes in secret data have no observable effect on public outputs. A program satisfies noninterference if variations in secret inputs cause no differences in public outputs. In Revizor's context, this property is checked with respect to side-channel observations and speculation contracts. <p>Related Documentation</p> <ul> <li>Primer: Information-Flow Properties</li> <li>Primer: Noninterference Definition</li> </ul>"},{"location":"glossary/#information-flow","title":"Information Flow","text":"The movement of data through a computation. Information-flow security is concerned with how data moves through a system and how it can be observed by an attacker. For example, if a program contains a data-dependent memory access <code>array[secret_index]</code>, the value of <code>secret_index</code> influences which memory location is accessed. In turn, if the attacker can observe the cache lines being accessed by this program, the execution of the array access will reveal (leak) information about <code>secret_index</code> through side channels. This creates an information flow from the secret data (<code>secret_index</code>) to the attacker's observations (cache state). <p>Related Documentation</p> <ul> <li>Primer: Information-Flow Properties</li> <li>Primer: Side Channels</li> </ul>"},{"location":"glossary/#speculation-contract-aka-leakage-contract","title":"Speculation Contract (aka Leakage Contract)","text":"A formalization of how we expect the CPU to behave and what information we expect it to leak when any given program is executed. A simplified and deterministic model of CPU hardware designed to capture the information that a given program could leak over side channels when executed with given inputs. A speculation contract defines two key aspects for every instruction: an observation clause (describing what data is exposed) and an execution clause (describing how hardware optimizations like speculative execution affect the instruction). Speculation contracts intentionally overestimate possible leaks to ensure conservative and deterministic traces. <p>Related Documentation</p> <ul> <li>Topic: Contracts</li> <li>Primer: Speculation Contracts</li> <li>How-to: Choose a Contract</li> </ul>"},{"location":"glossary/#observation-clause","title":"Observation Clause","text":"Part of a speculation contract that specifies what information an instruction exposes through side channels when executed. For example, an observation clause might specify that a load instruction exposes the memory address it accesses. <p>Related Documentation</p> <ul> <li>Topic: Contracts - Contract Structure</li> <li>Primer: Speculation Contracts</li> </ul>"},{"location":"glossary/#execution-clause","title":"Execution Clause","text":"Part of a speculation contract that specifies how hardware optimizations (particularly speculative execution) affect an instruction's semantics. For example, an execution clause might specify that a conditional branch may mispredict its target and execute down the wrong path. <p>Related Documentation</p> <ul> <li>Topic: Contracts - Contract Structure</li> <li>Primer: Speculation Contracts</li> </ul>"},{"location":"glossary/#leakage-model","title":"Leakage Model","text":"An implementation of a speculation contract. This model is used to compare the actual CPU behavior against the specification defined by the contract. It predicts what information flow is allowed through side channels for any given test case. <p>Related Documentation</p> <ul> <li>Topic: Leakage Models</li> <li>Internals: Model Architecture</li> <li>Internals: Unicorn Backend</li> <li>Internals: DynamoRIO Backend</li> </ul>"},{"location":"glossary/#contract-trace-ctrace","title":"Contract Trace (CTrace)","text":"The output of a leakage model. A CTrace is a recording of all exposed information when a given program is executed on the leakage model (e.g., a sequence of memory addresses accessed). This trace represents the expected information flow according to the contract. <p>Related Documentation</p> <ul> <li>Topic: Contracts - Contract Traces</li> <li>Topic: Leakage Models - Trace Representation</li> <li>Topic: Trace Analysis</li> </ul>"},{"location":"glossary/#executor","title":"Executor","text":"The component responsible for running programs on real hardware and collecting attacker-observable microarchitectural changes. This component acts as the counterpart to the leakage model; that is, while the model represents our expectations of the CPU behavior, the executor captures the actual behavior of the CPU under test. <p>Related Documentation</p> <ul> <li>Internals: Executor Architecture</li> <li>Reference: Configuration Options</li> </ul>"},{"location":"glossary/#hardware-trace-htrace","title":"Hardware Trace (HTrace)","text":"The output of the executor. An HTrace is a recording of microarchitectural state changes (like cache evictions, readings of the time stamp counter, etc.) observed during a program execution. These traces are used to capture the information flows on the CPU under test, both the expected and unexpected ones. <p>Related Documentation</p> <ul> <li>Topic: Trace Analysis</li> <li>Internals: Executor Architecture</li> </ul>"},{"location":"glossary/#test-case-program","title":"Test Case Program","text":"A small assembly program, either generated automatically by Revizor or written manually by the user. Test case programs are intended to be executed on the target CPU to collect hardware traces, and on the leakage model to collect contract traces. <p>Related Documentation</p> <ul> <li>Topic: Test Case Generation</li> <li>Internals: Code Generator Architecture</li> <li>Reference: Binary Formats - RCBF</li> </ul>"},{"location":"glossary/#test-case-data-aka-test-case-input","title":"Test Case Data (aka Test Case Input)","text":"A blob of data used to initialize memory and registers for the execution of a test case program. Test case data can be generated automatically by Revizor or provided manually by the user. <p>Related Documentation</p> <ul> <li>Topic: Test Case Generation</li> <li>Internals: Data Generator Architecture</li> <li>Reference: Binary Formats - RDBF</li> </ul>"},{"location":"glossary/#sandbox-or-test-case-sandbox","title":"Sandbox (or Test Case Sandbox)","text":"An isolated execution environment where test case programs are run on the target CPU and on the model. On the technical level, a sandbox constitutes of a dedicated region of memory where the test case program and data are loaded, as well as a set of mechanisms to isolate the test case execution from the rest of the system (e.g., by disabling interrupts, overriding MSRs, etc.). <p>Related Documentation</p> <ul> <li>Reference: Sandbox</li> <li>Reference: Registers</li> </ul>"},{"location":"glossary/#model-based-relational-testing-mrt","title":"Model-based Relational Testing (MRT)","text":"The core methodology of Revizor. It involves randomly generating test programs and inputs to them, executing them with the executor and the model, collecting the corresponding hardware and contract traces, identifying the information flows in both, and comparing them to find unexpected leaks. <p>Related Documentation</p> <ul> <li>Primer: Model-Based Relational Testing</li> <li>Topic: Trace Analysis</li> <li>Internals: Fuzzer Architecture</li> </ul>"},{"location":"glossary/#violation","title":"Violation","text":"A situation where hardware traces expose some information that is not exposed in the contract traces for the same test case. This indicates that the CPU is leaking some information not specified by the contract, which may represent a security vulnerability. <p>Related Documentation</p> <ul> <li>Topic: Trace Analysis</li> <li>Primer: Contract Violation</li> <li>How-to: Root-Cause a Violation</li> </ul>"},{"location":"glossary/#violation-artifact-aka-contract-counterexample","title":"Violation Artifact (aka Contract Counterexample)","text":"A bundle consisting of a test case program, two inputs that trigger the violation (plus extra inputs to set the uarch state, if needed), the corresponding hardware and contract traces, and a collection of configuration files to reproduce the violation. Violation artifacts are generated automatically by Revizor when a violation is detected. <p>Related Documentation</p> <ul> <li>Reference: Binary Formats</li> <li>How-to: Root-Cause a Violation</li> <li>How-to: Minimize Test Cases</li> </ul>"},{"location":"glossary/#minimization","title":"Minimization","text":"A post-processing mode that takes a violation artifact and performs transformation passes to simplify the program and data while preserving the violation. The goal is to produce a minimal artifact that is easier to understand and analyze, using program passes (instruction removal/simplification), input passes (sequence/diff minimization), and analysis passes (source analysis). <p>Related Documentation</p> <ul> <li>How-to: Minimize Test Cases</li> <li>Reference: Minimization Passes</li> <li>Internals: Minimization Architecture</li> </ul>"},{"location":"glossary/#multi-stage-filtering","title":"Multi-stage Filtering","text":"A pipeline of validation stages applied to potential violations to rule out false positives. A violation must survive all stages to be reported. <p>Related Documentation</p> <ul> <li>Internals: Fuzzer Architecture</li> <li>Reference: Configuration Options</li> </ul>"},{"location":"glossary/#priming-test","title":"Priming Test","text":"One of the most important validation stages. It is motivated by the following problem: when hardware traces are collected for a sequence of many inputs, the execution of the program with earlier inputs will affect the microarchitectural state for later inputs (e.g., the branch predictor state). This can lead to false positives, where two inputs that should be indistinguishable according to the contract produce different hardware traces simply because they were executed in different microarchitectural states (e.g., one input triggered a misprediction while the other did not). These case don't actually represent a violation because the difference in traces is not caused by the data difference, but rather by the sequence of executions. <p>The priming test mitigates this problem by re-executing the violating inputs in a different sequence, by swapping the order of inputs that trigger a violation. If the violation disappears when the order is swapped, it indicates that the difference in traces was due to inconsistent microarchitectural state rather than a true violation. Otherwise, we have evidence that the violation is genuine.</p> <p>Related Documentation</p> <ul> <li>Reference: Configuration Options - enable_priming</li> <li>Internals: Fuzzer Architecture</li> </ul>"},{"location":"glossary/#contract-compliance","title":"Contract Compliance","text":"A CPU complies with a speculation contract if, for all possible programs and input pairs that produce identical contract traces, the corresponding hardware traces are also identical. This ensures that the contract captures all information that the hardware can leak. While testing all possible programs is infeasible, Revizor approximates this by randomly sampling the search space with a large number of test cases. <p>Related Documentation</p> <ul> <li>Topic: Trace Analysis - Contract Compliance Property</li> <li>Topic: Contracts - Contract Compliance</li> <li>Primer: Contract Compliance</li> </ul>"},{"location":"glossary/#contract-equivalence-class-contracteqclass","title":"Contract Equivalence Class (ContractEqClass)","text":"A group of inputs that produce identical contract traces for a given test case program. According to the leakage model, these inputs should be indistinguishable when executed. <p>Related Documentation</p> <ul> <li>Topic: Trace Analysis - Deterministic Trace Comparison</li> <li>Internals: Analyser Architecture</li> </ul>"},{"location":"glossary/#hardware-equivalence-class-hardwareeqclass","title":"Hardware Equivalence Class (HardwareEqClass)","text":"A group of inputs that produce statistically similar hardware traces for a given test case program. These inputs are actually indistinguishable on real hardware. <p>Related Documentation</p> <ul> <li>Topic: Trace Analysis - Statistical Trace Comparison</li> <li>Internals: Analyser Architecture</li> </ul>"},{"location":"glossary/#boosting-aka-contract-driven-input-generation","title":"Boosting (aka Contract-driven Input Generation)","text":"A data generation optimization technique that uses taint analysis to generate inputs more likely to trigger contract violations. The boosted generator identifies which input bytes affect the contract trace and generates new inputs by mutating the non-tainted bytes. This way, we can deterministically and efficiently create any number of inputs that produce the same contract trace (i.e., form one ContractEqClass), increasing the chances of finding violations. <p>Related Documentation</p> <ul> <li>Internals: Data Generator Architecture</li> <li>Reference: Configuration Options</li> </ul>"},{"location":"glossary/#fuzzer","title":"Fuzzer","text":"The main orchestrator in Revizor that manages core components (CodeGenerator, DataGenerator, Model, Executor, and Analyser) and coordinates the fuzzing loop. When a potential violation is found, the Fuzzer runs it through a multi-stage filtering pipeline to eliminate false positives. <p>Related Documentation</p> <ul> <li>Internals: Fuzzer Architecture</li> <li>Reference: Configuration Options</li> </ul>"},{"location":"glossary/#analyser","title":"Analyser","text":"The component that compares contract traces with hardware traces to detect violations. It uses an equivalence class approach where it groups inputs by contract traces (ContractEqClasses) and then checks if they split into multiple hardware equivalence classes (HardwareEqClasses), which would indicate a violation. <p>Related Documentation</p> <ul> <li>Topic: Trace Analysis</li> <li>Internals: Analyser Architecture</li> <li>Reference: Configuration Options - analyser</li> </ul>"},{"location":"glossary/#actor","title":"Actor","text":"A partition of the sandbox representing a distinct execution context with specific isolation properties (e.g., a VM). An actor encompasses a code region, a data region with configurable permissions, and an execution context (CPU mode, privilege level, and system configuration). Actors enable testing for information leaks across different security domains. <p>Related Documentation</p> <ul> <li>Topic: Actors</li> <li>Reference: Sandbox</li> </ul>"},{"location":"glossary/#actor-non-interference","title":"Actor Non-Interference","text":"A specialized type mode of testing in Revizor, where, on top of testing for standard contract violations, the tool also checks that there are no information flows between different actors in a multi-actor test case. This mode is used to verify isolation properties between security domains, ensuring that secret data in one actor does not influence observable behavior in another actor. <p>Related Documentation</p> <ul> <li>Topic: Actors</li> </ul>"},{"location":"glossary/#observer-actor","title":"Observer Actor","text":"An actor marked as an observer in the configuration, representing an attacker that can observe data leaks in multi-actor testing scenarios. This is used in conjunction with the Actor Non-Interference mode to check that secret data in other actors does not influence the traces in the observer actor. <p>Related Documentation</p> <ul> <li>Topic: Actors</li> <li>Reference: Configuration Options</li> </ul>"},{"location":"glossary/#rcbf-revizor-code-binary-format","title":"RCBF (Revizor Code Binary Format)","text":"A custom binary format used to transfer test case programs between Revizor components. The format contains a header, actor table, symbol table, metadata, and code sections for each actor. <p>Related Documentation</p> <ul> <li>Reference: Binary Formats - RCBF</li> </ul>"},{"location":"glossary/#rdbf-revizor-data-binary-format","title":"RDBF (Revizor Data Binary Format)","text":"A custom binary format used to transfer input data between Revizor components. The format contains initialization data for sandbox memory and registers, and can combine multiple inputs into a single file for batch processing. <p>Related Documentation</p> <ul> <li>Reference: Binary Formats - RDBF</li> </ul>"},{"location":"glossary/#template","title":"Template","text":"An assembly file that combines regular assembly instructions with placeholders to define a test case structure for the code generator. Such templates are used in a special template mode of Revizor, where the programs are generated by populating the placeholders with random instructions instead of generating programs from scratch. <p>Related Documentation</p> <ul> <li>How-to: Use Templates</li> <li>Reference: Configuration Options</li> </ul>"},{"location":"glossary/#macro","title":"Macro","text":"A special pseudo-instruction in test case programs that can be treated differently depending on whether the test case is executed by the model or the executor. One prominent example is VM transition macros, which handle switching between actors. A special type of macro is also used to implement the placeholders in templates. <p>Related Documentation</p> <ul> <li>How-to: Use Macros</li> <li>Reference: Macro Reference</li> </ul>"},{"location":"structure/","title":"Revizor Documentation","text":"<p>Everything you need to know about using, understanding, and contributing to Revizor.</p>"},{"location":"structure/#first-steps","title":"First Steps","text":"<p>Are you new to Revizor? Start here:</p> <ul> <li>Revizor at a Glance: Understand what Revizor is, what problems it solves, and see a quick example of violation detection.</li> <li>Installation Guide: Get Revizor installed on your system and verify your setup.</li> <li>Your First Fuzzing Campaign: Follow a hands-on tutorial that walks you through running your first test, detecting a violation, and understanding the results.</li> <li>Core Concepts: Learn about contracts, traces, speculation, and other fundamental concepts needed to use Revizor effectively.</li> <li>Glossary: A quick reference for key terms used throughout the documentation.</li> </ul>"},{"location":"structure/#getting-help","title":"Getting Help","text":"<p>Stuck? Need clarification? Here's where to get help.</p> <ul> <li>FAQ - What is Revizor? How does it work? What's a contract?</li> <li>GitHub Discussions - Ask questions, share experiences, discuss ideas</li> <li>GitHub Issues - Report bugs or request features</li> <li>Contributing Guide - Help improve Revizor</li> <li>Zulip Chat - Real-time community support</li> </ul>"},{"location":"structure/#how-the-documentation-is-organized","title":"How the Documentation is Organized","text":"<p>Revizor's documentation is organized into five distinct categories based on your needs:</p>"},{"location":"structure/#learning-oriented-tutorials","title":"Learning-Oriented: Tutorials","text":"<p>Tutorials take you by the hand through a series of steps to complete a project. They are designed for newcomers who want to get started with Revizor. Start here if you're learning.</p> <ul> <li>Main Tutorial Series: Follow a series of hands-on tutorials that walk you through running your first tests, detecting violations, and rump up all the way to root-cause analysis and design of custom campaigns.</li> <li>How TSA-SQ Was Detected: A practical case study showing how Revizor was used to discover the TSA-SQ vulnerability. For those interested in how Revizor is used in the real world.</li> </ul>"},{"location":"structure/#task-oriented-how-to-guides","title":"Task-Oriented: How-To Guides","text":"<p>How-to guides are recipes that guide you through steps to solve specific problems. They assume you have basic knowledge and want to accomplish something particular.</p> <ul> <li>How to Choose a Contract - Select appropriate reference model</li> <li>How to Design a Fuzzing Campaign - Plan effective testing strategies</li> <li>How to Interpret Results - Understand what the outputs mean</li> <li>How to Minimize Violations - Reduce test cases to essentials</li> <li>How to Root-Cause a Violation - Analyze and understand detected leaks</li> <li>How to Use Macros - Leverage macros for customizing test cases</li> <li>How to Use Templates - Create structured test cases with templates</li> </ul>"},{"location":"structure/#understanding-oriented-topic-guides","title":"Understanding-Oriented: Topic Guides","text":"<p>Topic guides provide background and explanation to help you understand how Revizor works. They don't contain step-by-step instructions but explain key concepts in depth.</p> <ul> <li>Leakage Contracts - Understanding security specifications</li> <li>Actors and Isolation - Multi-domain testing concepts</li> <li>Leakage Models - How the model predicts CPU behavior</li> <li>Test Case Generation - Code and data generation explained</li> <li>Trace Analysis - How violations are detected</li> </ul>"},{"location":"structure/#information-oriented-reference","title":"Information-Oriented: Reference","text":"<p>Reference guides contain technical descriptions of Revizor's components. They're like a dictionary\u2014useful when you know what you're looking for.</p> <ul> <li>Command Line Interface - Complete CLI reference</li> <li>Configuration Options - All configuration parameters</li> <li>Execution Modes - Fuzz, reproduce, analyze, minimize</li> <li>Macros Reference - Template macro system</li> <li>Minimization Passes - Available minimization techniques</li> <li>Runtime Statistics - Runtime metrics printed during execution</li> <li>Binary Format - (advanced) Revizor's custom binary format</li> <li>Allocated Registers - (advanced) Register allocation details</li> <li>Sandbox - (advanced) Sandbox for executing test cases</li> </ul>"},{"location":"structure/#contributor-oriented-development-guides","title":"Contributor-Oriented: Development Guides","text":"<p>Development guides help contributors understand the codebase, architecture, and development practices.</p> <ul> <li>Developer Index</li> <li>Architecture Overview</li> <li>Code Style Guidelines</li> <li>Git Conventions</li> </ul>"},{"location":"structure/#research-and-background","title":"Research and Background","text":"<p>Revizor is built on peer-reviewed research in hardware security and formal methods:</p> <ol> <li>Original paper that introduced the concept of Model-based Relation Testing as well as the Revizor tool: \"Revizor: Testing Black-box CPUs against Speculation Contracts\"</li> <li>Theoretical foundations of leakage contract: \"Hardware-software contracts for secure speculation\"</li> <li>Accessible summary of the two papers above, in a journal format: \"Revizor: Testing Black-box CPUs against Speculation Contracts\". In IEEE Micro, 2023.</li> <li>Paper that introduced speculation filtering, observation filtering, and contract-based input generation: \"Hide and Seek with Spectres: Efficient discovery of speculative information leaks with random testing\"</li> <li>Paper that introduced exception-based testing (i.e., focus on Meltdown, Foreshadow) into Revizor: \"Speculation at Fault: Modeling and Testing Microarchitectural Leakage of CPU Exceptions.\"</li> <li>Paper that introduced testing of cross-VM and user-kernel leaks in Revizor, as well as presented TSA attacks on AMD CPUs: \"Enter, Exit, Page Fault, Leak: Testing Isolation Boundaries for Microarchitectural Leaks\"</li> </ol>"},{"location":"structure/#documentation-feedback","title":"Documentation Feedback","text":"<p>If you find errors, confusing explanations, or missing information in the documentation, please let us know:</p> <ul> <li>Open an issue with the \"documentation\" label</li> <li>Suggest improvements via pull request</li> <li>Discuss on GitHub Discussions</li> </ul>"},{"location":"faq/general/","title":"General FAQ","text":""},{"location":"faq/general/#overview","title":"Overview","text":""},{"location":"faq/general/#what-is-revizor","title":"What is Revizor?","text":"Revizor is a security-oriented fuzzer designed to detect microarchitectural information leaks in CPUs. It automatically generates random test programs, executes them on real hardware, and compares the observed behavior against a formal model to identify unexpected information leakage through side channels like those exploited by Spectre and Meltdown attacks."},{"location":"faq/general/#who-uses-revizor","title":"Who is Revizor for?","text":"Revizor is primarily designed for CPU security researchers and hardware vendors interested in identifying and mitigating microarchitectural vulnerabilities. It may also be useful for system developers and security professionals who want to assess the security of the hardware platforms they work with."},{"location":"faq/general/#how-does-revizor-differ-from-other-hardware-fuzzers","title":"How does Revizor differ from other hardware fuzzers (e.g., SiliFuzz)?","text":"Most of the existing hardware fuzzers focus on finding functional bugs, such as incorrect instruction execution or crashes. Revizor, on the other hand, is specifically designed to find security vulnerabilities related to microarchitectural side channels. It uses a model-based approach to define what information is allowed to leak and tests whether the CPU adheres to these specifications. See Revizor at a Glance for a more detailed introduction."},{"location":"faq/general/#how-does-revizor-differ-from-ct-testing-tools","title":"How is Revizor different from constant-time testing tools (e.g., Microwalk)?","text":"Constant-time testing tools like Microwalk focus on verifying that software implementations do not leak sensitive information through timing variations. They analyze the execution of programs to ensure that their timing behavior is independent of secret data. Revizor, in contrast, tests the CPU hardware itself for microarchitectural information leaks. It tests whether the CPU behaves as expected, regardless of the software running on it."},{"location":"faq/general/#supported-cpus","title":"What CPUs does Revizor support?","text":"Revizor currently supports testing on x86-64 CPUs from Intel and AMD, as well as ARM CPUs."},{"location":"faq/general/#leaks-described-in-contract","title":"Does Revizor detect only those leaks that are described in the contract?","text":"No! It is a common misconception that Revizor can only find leaks that are explicitly described in the contract. In reality, it is the opposite: The contract defines what the Revizor should not report as a leak, which allows the tool to filter out the known types of leakage and focus on finding unexpected leaks that violate the contract. This is how Revizor is able to discover new vulnerabilities even in completely black-box CPUs."},{"location":"faq/general/#running-revizor","title":"Running Revizor","text":""},{"location":"faq/general/#requires-root","title":"Does Revizor require root or administrator privileges?","text":"Yes. Revizor's executor is implemented as a kernel module that requires loading into the kernel and accessing hardware performance counters. Both operations require root privileges. Additionally, some system configuration steps recommended for optimal performance (like disabling hyperthreading) require administrative access."},{"location":"faq/general/#run-on-vms","title":"Can I run Revizor in a virtual machines?","text":"Unfortunately, not. Revizor requires direct access to the CPU's PMU to accurately measure side-channel leakage. Running Revizor inside a virtual machine would introduce additional layers of abstraction and interference that could distort the measurements and lead to inaccurate results. You need to run Revizor on a bare-metal installation of Linux."},{"location":"faq/general/#safety","title":"Can Revizor affect system stability?","text":"Although extremely unlikely, Revizor could potentially affect the host operating system. Revizor executes randomly-generated code in kernel space, which means that a misconfiguration or bug can crash the system and potentially lead to data loss. However, it does not intentionally perform any operations that would damage hardware. You should never run Revizor on production machines or systems containing important data without backups. Always use a dedicated testing machine."},{"location":"faq/general/#time-to-find","title":"How long does it take to find a vulnerability?","text":"This varies significantly, based on the complexity of the experiment. Typical numbers range from minutes to weeks."},{"location":"faq/general/#test-custom-programs","title":"Can Revizor test my own assembly programs or does it only generate random ones?","text":"Yes, Revizor can test custom assembly programs using the <code>-t</code> flag. You can provide your own test case program in assembly format, and Revizor will execute it with randomly-generated inputs to check for contract violations. This is useful when you want to verify specific code patterns or investigate potential vulnerabilities in particular instruction sequences. See the CLI Reference for details on the <code>-t</code> option."},{"location":"faq/general/#resource-requirements","title":"How much computational resources does a typical fuzzing campaign require?","text":"Resource requirements vary significantly based on the fuzzing configuration. A typical campaign runs continuously for hours to weeks. The primary variables affecting performance are the number of inputs per test case, sample sizes for hardware measurements, and the complexity of the ISA subset being tested. Larger sample sizes increase accuracy but reduce throughput. Most campaigns run on standard server or workstation hardware without specialized requirements beyond the supported CPU architecture. See How to Design a Fuzzing Campaign for guidance on balancing performance and detection effectiveness."},{"location":"faq/general/#violations","title":"Violations","text":""},{"location":"faq/general/#false-positives","title":"Are false positives common? How does Revizor handle them?","text":"No, unless it is misconfigured. Revizor uses a multi-stage filtering pipeline to eliminate false positives caused by noise and non-deterministic hardware behavior. This removes the vast majority of spurious violations. However, if Revizor is misconfigured (e.g., insufficient sample sizes), false positives can still occur due to noise in hardware measurements. These are relatively easy to identify as they tend to be unstable and non-reproducible. See How to Interpret Violation Results for guidance on evaluating violation quality and handling false positives."},{"location":"faq/general/#generate-exploits","title":"Can Revizor automatically generate exploits or proof-of-concept code?","text":"No. Revizor detects violations of the leakage contract by identifying test cases where hardware behavior differs from the contract's predictions. While it provides the test program and inputs that trigger the violation, it does not automatically generate working exploits. The violation artifacts serve as evidence of unexpected leakage and a starting point for manual security analysis. You can use the minimization feature to simplify the test case, making it easier to understand and potentially develop into a proof-of-concept. See How to Minimize Test Cases for details on simplifying violations."},{"location":"faq/general/#exploitability","title":"How do I know if a detected violation is actually exploitable?","text":"Determining exploitability requires manual analysis of the violation. Start by reproducing the violation to confirm it's stable, then use the minimization feature to simplify the test case. Next, analyze the minimized program to understand what information is leaking and through which side channel. Root-cause analysis involves examining the assembly code, understanding the data dependencies, and determining whether an attacker could control the leaked information to extract sensitive data. Not all violations are practically exploitable, but all indicate deviation from the specified security contract. See How to Root-Cause a Violation for systematic analysis techniques."},{"location":"faq/general/#reproducibility","title":"Is Revizor deterministic? Can I reproduce results?","text":"Contract traces are fully deterministic\u2014the same program with the same inputs always produces identical contract traces. Hardware traces, however, contain inherent non-determinism due to timing variations, cache state, and other microarchitectural effects. Revizor handles this through statistical analysis of multiple samples. Violations are reproducible when the same test program and inputs consistently show the same distributional differences in hardware traces. The violation artifact includes all necessary files (program, inputs, configuration) to reproduce detected violations, and Revizor provides a dedicated reproduce mode for verification. See Execution Modes for details on the reproduce mode."},{"location":"faq/general/#development-and-contribution","title":"Development and Contribution","text":""},{"location":"faq/general/#maintenance-status","title":"Is Revizor actively maintained?","text":"Yes. Revizor is actively maintained and continues to receive updates, bug fixes, and new features. The project has an active GitHub repository with recent commits and ongoing development."},{"location":"faq/general/#contributing","title":"Can I contribute to Revizor?","text":"Yes, we welcome contributions from the community! You can contribute by reporting issues, suggesting new features, improving documentation, or submitting code changes through pull requests. Please refer to our Contribution Guidelines for instructions on how to get started."},{"location":"howto/choose-contract/","title":"How to Choose a Contract","text":"<p>This guide helps you select the appropriate contract for your fuzzing campaign. The contract determines which microarchitectural leaks Revizor will report as violations, making it a critical configuration choice that affects both what you find and how efficiently you find it.</p> <p>Prerequisites</p> <p>Before choosing a contract, you should understand what contracts are and how they work. Read the Contracts topic guide if you need background on contract structure and purpose.</p>"},{"location":"howto/choose-contract/#standard-fuzzing-with-ct-seq","title":"Standard Fuzzing with CT-SEQ","text":"<p>Use CT-SEQ for most fuzzing campaigns. This contract assumes nothing about the target CPU except the presence of CPU caches, making it a zero-knowledge baseline for detecting unknown vulnerabilities. With CT-SEQ, Revizor reports any information leaks beyond the most trivial non-speculative cache accesses.</p> <p>Configure CT-SEQ by setting the observation clause to <code>ct</code> and the execution clause to <code>seq</code>:</p> <pre><code>contract_observation_clause: ct\ncontract_execution_clause:\n  - seq\n</code></pre> <p>CT-SEQ provides the strictest security guarantees and will detect the widest range of vulnerabilities. Start with this contract unless you have specific reasons to use a different one.</p>"},{"location":"howto/choose-contract/#continuing-after-finding-a-violation","title":"Continuing After Finding a Violation","text":"<p>When you find a violation with CT-SEQ and want to continue testing for additional vulnerabilities, you have two approaches.</p> <p>The simpler and more efficient approach is to blocklist the instruction that triggered the violation. Use the <code>instruction_blocklist_append</code> configuration option to exclude specific instructions from testing. For example, if a branch misprediction caused the violation, blocklist all conditional branch instructions:</p> <pre><code>contract_observation_clause: ct\ncontract_execution_clause:\n  - seq\ninstruction_blocklist_append:\n  - jne\n  - je\n  # add other branch instructions\n</code></pre> <p>This approach lets you continue using CT-SEQ's fast and efficient detection while avoiding repeated reports of the same root cause.</p> <p>Alternatively, you can incorporate the newly discovered speculation source into the contract by switching to a different execution clause. For violations caused by branch mispredictions, switch to the COND execution clause:</p> <pre><code>contract_observation_clause: ct\ncontract_execution_clause:\n  - cond\n</code></pre> <p>The CT-COND contract models speculative execution from branch mispredictions as expected behavior. Revizor will no longer report violations from this source, allowing you to search for other types of leaks in the same instruction set.</p>"},{"location":"howto/choose-contract/#testing-with-exceptions","title":"Testing with Exceptions","text":"<p>If your fuzzing campaign includes code that may raise exceptions such as page faults or general protection faults, these exceptions will likely cause trivial violations under CT-SEQ. Modern CPUs implement out-of-order execution, which means instructions after a faulting instruction may begin executing before the CPU recognizes the exception. These subsequent instructions can leak information not predicted by CT-SEQ's strictly sequential model.</p> <p>These violations typically represent known artifacts of out-of-order execution rather than genuine security issues. To suppress such trivial reports, use the CT-DEH contract instead. This contract models delayed exception handling, allowing instructions after a faulting instruction to execute transiently before the exception is handled:</p> <pre><code>contract_observation_clause: ct\ncontract_execution_clause:\n  - deh\n</code></pre> <p>CT-DEH remains strict about other speculation sources while accommodating the expected behavior around exceptions.</p>"},{"location":"howto/choose-contract/#testing-cross-domain-isolation","title":"Testing Cross-Domain Isolation","text":"<p>When testing isolation between security domains such as kernel versus user mode or host versus guest execution, use the Actor Non-Interference contract (CT-NI). This contract changes the security property being tested. Instead of only checking that inputs with identical contract traces produce equivalent hardware traces, CT-NI adds an additional requirement: the hardware traces observed by attacker actors must not depend on data from victim actors.</p> <p>Configure CT-NI with the following observation clause:</p> <pre><code>contract_observation_clause: ct-ni\n</code></pre> <p>You must also configure actors properly, designating which actors are observers (attackers) and which are victims. See Actors for details on actor configuration.</p>"},{"location":"howto/choose-contract/#investigating-known-vulnerabilities","title":"Investigating Known Vulnerabilities","text":"<p>When investigating variants of known vulnerabilities, use a contract that models the specific vulnerability class you are studying.</p> <p>For Spectre V1 variant analysis, use the COND execution clause to model branch mispredictions as expected behavior:</p> <pre><code>contract_observation_clause: ct\ncontract_execution_clause:\n  - cond\n</code></pre> <p>This configuration lets you explore whether other instructions or gadget patterns can be exploited through branch misprediction without being distracted by the original Spectre V1 finding.</p> <p>For other vulnerability classes, choose the execution clause that models the corresponding speculation mechanism. See the Configuration Reference for a list of available execution clauses and their intended use cases.</p>"},{"location":"howto/choose-contract/#whats-next","title":"What's Next?","text":"<ul> <li>Topic: Contracts - Understanding contract structure and behavior</li> <li>How-to: Design a Fuzzing Campaign - Complete campaign planning including contract selection</li> <li>Reference: Configuration Options - Complete list of contract and configuration parameters</li> <li>Glossary: Contract, Observation Clause, Execution Clause</li> </ul>"},{"location":"howto/design-campaign/","title":"How to Design a Fuzzing Campaign","text":"<p>This guide shows you how to design and configure a fuzzing campaign for detecting speculative execution vulnerabilities. A campaign consists of three components: a configuration file (YAML), command-line arguments, and optionally a template file (ASM).</p> <p>Prerequisites</p> <ul> <li>Revizor installed and the executor kernel module loaded</li> <li>Basic understanding of contracts and what you want to test</li> </ul>"},{"location":"howto/design-campaign/#select-instruction-set","title":"Select Instruction Set","text":"<p>Choose which instruction subset to test. Smaller subsets are more effective because violations are found faster and root-cause analysis is simpler. For comprehensive ISA coverage, split testing into multiple targeted campaigns rather than running a single large campaign.</p> <p>Specify instruction categories in your configuration file using <code>instruction_categories</code>:</p> <pre><code>instruction_categories:\n  - BASE-BINARY      # arithmetic instructions\n  - BASE-STRINGOP    # string operations\n  - BASE-LOGIC       # logical operations\n</code></pre> <p>Verify which instructions are included by enabling debug logging:</p> <pre><code>logging_modes: ['info', 'stat', 'dbg_generator']\n</code></pre> <p>For fine-grained control over the instruction set, see the Configuration Reference.</p>"},{"location":"howto/design-campaign/#configure-exception-testing","title":"Configure Exception Testing","text":"<p>Enable exception testing using the <code>generator_faults_allowlist</code> option:</p> <pre><code>generator_faults_allowlist:\n  - div-by-zero              # division by zero exceptions\n</code></pre> <p>Ensure the corresponding instructions are included in your instruction set. For example, <code>div-by-zero</code> requires division instructions in the tested pool.</p> <p>For testing Meltdown or Foreshadow-like vulnerabilities, configure memory access permissions through actor-specific <code>data_properties</code> and <code>data_ept_properties</code>:</p> <pre><code>actors:\n  - main:\n      data_properties:\n        present: false     # trigger page faults\n        writable: false    # trigger write protection faults\n</code></pre> <p>See the Sandbox Reference for details on memory permissions and the Configuration Reference for all exception handling options.</p>"},{"location":"howto/design-campaign/#configure-actors-for-multi-domain-testing","title":"Configure Actors for Multi-Domain Testing","text":"<p>For cross-domain leakage testing, define actors to represent different security domains:</p> <pre><code>actors:\n  - main:\n      mode: host\n      privilege_level: kernel\n  - guest:\n      mode: guest\n      privilege_level: kernel\n      observer: true\n</code></pre> <p>Create corresponding template files to specify transition sequences between actors. See Actors for detailed instructions.</p>"},{"location":"howto/design-campaign/#select-contract","title":"Select Contract","text":"<p>Choose a contract that defines what execution behavior constitutes a violation. Contract selection depends on whether you are testing cross-domain leakage and which known vulnerabilities you want to filter out.</p> <p>For detailed guidance on selecting the appropriate contract for your testing scenario, see How to Choose a Contract.</p> <p>Example configuration:</p> <pre><code>contract_observation_clause: ct\ncontract_execution_clause:\n  - seq\n</code></pre> <p>See the Configuration Reference for all available contract options.</p>"},{"location":"howto/design-campaign/#configure-noise-threshold","title":"Configure Noise Threshold","text":"<p>Adjust noise tolerance based on your system characteristics. Higher thresholds and larger sample sizes reduce false positives but may miss subtle leaks and decrease performance. Lower thresholds increase sensitivity but may produce false positives on noisy systems.</p> <p>For high-noise systems:</p> <pre><code>analyser_stat_threshold: 0.5      # conservative threshold\nexecutor_sample_sizes: [50, 100, 500, 1000]\n</code></pre> <p>For low-noise systems:</p> <pre><code>analyser_stat_threshold: 0.1      # sensitive threshold\nexecutor_sample_sizes: [10, 50, 100]\n</code></pre> <p>Start with low-noise settings and increase thresholds if you encounter non-reproducible violations. See the Trace Analysis Guide for more information on noise handling.</p>"},{"location":"howto/design-campaign/#enable-reproducibility","title":"Enable Reproducibility","text":"<p>Set deterministic seeds to make the campaign reproducible:</p> <pre><code>program_generator_seed: 12345     # deterministic program generation\ndata_generator_seed: 67890        # deterministic input generation\n</code></pre> <p>Reproducible campaigns are essential for debugging and comparing results across different runs.</p>"},{"location":"howto/design-campaign/#configure-test-case-shape","title":"Configure Test Case Shape","text":"<p>Control the structure of generated test cases:</p> <pre><code>program_size: 64                  # instructions per program\navg_mem_accesses: 32              # average memory accesses\nmin_bb_per_function: 1            # minimum basic blocks per function\nmax_bb_per_function: 2            # maximum basic blocks per function\nmin_successors_per_bb: 1          # minimum successors per basic block\nmax_successors_per_bb: 1          # maximum successors per basic block\n</code></pre> <p>Larger programs may find more complex interactions but require longer analysis time. Start with smaller programs and increase size if needed.</p>"},{"location":"howto/design-campaign/#use-templates-for-targeted-testing","title":"Use Templates for Targeted Testing","text":"<p>Use templates when targeting specific microarchitectural scenarios. Templates define fixed assembly structures with random instruction insertion, allowing you to focus on specific patterns while maintaining variability.</p> <p>Example template:</p> <pre><code>.section .data.main\n.function_main_0:\n    # Fixed initialization\n    mov rax, 0\n\n    # Random instruction sequence\n    .macro.random_instructions.32.0:\n\n    # Fixed measurement\n    .macro.measurement_start:\n    mov rbx, [r14]\n    .macro.measurement_end:\n\n.test_case_exit:\n</code></pre> <p>See How to Use Templates for detailed template syntax and the Macro Reference for available macros.</p>"},{"location":"howto/design-campaign/#complete-example","title":"Complete Example","text":"<p>This campaign tests whether division-by-zero exceptions cause unexpected information leakage on the target CPU. It focuses on simple arithmetic instructions to isolate exception handling behavior and answers the question: \"Does division by zero on this CPU leak information through microarchitectural side channels?\"</p> <p>The configuration assumes a CPU with relatively low non-determinism, using moderate sample sizes and a conservative statistical threshold. The campaign uses the DEH (Delay Exception Handling) contract to filter out trivial cases of out-of-order handling of the exception. Test cases are kept small (32 instructions, no branches) to simplify analysis and accelerate violation detection. Each campaign iteration generates 100 different inputs per test case to explore various data-dependent behaviors around division operations.</p> <pre><code># Instruction selection\ninstruction_categories:\n  - BASE-BINARY\n\n# Exception handling\ngenerator_faults_allowlist:\n  - div-by-zero\n\n# Contract\ncontract_observation_clause: ct\ncontract_execution_clause:\n  - deh\n\n# Noise handling\nanalyser_stat_threshold: 0.2\nexecutor_sample_sizes: [10, 50, 100, 500]\n\n# Reproducibility\nprogram_generator_seed: 12345\ndata_generator_seed: 67890\n\n# Test case shape: 32 instructions with no branches\nprogram_size: 32\navg_mem_accesses: 16\nmin_bb_per_function: 1\nmax_bb_per_function: 1\n\n# Single actor\nactors:\n  - main:\n      mode: host\n      privilege_level: kernel\n      data_properties:  # no page faults\n        present: true\n        writable: true\n\n# Debugging\nlogging_modes: ['info', 'stat', 'dbg_generator']\n</code></pre> <p>Launch the campaign:</p> <pre><code>rvzr fuzz -s base.json -c config.yaml -n 100000 -i 100 -w ./violations --timeout 3600\n</code></pre>"},{"location":"howto/design-campaign/#whats-next","title":"What's Next?","text":"<ul> <li>How-to: Choose a Contract - Select the appropriate contract for your testing scenario</li> <li>How-to: Use Templates - Create targeted test cases</li> <li>How-to: Interpret Results - Understand fuzzing output</li> <li>Topic: Actors - Configure multi-domain testing</li> <li>Topic: Contracts - Understanding leakage contracts</li> <li>Topic: Test Case Generation - How test cases are generated</li> <li>Reference: Configuration Options - Complete configuration reference</li> <li>Reference: CLI Reference - Command-line interface reference</li> </ul>"},{"location":"howto/interpret-results/","title":"How to Interpret Violation Results","text":"<p>So you've run a fuzzing campaign and found a violation. Now what?</p> <p>This guide will help you understand and validate violations detected by Revizor. This guide explains the structure of violation artifacts, how to reproduce violations, and how to interpret the output to determine whether a violation is genuine and worth investigating.</p> <p>Prerequisites</p> <p>Before starting, ensure you have:</p> <ul> <li>Revizor installed and functional on the target system</li> <li>A violation directory (<code>violation-&lt;timestamp&gt;</code>) produced during fuzzing</li> <li>The configuration file (<code>config.yaml</code>) used in the original fuzzing campaign</li> <li>Access to the same hardware where the violation was detected</li> </ul>"},{"location":"howto/interpret-results/#violation-message","title":"Violation Message","text":"<p>When Revizor detects a violation during fuzzing, it prints a summary message to the console similar to this:</p> <pre><code>(venv-3.12) main \u279c  revizor ./revizor.py fuzz -s base.json -c demo/detecting-v1.yaml -n 1000 -i 100 -w ./\n\nINFO: [prog_gen] Setting program_generator_seed to random value: 599740\n\nINFO: [fuzzer] Starting at 15:39:42\n17    ( 2%)| Stats: Cls:0/0,In:200,R:7,SF:10,OF:7,Fst:0,CN:0,CT:0,P1:0,CS:0,P2:0,V:0&gt; Priming  27             . to 500\n\n================================ Violations detected ==========================\nViolation Details:\n\n-----------------------------------------------------------------------------------\n                             HTrace                              | ID:92  | ID:192|\n-----------------------------------------------------------------------------------\n^...^...................^...........^.........^................. | 497    | 0     |\n^...^........................................................... | 3      | 2     |\n^^..^...........................................^.........^..... | 0      | 498   |\n\n\n================================ Statistics ===================================\n\nTest Cases: 18\nInputs per test case: 200.0\nViolations: 1\nEffectiveness:\n  Total Cls: 98.0\n  Effective Cls: 98.0\nDiscarded Test Cases:\n  Speculation Filter: 10\n  Observation Filter: 7\n  Fast Path: 0\n  Max Nesting Check: 0\n  Tainting Check: 0\n  Early Priming Check: 0\n  Large Sample Check: 0\n  Priming Check: 0\n\nDuration: 40.5\nFinished at 15:40:23\n</code></pre> <p>Most of the output is statistics, and they are mostly irrelevant for interpreting the violation itself. You can find a detailed explanation of the runtime statistics in the Statistics Reference.</p> <p>The relevant part for interpreting the violation is the <code>Violation Details</code> section:</p> <pre><code>-----------------------------------------------------------------------------------\n                             HTrace                              | ID:92  | ID:192|\n-----------------------------------------------------------------------------------\n^...^...................^...........^.........^................. | 497    | 0     |\n^...^........................................................... | 3      | 2     |\n^^..^...........................................^.........^..... | 0      | 498   |\n</code></pre> <p>This section summarizes the hardware trace samples recorded for the inputs that triggered the violation.</p> <p>Let's break it down.</p>"},{"location":"howto/interpret-results/#violating-inputs","title":"Violating Inputs","text":"<pre><code>| ID:92  | ID:192|\n</code></pre> <p>This block tells us which inputs produced the violation. In this case, it's inputs 92 and 192. You can find them in the violation artifact directory as <code>input_92.bin</code> and <code>input_192.bin</code>.</p>"},{"location":"howto/interpret-results/#hardware-traces","title":"Hardware Traces","text":"<pre><code>^...^...................^...........^.........^.................\n^...^...........................................................\n^^..^...........................................^.........^.....\n</code></pre> <p>This block shows a visual representation of all observed hardware traces for these inputs. In this example, we used Revizor's default P+P (Prime+Probe) cache side channel tracer, which records the state of L1D cache after a test case execution. The <code>^</code> character indicates that a cache line was accessed (evicted by the test case program), while the <code>.</code> character indicates that the cache line was not accessed. The complete line is a bitmap of all 64 L1D cache sets available on the target machine, numbered left to right from 0 to 63.</p> <p>Accordingly, the first line is interpreted as follows:</p> <pre><code>    Set 4 accessed                  Set 36 accessed\n    |                               |         Set 46 accessed\n    |                               |         |\n^...^...................^...........^.........^.................\n|                       |\nSet 0 accessed          Set 24 accessed\n</code></pre> <p>meaning that cache sets with IDs 0, 4, 24, 36, and 46 were accessed in this hardware trace.</p> <p>Colors!</p> <p>Enable <code>color: true</code> in the configuration file to improve readability of hardware trace visualizations.</p>"},{"location":"howto/interpret-results/#trace-distribution","title":"Trace Distribution","text":"<pre><code>... | 497    | 0     |\n... | 3      | 2     |\n... | 0      | 498   |\n</code></pre> <p>Finally, this block shows the statistical distribution of hardware traces for each input. For example, input 92 produced the first hardware trace 497 times (out of the total of 500 measurements), while input 192 never produced that trace. Instead, input 192 produced the third hardware trace 498 times.</p>"},{"location":"howto/interpret-results/#analysis","title":"Analysis","text":"<p>By looking at this table, we can deduce two important facts about the violation:</p> <ol> <li>There is a clear difference in the sample distributions for the two inputs. This indicates a genuine violation rather than random noise.</li> <li>The dominant (most frequently observed) hardware trace for each input have evicted distinct sets of cache lines. This is an indirect clue that the test case had a data-dependent memory accesses pattern that was not predicted by the contract (likely due to speculative execution).</li> </ol>"},{"location":"howto/interpret-results/#violation-artifact","title":"Violation Artifact","text":"<p>When Revizor detects a violation, it creates a directory named <code>violation-&lt;timestamp&gt;</code>, with the following structure:</p> <pre><code>violation-&lt;timestamp&gt;/\n\u251c\u2500\u2500 program.asm\n\u251c\u2500\u2500 input_0.bin\n\u251c\u2500\u2500 input_1.bin\n\u251c\u2500\u2500 ...\n\u251c\u2500\u2500 report.txt\n\u251c\u2500\u2500 org-config.yaml\n\u251c\u2500\u2500 reproduce.yaml\n\u2514\u2500\u2500 minimize.yaml\n</code></pre> <p>The <code>program.asm</code> file holds the test case program that triggered the violation. The <code>input_*.bin</code> files contain the input sequence that exposed the leak. The <code>report.txt</code> file provides additional details including hardware and contract traces. The configuration files include <code>org-config.yaml</code> (the original configuration), <code>reproduce.yaml</code> (for reproducing the violation), and <code>minimize.yaml</code> (for test case minimization).</p> <p>Before proceeding with analysis, locate this directory and verify that all required files are present.</p>"},{"location":"howto/interpret-results/#reproducing-the-violation","title":"Reproducing the Violation","text":"<p>It is usually a good idea to first reproduce the violation outside of the fuzzing campaign. This confirms that the violation is stable and not a transient artifact of noise or a misconfiguration of the fuzzer.</p> <pre><code>rvzr reproduce -s base.json -c ./violation-&lt;timestamp&gt;/reproduce.yaml \\\n    -t ./violation-&lt;timestamp&gt;/program.asm -i ./violation-&lt;timestamp&gt;/input_*.bin\n</code></pre> <p>If Revizor prints \"Violation detected\" in the output, the violation reproduced successfully. The distribution of hardware traces should roughly match the original violation. Significant differences may indicate a bug or misconfiguration in the fuzzer (e.g., random seeds).</p> <p>Non-reproducible violations should be rare, typically no more than one or two per machine per week of fuzzing. If your campaign produces more, adjust the configuration file to increase noise tolerance. See the configuration options reference for details on noise-related parameters.</p>"},{"location":"howto/interpret-results/#evaluating-violation-quality","title":"Evaluating Violation Quality","text":"<p>Several factors determine whether a violation is worth investigating further.</p> <p>Reproducibility is the most important criterion. Violations that consistently reproduce across multiple runs indicate stable, genuine leaks. Sporadic violations that appear and disappear may be false positives caused by noise. In such cases, consider adjusting noise tolerance settings (<code>analyser_stat_threshold</code> and/or <code>executor_sample_sizes</code>) in the configuration file and rerunning the fuzzing campaign.</p> <p>Trace distribution provides additional insight. Clean violations show clear separation between inputs with consistent occurrence counts. Messy violations with overlapping traces or highly variable counts suggest non-determinism and may be harder to analyze. In such cases, consider collecting more samples per input by increasing the <code>executor_sample_sizes</code> configuration option (note: this will slow down fuzzing).</p> <p>Finally, the hardware trace pattern can be informative as well. There is no hard rule here, but if you see lots of accessed cache sets while the configuration is supposed to limit the number of memory accesses to only a few, that may indicate that some CPU feature creates additional noise, beyond the ability of the statistical analyzer to filter it out. In practice, this is often due to prefetchers. It is typically a good idea to disable them, unless you are specifically testing for prefetcher-related leaks.</p>"},{"location":"howto/interpret-results/#next-steps","title":"Next Steps","text":"<p>Once you have confirmed that a violation is reproducible and worth investigating, proceed to minimize the violation artifacts and root-cause the leak. See the How to Minimize Test Cases and How to Root-Cause a Violation guides for detailed instructions.</p>"},{"location":"howto/interpret-results/#see-also","title":"See Also","text":"<ul> <li>How to Root-Cause a Violation - Systematic analysis of confirmed violations</li> <li>How to Design a Fuzzing Campaign - Tuning fuzzer parameters for better results</li> <li>How to Minimize Test Cases - Simplifying violation artifacts for analysis</li> <li>Configuration Options - Detailed configuration parameter reference</li> <li>Execution Modes - Understanding reproduce mode and other execution modes</li> <li>Trace Analysis and Violation Detection - How Revizor detects and analyzes violations</li> <li>Contracts and Leakage Models - Understanding contract semantics</li> </ul>"},{"location":"howto/minimize/","title":"How to Minimize Test Cases","text":"<p>This guide discussed a process of test case minimization, which aims to reduce complexity of violation artifacts by simplifying test programs and input sequences while preserving the violation. This is typically a post-processing step performed after a fuzzing campaign has detected a violation, with the goal of producing a minimal test case suitable for human analysis and root-cause investigation.</p> <p>The minimization is done by using Revizor's <code>minimize</code> mode, which post-processes a violation through a series of transformation passes that simplify both the test program and input sequence.</p> <p>Related Documentation</p> <p>For a complete list of available passes and their detailed descriptions, see the Minimization Passes reference.</p> <p>Prerequisites</p> <p>Before starting, ensure you have:</p> <ul> <li>Revizor installed and functional on the target system</li> <li>A violation directory (<code>violation-&lt;timestamp&gt;</code>) produced during fuzzing</li> <li>The configuration file (<code>config.yaml</code>) used in the original fuzzing campaign</li> <li>Access to the same hardware where the violation was detected</li> </ul>"},{"location":"howto/minimize/#basic-usage","title":"Basic Usage","text":"<p>Run the minimizer with the following syntax:</p> <pre><code>rvzr minimize -s &lt;spec_file&gt; -c &lt;config_file&gt; -t &lt;program_file&gt; -o &lt;output_file&gt; \\\n    -i &lt;num_inputs&gt; --input-outdir &lt;input_outdir&gt; --num-attempts &lt;num_attempts&gt; \\\n    [pass_options]\n</code></pre> <p>Parameters:</p> <ul> <li><code>-s</code>: Path to ISA specification (e.g., <code>base.json</code>)</li> <li><code>-c</code>: Path to configuration file (typically <code>minimize.yaml</code> from violation directory)</li> <li><code>-t</code>: Path to test program (typically <code>program.asm</code> from violation directory)</li> <li><code>-o</code>: Output path for minimized program</li> <li><code>-i</code>: Number of inputs in the sequence (must match the original fuzzing campaign)</li> <li><code>--input-outdir</code>: Directory to store minimized input files</li> <li><code>--num-attempts</code>: Number of minimization iterations to perform</li> <li><code>[pass_options]</code>: Enable specific minimization passes (see Minimization Passes)</li> </ul> <p>Example command (assuming a violation directory named <code>violation-0000-0000</code>):</p> <pre><code>rvzr minimize -s base.json -c violation-0000-0000/minimize.yaml -t violation-0000-0000/program.asm \\\n    -i 25 --input-outdir ./min-inputs --num-attempts 10 --enable-instruction-pass 1 \\\n    -o min.asm\n</code></pre> <p>This command generates an input sequence of 25 inputs based on the seed in <code>violation-0000-0000/minimize.yaml</code>, applies the instruction removal pass 10 times to simplify <code>program.asm</code>, and writes the minimized program to <code>min.asm</code>. The simplified input sequence is stored in <code>./min-inputs</code>.</p>"},{"location":"howto/minimize/#interpreting-the-output","title":"Interpreting the Output","text":"<p>Each minimization pass prints progress indicators to the console as it executes. Understanding this output helps verify that minimization is progressing correctly.</p>"},{"location":"howto/minimize/#program-pass-output","title":"Program Pass Output","text":"<p>Program passes display one character per instruction to indicate success or failure:</p> <ul> <li><code>.</code> indicates the pass succeeded on this instruction (e.g., instruction was successfully removed)</li> <li><code>-</code> indicates the pass failed on this instruction (e.g., removing this instruction breaks the violation)</li> </ul> <p>Example output when running <code>--enable-instruction-pass</code>:</p> <pre><code>[Pass 2] Instruction Removal Pass\n\n.............-.....--.-------..----\n</code></pre> <p>Interpret this output by reading from right to left, since the pass iterates from the end of the program to the beginning. In this example, the pass successfully removed the last 13 instructions, failed on the 14<sup>th</sup> instruction from the end, succeeded on the 15<sup>th</sup>, and so on.</p>"},{"location":"howto/minimize/#input-pass-output","title":"Input Pass Output","text":"<p>The <code>input-diff</code> pass uses a memory-map visualization to show minimization progress. Each character represents one byte in the input sequence:</p> <ul> <li><code>.</code> indicates zeroing the byte succeeded</li> <li><code>+</code> indicates copying the byte from the first input to the second succeeded</li> <li><code>=</code> indicates the byte was already identical in both inputs</li> <li><code>^</code> indicates the pass could not minimize this byte (it remains different between inputs)</li> </ul> <p>Example output from <code>--enable-input-diff-pass</code>:</p> <pre><code>Address    +0x0     +0x40    +0x80    +0xc0    +0x100   +0x140   +0x180   +0x1c0\n0x00000000 ........ ........ ........ ........ ........ ........ ........ ........\n0x00000200 ........ ........ ........ ........ ........ ........ ........ ........\n0x00000400 ........ ........ ........ ........ ........ ........ ........ ........\n0x00000600 ........ ........ ........ ........ ........ ........ ........ ........\n0x00000800 ........ ........ ........ ........ ........ ........ ........ ........\n0x00000a00 ........ ........ ........ ........ ........ ........ ........ ........\n0x00000c00 ........ ........ ........ ........ ........ ........ ........ ........\n0x00000e00 ........ ........ ........ ........ ........ ........ ........ ........\n0x00001000 ........ ........ ........ ........ ........ ........ ........ ........\n0x00001200 ........ ........ ........ ........ ........ ........ ........ ........\n0x00001400 ........ ........ ........ ........ ........ ........ ........ ........\n0x00001600 ........ ........ ........ ........ ........ ........ ........ ........\n0x00001800 ........ ........ ........ ........ ........ ........ ........ ........\n0x00001a00 ........ ........ ........ ........ ........ ........ ........ ........\n0x00001c00 ........ ........ ........ ........ ........ ........ ........ ........\n0x00001e00 ........ ........ ........ ........ ........ ........ ........ ........\n0x00002000 ====^=..\n0x00002040 ........ ........ ........ ........\n  &gt; Result: Leaked 1 bytes\n  &gt; Addresses: ['0x2020']\n</code></pre> <p>This output shows that the pass successfully minimized most input differences. The byte at address <code>0x2020</code> (marked with <code>^</code>) remains different between the two inputs and likely contributes to the violation. Bytes at addresses <code>0x2000-0x2018</code> and <code>0x2028</code> (marked with <code>=</code>) were already identical.</p>"},{"location":"howto/minimize/#comment-pass-output","title":"Comment Pass Output","text":"<p>Enable <code>--enable-comment-pass</code> to annotate the minimized program with analysis information. The pass inserts comments indicating which memory accesses contributed to the violation, making it easier to identify the root cause.</p> <p>Comment format:</p> <pre><code># mem access: [input1_id] [load_addr]-[store_addr]\n  CL [cache_set_id]:[cache_line_offset] | [input2_id] [load_addr]-[store_addr]\n  CL [cache_set_id]:[cache_line_offset]\n</code></pre> <p>Each comment shows the memory addresses accessed by an instruction when executed with the two inputs that triggered the violation. The comment includes both virtual addresses and their corresponding L1D cache set IDs and line offsets.</p> <p>Example comment:</p> <pre><code># mem access: [1] 0x800-0x800 CL 32:0 | [11] 0x710-0x710 CL 28:10\n</code></pre> <p>This indicates that when executed with input 1, the instruction accessed address <code>0x800</code> (cache set 32, offset 0), and when executed with input 11, it accessed address <code>0x710</code> (cache set 28, offset 10). These different cache set accesses likely contributed to the violation.</p>"},{"location":"howto/minimize/#complete-workflow-example","title":"Complete Workflow Example","text":"<p>This example demonstrates a typical minimization workflow. Assume a fuzzing campaign detected a violation:</p> <pre><code>rvzr fuzz -s base.json -c config.yaml -n 1000 -i 25 -w .\n</code></pre> <p>The fuzzer created a violation directory (e.g., <code>violation-000000-000000</code>) containing the test case artifacts.</p>"},{"location":"howto/minimize/#step-1-minimize-the-program","title":"Step 1: Minimize the Program","text":"<p>Apply all program passes to simplify the test case while preserving the violation:</p> <pre><code>rvzr minimize -s base.json -c ./violation-000000-000000/minimize.yaml \\\n    -t ./violation-000000-000000/program.asm \\\n    -o min.asm -i 25 --num-attempts 3 \\\n    --enable-instruction-pass 1 \\\n    --enable-simplification-pass 1 \\\n    --enable-nop-pass 1 \\\n    --enable-constant-pass 1 \\\n    --enable-mask-pass 1 \\\n    --enable-label-pass 1\n</code></pre>"},{"location":"howto/minimize/#step-2-verify-program-minimization","title":"Step 2: Verify Program Minimization","text":"<p>Confirm the minimized program still triggers the violation:</p> <pre><code>rvzr fuzz -s base.json -c ./violation-000000-000000/minimize.yaml -t min.asm -i 25\n</code></pre> <p>If the violation is no longer detected, reduce <code>--num-attempts</code> or disable some passes, then retry step 1.</p>"},{"location":"howto/minimize/#step-3-minimize-inputs-and-add-annotations","title":"Step 3: Minimize Inputs and Add Annotations","text":"<p>Apply input passes and analysis passes to further simplify the test case and add helpful comments:</p> <pre><code>rvzr minimize -s base.json -c ./violation-000000-000000/minimize.yaml \\\n    -t min.asm -o commented.asm -i 25 \\\n    --input-outdir ./inputs \\\n    --enable-input-diff-pass 1 \\\n    --enable-input-seq-pass 1 \\\n    --enable-comment-pass 1\n</code></pre>"},{"location":"howto/minimize/#step-4-verify-complete-minimization","title":"Step 4: Verify Complete Minimization","text":"<p>Reproduce the violation with the minimized program and inputs:</p> <pre><code>rvzr reproduce -s base.json -c ./violation-000000-000000/reproduce.yaml \\\n    -t commented.asm -i ./inputs/min_input*.bin\n</code></pre> <p>If successful, the minimized test case in <code>commented.asm</code> and <code>./inputs/</code> is ready for detailed analysis. The annotated comments will help identify the root cause of the violation.</p> <p>Troubleshooting Failed Minimization</p> <p>If minimization breaks the violation, try these adjustments:</p> <ul> <li>Reduce <code>--num-attempts</code> to perform fewer iterations</li> <li>Disable aggressive passes like <code>--enable-simplification-pass</code></li> <li>Minimize the program before minimizing inputs</li> <li>Check that <code>data_generator_seed</code> matches the original fuzzing campaign</li> </ul>"},{"location":"howto/minimize/#whats-next","title":"What's Next?","text":"<p>Once a violation is minimized, the next step is typically to analyze it manually to understand the root cause. The How to Root-Cause a Violation guide is dedicated to this topic.</p>"},{"location":"howto/minimize/#see-also","title":"See Also","text":"<ul> <li>Minimization Passes - Complete list of available passes and their options</li> <li>CLI Reference - Full command-line interface documentation</li> <li>Execution Modes - Overview of all Revizor execution modes</li> <li>Configuration Options - Configuration file reference including <code>data_generator_seed</code></li> <li>How to Design a Fuzzing Campaign - Set up effective fuzzing campaigns</li> <li>How to Interpret Results - Understand fuzzing outputs and violation reports</li> <li>Trace Analysis and Violation Detection - Understanding how violations are detected</li> </ul>"},{"location":"howto/root-cause-a-violation/","title":"How to Root-Cause a Violation","text":"<p>This guide discussed in detail how to identify the root cause of confirmed contract violations. This guide shows a typical workflow and some useful techniques for analyzing violation artifacts and isolating the specific CPU behavior that leads to information leakage.</p> <p>Art, Not Science</p> <p>Root-causing violations is more art than science. The techniques described here are not guaranteed to work in every situation because violations can arise from a wide variety of complex CPU behaviors. Use your intuition and knowledge of microarchitecture to guide your analysis. Experiment with different approaches and document what works best for you.</p> <p>Prerequisites</p> <p>The guide assume you have already finished a fuzzing campaign and minimized the violation artifacts.</p>"},{"location":"howto/root-cause-a-violation/#locate-the-violation-files","title":"Locate the Violation Files","text":"<p>We will explore the root-cause analysis through a concrete example. The example will demonstrate a CT-SEQ contract violation on an x86-64 CPU.</p> <p>We will be working with:</p> <ul> <li>The violation artifact in <code>violation-0000-0000/</code> produced during fuzzing</li> <li>A minimized version of the violation program in <code>min.asm</code> produced by the minimizer</li> <li>A set of minimized input files in <code>./inputs/min_input_*.bin</code> produced by the minimizer</li> <li>The configuration file <code>config.yaml</code> used during fuzzing</li> </ul>"},{"location":"howto/root-cause-a-violation/#gather-insights-from-minimizer","title":"Gather Insights from Minimizer","text":"<p>A good starting point is to examine the output of the minimizer, especially from input minimization passes. These passes attempt to reduce the differences between inputs that trigger the violation, and thus they often highlight the specific data values that leak and that impact the violation.</p> <p>Below is an example of the printed summary from the differential input minimizer:</p> <pre><code>[PASS 2] Differential Input Minimizer\n  &gt; Minimizing the difference between inputs 1 and 11\n\nAddress    +0x0     +0x40    +0x80    +0xc0    +0x100   +0x140   +0x180   +0x1c0\n0x00000000 ........ ........ ........ ........ ........ ........ ........ ........\n0x00000200 ........ =....... ........ ........ ........ ........ ........ ........\n0x00000400 ........ ........ ........ ........ ........ ........ ........ ........\n0x00000600 ........ ........ ........ ........ ........ ........ ........ ........\n0x00000800 ........ ........ ........ ........ ........ ........ ........ ........\n0x00000a00 ........ ........ ........ ........ ........ ........ ........ ........\n0x00000c00 ........ ........ ........ ........ ........ ........ ........ ........\n0x00000e00 ........ ........ ........ ........ ........ ........ ........ ........\n0x00001000 ........ ........ ........ ........ ........ ........ ........ ........\n0x00001200 ........ ........ ........ ........ ........ ........ ........ ........\n0x00001400 ........ ........ ........ ........ ........ ........ ........ ........\n0x00001600 ........ ........ ........ ........ ........ ........ ........ ........\n0x00001800 ........ ........ ........ ........ ........ ........ ........ ........\n0x00001a00 ........ ........ ........ ........ ........ ........ ........ ........\n0x00001c00 ........ ........ ........ ........ ........ ........ ........ ........\n0x00001e00 ........ ........ ........ ........ ........ ........ ........ ........\n0x00002000 .....^..\n0x00002040 ........ ........ ........ ........\n  &gt; Result: Leaked 1 bytes\n  &gt; Addresses: ['0x2028']\n</code></pre> <p>The minimizer goes through the pair of inputs that trigger the violation - inputs #1 and #11 in this case - and tries to minimize the differences between them:</p> <ul> <li>If both inputs already have identical values at a given address, the minimizer prints <code>=</code> for that address. In this example, this is the case for address <code>0x240</code>.</li> <li>Next, the pass attempts to zero out one byte at a time in both inputs. If the violation persists, then the minimizer prints <code>.</code> for that address. In this example, most of the addresses are zeroed out.</li> <li>Next, the pass attempts to copy one byte from input #1 into the same address in input #11. If the violation persists, then the minimizer prints <code>+</code> for that address. This example does not have such cases.</li> <li>If both attempts fail, the pass restores the original values at the given address, prints <code>^</code>, and moves to the next address. In this example, the minimizer restored the original value at address <code>0x2028</code>.</li> </ul> <p>The interpretation of these results is case-specific, but generally, the values with <code>+</code> or <code>=</code> are those that create conditions for leakage, and the values with <code>^</code> are the addresses whose value leaks.</p> <p>In this example, the minimizer found that this test case leaks one byte at address <code>0x2028</code> (used to initialize RDI). The minimizer also found that the address <code>0x240</code> must contain specific non-zero values that must be the same in both inputs. This address in the input is used to initialize the corresponding offset in the sandbox of actor 0. See Sandbox Memory Layout for more details about register and memory initialization.</p> <p>Minimizer Behavior</p> <p>Ideally, the minimizer should be able to reduce the leakage to a single byte. If more then a couple bytes leak, it typically indicates that the violation is non-deterministic, and it might be a good idea to re-run the program minimizer or to change the configuration to increase the number of attempts/increase the noise threshold. If no bytes leak, this is a certain sign that something went wrong; re-run the minimizer.</p>"},{"location":"howto/root-cause-a-violation/#step-3-add-comments-to-minimized-program","title":"Step 3: Add Comments to Minimized Program","text":"<p>Run the minimizer again with the <code>comment</code> pass enabled to annotate the minimized program with memory access information. This will help you map hardware traces to specific instructions in the program.</p> <pre><code>rvzr minimize -s base.json -c ./violation-0000-0000/minimize.yaml \\\n    -t min.asm -o commented.asm -i &lt;num_inputs&gt; \\\n    --enable-comment-pass 1\n</code></pre>"},{"location":"howto/root-cause-a-violation/#insert-speculation-fences","title":"Insert Speculation Fences","text":"<p>To isolate speculative behavior, add fences:</p> <pre><code>rvzr minimize -s base.json -c ./violation-0000-0000/minimize.yaml \\\n    -t commented.asm -o fenced.asm -i &lt;num_inputs&gt; \\\n    --enable-fence-pass 1\n</code></pre> <p>This pass with attempt to insert an <code>LFENCE</code> after every instruction in the program and check if the violation still occurs.</p> <p>In the resulting file (<code>fenced.asm</code>) the region without fences is the one that causes the violation. The remaining instructions are just setting up the data for the violation, and are likely irrelevant.</p> <p>Unexpected Fence Insertion Results</p> <p>If an <code>LFENCE</code> is inserted after every instruction in the test case and the violation still occurs, this is most likely due to a bug in the model or the executor. If you are using a custom model, consider checking the model for correctness. If you haven't made changes to the Revizor source code, please, open an issue in the bug tracker.</p>"},{"location":"howto/root-cause-a-violation/#map-hardware-traces-to-minimized-program-and-data","title":"Map Hardware Traces to Minimized Program and Data","text":"<p>When both program and its inputs are minimized, you should be able to identify which instructions caused the cache accesses in the hardware traces and which data was leaked.</p> <p>When we run the <code>reproduce</code> command with the minimized program and inputs, we will see the following hardware traces:</p> <pre><code>rvzr reproduce -s base.json -c ./violation-0000-0000/reproduce.yaml \\\n    -t commented.asm -i ./inputs/min_input*.bin\n\n...\n\n================================ Violations detected ==========================\n-----------------------------------------------------------------------------------\n                             HTrace                              | ID:1   | ID:11 |\n-----------------------------------------------------------------------------------\n^...............................................^............... | 420    | 0     |\n^............................................................... | 80     | 0     |\n^..............^................................................ | 0      | 500   |\n</code></pre> <p>Input IDs</p> <p>If in your case the input IDs have changed after minimization, you can either exclude some of the inputs from the arguments of the <code>reproduce</code> command, or re-run the minimizer with fewer passes.</p> <p>We see that the hardware traces have been significantly simplified compared to the original violation, and now there are at most two accessed cache sets in each trace: 0 and 48 for input #1, and 0 and 15 for input #11. This is a good sign: the minimization was successful.</p> <p>We can also tell that the only difference between the two traces is the accessed cache set 48 vs 15 . This is the cache set that is causing the violation, and we should be aiming to find the instruction that does the access.</p> <p>To do so, let's look at the contents of the <code>commented.asm</code> file. This file contains the minimized program with comments that show which memory addresses or cache lines are accessed by each instruction.</p> <pre><code>; ... skipped header ...\n1.  and rax, 0b1111111111111 # instrumentation\n2.  lfence\n3.  mov edx, dword ptr [r14 + rax]\n4.  # mem access: [1] 0x0 cl 0:0 | [11] 0x0 cl 0:0\n5.  or cx, 0b1000 # instrumentation\n6.  and cl, 0b11111000 # instrumentation\n7.  and dx, 0b11 #\n8.  and rsi, 0b1111111111111 #\n9.  add cl, 39 #\n10. mov rbx, 0b1111111111111 #\n11. bt si, dx\n12. jbe .bb_0.1\n13. jmp .exit_0\n14. .bb_0.1:\n15. mov ecx, edi\n16. and rcx, 0b1111111111000 # instrumentation\n17. mov byte ptr [r14 + rcx], 88\n; ... skipped footer ...\n</code></pre> <p>This program contains only two memory accesses, at lines 3 and 17.</p> <p>The annotation at line 4 tells us that the <code>mov</code> instruction accesses memory offset <code>0x0</code> when executed with input 1 (<code>[1]</code>) and the same cache set when executed with input 11 (<code>[11]</code>). The notation <code>0:0</code> stands for cache set <code>0</code> and cache line offset <code>0</code>.</p> <p>This information lets us map this instruction to the first access in the hardware trace:</p> <pre><code>    ^...............................................^...............\n    |\n  This eviction maps to `mov edx, dword ptr [r14 + rax]` at line 3\n</code></pre> <p>The second memory access (line 17) does not have an annotation, which implies that the contract model has not executed this instruction with the inputs provided. It does not, however, mean that the CPU has not executed this instruction, as there is a chance that this instruction was executed speculatively. This is a typical scenario in violations detected by Revizor.</p> <p>If we look at the instructions prior to the memory access, we can see <code>jbe</code> instruction at line 12, which is a conditional jump - a common source of speculation, namely branch prediction. This type of speculation is not permitted by the target contract (CT-SEQ), so it could cause a violation. From this, we can make a hypothesis that the memory access at line 17 is speculative and is the one causing the second cache access:</p> <pre><code> Inputs [1]:\n              Hypothesis: This eviction maps to `mov` at line 17\n                                                  |\n  ^...............................................^...............\n\n Inputs [11]:\n  ^..............^................................................\n                 |\n           Hypothesis: This eviction maps to `mov` at line 17\n</code></pre> <p>To check if our hypothesis is correct, let's cross-reference this information with the leaked bytes from the differential input minimizer:</p> <pre><code>; .. skip zero bytes\n0x00002000 .....^..\n0x00002040 ........ ........ ........ ........\n  &gt; Result: Leaked 1 bytes\n  &gt; Addresses: ['0x2028']\n</code></pre> <p>This summary tells us that <code>rdi</code> has a differing value between inputs #1 and 11. At the same time, the first time <code>rdi</code> is used in the program is at line 15, where it is moved to <code>rcx</code>, and then later used as a part of the address in the memory access at line 17. This would make the speculative memory access at line 17 access different addresses with the two inputs, and would explain the difference between the hardware traces.</p> <p>At this point, the hypothesis is more-or-less confirmed, and we can declare that the root cause of the leak was the misprediction of the <code>jbe</code> branch at line 12, which caused the speculative execution of the memory access at line 17, and which in turn leaked the value of <code>rdi</code>.</p> <p>If we want to further increase our confidence, we can manually inspect the contents of the inputs at the address <code>0x2028</code> to see if the values correspond to the cache set ID that we observe in the hardware traces. This can be done by running the <code>hexdump</code> command on the input files:</p> <pre><code>$ hexdump -C ./inputs/min_input_0001.bin | grep 2020\n00002020  00 00 00 00 00 00 00 00  1e 1c 4a 00 1e 1c 4a 00  |..........J...J.|\n$ hexdump -C ./inputs/min_input_0011.bin | grep 2020\n00002020  00 00 00 00 00 00 00 00  c8 13 58 00 c8 13 58 00  |..........X...X.|\n</code></pre> <p>The values are <code>0x4a1c1e004a1c1e</code> for input #1 and <code>0x5813c8005813c8</code> for input #11. These are masked with <code>0b1111111111000</code> by <code>and</code> at line 16 and become <code>7192</code> and <code>5064</code> respectively. If we translate these values to cache set IDs (<code>id = (addr % 0x1000) // 64</code>), we get <code>48</code> and <code>15</code>. These values match the cache set IDs that we observed in the hardware traces, which confirms our hypothesis.</p> <p>If we want even more confidence, we can manually modify the input files (e.g, with <code>hexedit</code> tool) to see if the hardware traces change when we modify the value of <code>rdi</code> in the input files.</p>"},{"location":"howto/root-cause-a-violation/#modify-the-program","title":"Modify the Program","text":"<p>In many cases, the minimization process will not provide a clear result as in the example above and you will not be able to make a specific hypothesis about the root cause of the violation. In such cases, you can try to modify the program in various ways to see if the violation still occurs. There are no strict rules on which modifications to make and you will have to rely on your intuition and knowledge of the target microarchitecture, but here are some general guidelines:</p> <ol> <li>Simplify Instructions: Start by trying to manually replace instructions in <code>minimized.asm</code> with simpler ones. For example, replace complex instructions with memory operands with simple loads or stores.</li> <li>Increase/Decrease Aliasing: Try to change the addresses of memory accesses to match (or not match if they already do) the addresses of other instruction. Such aliasing often triggers speculation (e.g., in Speculative Store Bypass or MDS attacks).</li> <li>Add/Remove Dependent Instructions: If you have a hypothesis about which instruction triggers speculation, try adding or removing data-dependent instructions before it. This will change the size of the speculative window and might change hardware traces, which will give you more insight into the violation.</li> <li>Change Memory Permissions: If the violation is related to memory accesses, try changing the permissions of the memory regions that are accessed by the program. For example, if the memory is read-only, try changing it to read-write. If the violation disappears, it might indicate that the violation is related to the permission checks in the CPU.</li> <li>Change Instruction Operands: Try changing operands to add or remove data dependencies between instructions. For example, if you have a sequence of two moves <code>mov rax, [rax]; mov rbx, [rax]</code>, try changing the second move to <code>mov rbx, [rbx]</code> to see if the violation still occurs if there are no data dependencies between the instructions.</li> </ol> <p>After each modification, run the <code>reproduce</code> command to see if the violation still occurs:</p> <pre><code>rvzr reproduce -s base.json -c ./violation-&lt;timestamp&gt;/reproduce.yaml \\\n    -t modified.asm -i ./inputs/min_input*.bin\n</code></pre> <p>Share Your Findings</p> <p>If you find any other strategies that work well, please consider sharing them by opening a pull request to this documentation. We would love to hear about your experiences and learn from them.</p>"},{"location":"howto/root-cause-a-violation/#see-also","title":"See Also","text":"<ul> <li>How to Interpret Violation Results - Understanding and validating violations before root-cause analysis</li> <li>How to Minimize Test Cases - Complete minimization workflow and pass descriptions</li> <li>Minimization Passes - Reference documentation for all minimization passes</li> <li>Configuration Options - Configuration parameters for reproduction and minimization</li> <li>Command-Line Interface - Complete CLI reference for all execution modes</li> <li>Sandbox Memory Layout - Understanding input file structure and register initialization</li> <li>Trace Analysis and Violation Detection - How Revizor detects violations</li> <li>Contracts and Leakage Models - Understanding contract semantics</li> </ul>"},{"location":"howto/use-macros/","title":"How To: Use Macros","text":"<p>This document explains the concept of macros in Revizor and describes how to create test cases that use macros.</p> <p>Note that macros are especially useful in the template-based mode of Revizor, so if you are not familiar, check out the Template-Based Mode documentation as well.</p>"},{"location":"howto/use-macros/#what-is-a-macro","title":"What is a macro?","text":"<p>Macros in Revizor are special pseudo-instructions that provide a flexible way to insert complex operations into test cases. They appear as labels of a special format in the assembly code but are dynamically expanded into actual implementations during execution by the model and the executor.</p> <p>Macros solve two key challenges, especially in the context of multi-domain testing:</p> <ul> <li>Structuring: Enable insertion of pre-defined instruction sequences (like domain transitions or microarchitectural isolation primitives) within randomized test contexts</li> <li>Unification: Allow the same test case template to be instantiated differently across executor and model stages, accommodating differences in ISA support.</li> </ul>"},{"location":"howto/use-macros/#why-use-macros","title":"Why use macros?","text":"<p>Macros exist to provide extra flexibility and convenience when creating test case. There are certain operations that are cumbersome or impractical to express directly in assembly code, and macros serve to abstract away these complexities.</p>"},{"location":"howto/use-macros/#macro-definition-and-usage","title":"Macro Definition and Usage","text":""},{"location":"howto/use-macros/#assembly-syntax","title":"Assembly Syntax","text":"<p>Macros use standard assembly syntax of a label with the <code>.macro</code> prefix:</p> <pre><code>.macro.macro_name.argument1.argument2.argument3.argument4:\n</code></pre> <p>A macro can take at most four arguments. The arguments are strictly static; Revizor does not support dynamic arguments in macros, such as registers or memory addresses.</p>"},{"location":"howto/use-macros/#example-usage","title":"Example Usage","text":"<p>A user can create a test case program where only a subset of instruction is measured by using <code>measurement_start</code> and <code>measurement_end</code> macros:</p> <pre><code>.intel_syntax noprefix\n.section .data.main\n\n... ; non-measured code here\n\n.macro.measurement_start:\n\n... ; measured code here\n\n.macro.measurement_end:\n\n... ; non-measured code here\n\n.test_case_exit:\n</code></pre> <p>Revizor will automatically replace the macros with no-op operations of an ISA-dependent size, and record the location and the arguments of the macros in the test case metadata. When the executor and the model run the test case, they will recognize these macros and execute the corresponding logic. Note that the logic can be configurable, e.g., when the user has set <code>executor_mode: P+P</code> (prime+probe), the <code>measurement_start</code> macro will correspond the Prime stage of the measurement, and <code>measurement_end</code> will correspond to the Probe stage.</p> <p>See Implementation Overview for details on how macros are implemented in the executor and model.</p>"},{"location":"howto/use-macros/#implementation-overview","title":"Implementation Overview","text":""},{"location":"howto/use-macros/#internal-representation-of-macros","title":"Internal Representation of Macros","text":"<p>Revizor internally replaces all macros with a no-op placeholder of a fixed size (8 bytes for x86-64, 12 bytes for ARM64). This placeholder is used to maintain the original instruction flow while allowing the executor and model to recognize and handle macros dynamically. The macro location, type, and arguments are stored in the test case metadata, namely in the <code>SYMBOL TABLE</code> section of the RCBF File Format, where <code>owner</code> is set to the actor ID of the actor that contains the macro, <code>offset</code> is the offset of the macro placeholder in the code section of the actor, <code>id</code> is the macro type (defined in executor_km/include/macro_expansion.h), and <code>args</code> is a compressed representation of the macro arguments.</p>"},{"location":"howto/use-macros/#macros-in-executor","title":"Macros in Executor","text":"<p>Each actor's code section contains a dedicated memory region for macros, and the implementation is copied there during test case initialization. The executor copies the implementations of all macros into this section, and it replaces the macro placeholders with direct jumps to the corresponding implementations. The executor also inserts a return jump at the end of each macro implementation to return control flow back to the original instruction sequence.</p> <p>For example, if we have a simple test case like this:</p> <pre><code>.macro.measurement_start:\n... ; some code here\n.macro.measurement_end:\n.test_case_exit:\n</code></pre> <p>The executor with expand it as follows:</p> <pre><code>jump measurement_start_impl\nlfence\n.l1:\n... ; some code here\njump measurement_end_impl\nlfence\n.l2:\n.test_case_exit:\n\n.macro_code_section:\nmeasurement_start_impl:\n... ; sequence of instructions that implements the macro\njump .l1  ; jump to the end of the macro section\n\nmeasurement_end_impl:\n... ; sequence of instructions that implements the macro\njump .l2  ; jump to the end of the macro section\n</code></pre> <p>Note that the executor also inserts LFENCE barriers after each macro jump. This is to ensure that the macro execution does not trigger straight-line speculation, which could interfere with the measurement process.</p>"},{"location":"howto/use-macros/#macros-in-model","title":"Macros in Model","text":"<p>In the model, macros are implemented as dynamic callbacks. The model executes a hook function on every instruction execution, checking if the current instruction matches an entry in the symbol table. If a match is found, the model invokes the corresponding callback function to emulate the macro behavior.</p>"},{"location":"howto/use-templates/","title":"Template-Based Mode in Revizor","text":"<p>Template-based mode (<code>tfuzz</code>) enables targeted testing of specific CPU scenarios by using predefined assembly templates that get expanded with random instructions. This mode narrows down the fuzzing space to focus on particular interaction patterns while maintaining randomization within those patterns.</p>"},{"location":"howto/use-templates/#overview","title":"Overview","text":"<p>Template-based mode generates test cases from assembly templates containing macros that get dynamically expanded during generation. Templates define the structure and flow of test cases while allowing specific sections to be populated with random instructions based on configuration.</p>"},{"location":"howto/use-templates/#command-line-usage","title":"Command Line Usage","text":"<p>Template-based mode is invoked using the <code>rvzr tfuzz</code> command. The invocation is almost identical to the normal <code>rvzr fuzz</code> mode, but it takes an additional <code>-t</code> or <code>--template</code> parameter to specify the assembly template file.</p> <p>Invocation example:</p> <pre><code>rvzr tfuzz -t template.asm -c config.yaml -s base.json -n 10 -i 100\n</code></pre> <p>where <code>template.asm</code> is the template file.</p>"},{"location":"howto/use-templates/#template-structure","title":"Template Structure","text":"<p>Templates are assembly files that combine:</p> <ul> <li>Regular assembly instructions</li> <li>Macros (special pseudo-instructions as described in Macros)</li> </ul> <p>Example template:</p> <pre><code>.intel_syntax noprefix\n.section .data.main\n\n.macro.random_instructions.10.0:  ; Replaced with 10 random instructions\ndiv rax, rbx                      ; rax and rbx may be set by random instructions\njmp .test_case_exit               ; Jump to exit point if no exception occurs\n\n.fault_handler:\n    .macro.random_instructions.10.1:  ; Generate 10 random instructions executed when a fault occurs\n\n.test_case_exit:\n</code></pre> <p>Revizor will take this template and replace the <code>.macro.random_instructions.N</code> with N random instructions from the instruction pool defined in the configuration file. A new test case will be generated this way in each fuzzing round, allowing for a wide variety of test cases while still adhering to the structure defined in the template. For example, if <code>-n 10</code> is specified, the generator will produce 10 test cases based on the template, each with different random instruction sequences.</p>"},{"location":"internals/","title":"Developer Documentation","text":"<p>This section provides technical documentation for developers contributing to Revizor.</p>"},{"location":"internals/#development-guidelines","title":"Development Guidelines","text":"<ul> <li>General Guidelines: Development environment setup, testing procedures, contribution workflow</li> <li>Code Style: Formatting conventions for Python and C code, naming conventions</li> <li>Git Workflow: Branch management, commit message format, merge procedures</li> </ul>"},{"location":"internals/#architecture-and-modules","title":"Architecture and Modules","text":"<ul> <li>Overview: High-level system architecture and component interaction</li> <li>Code Structure: Organization of the source code directory and key modules</li> <li>Orchestration: Main fuzzing loop and coordination between components</li> <li>ISA Specification: Instruction set architecture definitions and JSON-based specification format</li> <li>Test Case Code Generation: Program generation algorithm and relevant classes</li> <li>Test Case Data Generation: Data generation algorithm and relevant classes</li> <li>Hardware Tracing: Execution of test cases on the target HW and hardware trace collection</li> <li>Contract Tracing: Leakage modeling and contract trace generation (high-level overview; implementation details in backend-specific pages)</li> <li>Trace Analysis: Comparison of contract and hardware traces to detect violations</li> <li>Minimization: Post-detection reduction of test cases to minimal reproducing examples</li> <li>Logging: Logging infrastructure and debugging facilities</li> </ul>"},{"location":"internals/#contract-modeling-backends","title":"Contract Modeling Backends","text":"<p>Revizor supports two different backends for contract-based leakage modeling. They are documented in the following pages:</p> <ul> <li>Unicorn Backend: Backend based on the Unicorn CPU emulator</li> <li>DynamoRIO Backend: Backend based on the DynamoRIO dynamic binary instrumentation engine</li> </ul>"},{"location":"internals/code-structure/","title":"Code Structure","text":"<p>The Revizor codebase is organized into the following main directories:</p> <pre><code>rvzr/                         Main source code directory containing core fuzzing logic\n  \u251c\u2500\u2500 *.py                    Core modules that implement main fuzzing components\n  \u251c\u2500\u2500 tc_components/          Test case representation objects (code and data)\n  \u251c\u2500\u2500 model_unicorn/          Unicorn-based leakage model\n  \u251c\u2500\u2500 model_dynamorio/        DynamoRIO-based leakage model\n  \u251c\u2500\u2500 executor_km/            Kernel module that implements the hardware executor\n  \u251c\u2500\u2500 postprocessing/         Minimization utilities for contract counterexamples\n  \u2514\u2500\u2500 arch/                   Architecture-specific implementations (x86/ and arm64/)\ntests/                        Unit and integration tests\ndocs/                         Documentation files\n</code></pre> <p>The main entry point is <code>rvzr/cli.py</code>, which parses command-line arguments and initializes the <code>Fuzzer</code> object.</p>"},{"location":"internals/architecture/analysis/","title":"Trace Analysis","text":"Module <code>rvzr/analyser.py</code> Public interface <code>Analyser</code> Inputs <code>CTrace</code>, <code>HTrace</code> Outputs <code>Violation</code> <p>The Analyser compares contract traces with hardware traces to detect violations. The core principle: inputs with identical CTraces should produce equivalent HTraces. When they don't, a contract violation has occurred.</p> <pre><code>For all inputs i, j:\n    if CTrace(i) == CTrace(j) and HTrace(i) != HTrace(j):\n        \u2192 Violation detected\n</code></pre> <p>Analyser implementations:</p> <p>Different analysers define \"equivalent HTrace\" differently:</p> <ul> <li><code>MergedBitmapAnalyser</code> (default) \u2014 Merges samples using bitwise OR, compares bitmaps. For cache-based channels.</li> <li><code>SetAnalyser</code> \u2014 Compares sets of unique samples.</li> <li><code>MWUAnalyser</code> \u2014 Uses Mann-Whitney U statistical test. For timing-based channels.</li> <li><code>ChiSquaredAnalyser</code> \u2014 Uses chi-squared test for distribution differences.</li> </ul>"},{"location":"internals/architecture/code/","title":"Test Case Code Generation","text":"Module <code>rvzr/code_generator.py</code> Public interface <code>CodeGenerator</code> Inputs <code>InstructionSet</code> Outputs <code>TestCaseProgram</code> <p>This module generates random assembly programs for testing. The generator creates programs designed to trigger speculative execution and expose microarchitectural leaks.</p>"},{"location":"internals/architecture/code/#generation-process","title":"Generation process","text":"<ol> <li> <p>Create control flow graph \u2014 Generate a random Directed Acyclic Graph (DAG) of basic blocks. The DAG structure prevents infinite loops while allowing branches and mispredictions.</p> </li> <li> <p>Add jump instructions \u2014 Insert conditional and unconditional jumps at block boundaries to connect the blocks according to the DAG.</p> </li> <li> <p>Fill basic blocks \u2014 Populate blocks with random instructions from the tested instruction pool, respecting instruction frequencies and operand constraints.</p> </li> <li> <p>Instrument \u2014 (Optionally) Prevent faults by masking memory addresses, avoiding division by zero, and ensuring all accesses stay within the sandbox.</p> </li> <li> <p>Assemble \u2014 Convert to binary and extract metadata.</p> </li> <li> <p>Transform into RCBF \u2014 Serialize the test case into Revizor's custom binary format (RCBF) for execution.</p> </li> </ol>"},{"location":"internals/architecture/code/#test-case-representation","title":"Test case representation","text":"<pre><code>TestCaseProgram\n  \u251c\u2500 CodeSection (one per actor)\n  \u2502    \u2514\u2500 Function\n  \u2502         \u2514\u2500 BasicBlock\n  \u2502              \u2514\u2500 InstructionNode\n  \u2502                   \u2514\u2500 Instruction\n  \u2502                        \u2514\u2500 Operand\n  \u2514\u2500 TestCaseBinary\n       \u2514\u2500 SymbolTable\n</code></pre>"},{"location":"internals/architecture/code/#variants","title":"Variants","text":"<p>Architecture-specific implementations of the code generator exist for x86 and ARM64, named <code>X86Generator</code> and <code>ARM64Generator</code> in <code>rvzr/arch/*/code_generator.py</code></p>"},{"location":"internals/architecture/data/","title":"Test Case Data Generation","text":"Module <code>rvzr/data_generator.py</code> Public interface <code>DataGenerator</code> Inputs <code>Config</code> Outputs <code>InputData</code> <p><code>DataGenerator</code> generates input data that is used to initialize registers and memory before executing a test case, on both the model and the target hardware.</p>"},{"location":"internals/architecture/data/#generation-modes","title":"Generation modes","text":"<p>Two input generation modes are supported:</p>"},{"location":"internals/architecture/data/#standard-generation","title":"Standard generation","text":"<p>Interface: <code>DataGenerator.generate(...)</code></p> <p>This method creates fully random inputs using a PRNG. Can optionally reduce entropy (to increase trace collisions) or inject special values (zeros, boundary values) to trigger edge cases.</p>"},{"location":"internals/architecture/data/#boosted-generation","title":"Boosted generation","text":"<p>Interface: <code>DataGenerator.generate_boosted(...)</code></p> <p>Boosted generation solves the following challenge: Two detect a violation via relational non-interference testing, we always need at least two inputs that produce identical contract traces (see Trace Analysis). Generating such contract-equivalent inputs through pure randomness is extremely inefficient because the entropy of contract traces is usually very high, and thus most random inputs produce unique traces.</p> <p>Boosted generation addresses this by leveraging dynamic taint analysis on the model side. It works as follows: Start by producing a set of random inputs using standard generation. Then, we execute the test case with each input in the model and perform backwards taint analysis to identify which input bytes affect the contract trace (tainted) and which don't (untainted). This produces a set of <code>InputTaint</code> objects that map input bytes to their taint status. These taint maps a fed back into the <code>generate_boosted()</code> method, which creates new inputs such that the tainted bytes remain fixed while the untainted bytes are randomized.</p> <pre><code>Original InputData \u2192 Model \u2192 InputTaint \u2192 N contract-equivalent inputs\n</code></pre> <p>Such \"boosted\" inputs are guaranteed to produce the same contract trace as the original input while still being mostly random.</p>"},{"location":"internals/architecture/data/#data-representation","title":"Data Representation","text":"<p>Each input is represented as an <code>InputData</code> object, which is a numpy structured array containing</p> <ul> <li>Memory contents</li> <li>General-purpose registers</li> <li>SIMD registers</li> <li>Flags and special registers</li> </ul> <p>for each actor in the test case. This object can be serialized into Revizor's custom binary format (RDBF) for consumption by the model and executor.</p>"},{"location":"internals/architecture/exec/","title":"Hardware Tracing","text":"Module <code>rvzr/executor.py</code>, <code>rvzr/executor_km/</code> Public interface <code>Executor</code> Inputs <code>TestCaseProgram</code>, <code>InputData</code> Outputs <code>HTrace</code>"},{"location":"internals/architecture/exec/#executor","title":"Executor","text":"<p>The Executor runs test cases on real hardware and collects hardware traces (HTraces) using side-channel measurements. It uses a two-layer architecture: Python code communicates with a kernel module that performs measurements in kernel space.</p> <pre><code>Python (executor.py)\n  \u251c\u2500 X86IntelExecutor\n  \u251c\u2500 X86AMDExecutor\n  \u2514\u2500 ARM64Executor\n       \u2502\n       \u2502 /sys/rvzr_executor/ interface\n       \u25bc\nKernel Module (executor_km/)\n</code></pre>"},{"location":"internals/architecture/exec/#htrace-representation","title":"HTrace representation","text":"<p>The <code>HTrace</code> class (<code>rvzr/traces.py</code>) represents hardware traces collected during execution. The executor produces one <code>HTrace</code> object per program-input pair, meaning that for each <code>TestCaseProgram</code> execution with each <code>InputData</code> input, one <code>HTrace</code> is generated.</p> <p>Each <code>HTrace</code> encapsulates multiple measurements results (samples): This is because the executor typically repeats the execution several times and each execution produces one measurement sample. Such repeated measurements allow us to apply statistical methods when comparing noisy hardware traces (see Trace Analysis below).</p> <p>The structure of an <code>HTrace</code> is as follows:</p> <pre><code>HTrace\n  \u2514\u2500 Array[RawHTraceSample]\n       \u251c\u2500 trace       Main measurement (cache bitmap, timestamp, or registers)\n       \u2514\u2500 pfc0-pfc4   Performance counter values\n</code></pre>"},{"location":"internals/architecture/fuzz/","title":"Orchestration Module","text":"Module <code>rvzr/fuzzer.py</code> Public interface <code>Fuzzer</code> Inputs <code>Config</code>, <code>InstructionSet</code>, ASM Template Outputs Violation artifact, logs <p>The <code>Fuzzer</code> class is the main coordinator. It manages the core components (<code>CodeGenerator</code>, <code>DataGenerator</code>, <code>Model</code>, <code>Executor</code>, and <code>Analyser</code>) and orchestrates the fuzzing loop.</p>"},{"location":"internals/architecture/fuzz/#main-workflow","title":"Main workflow","text":"<pre><code>Fuzzer.start()\n  \u2514\u2500&gt; for each test case:\n        \u251c\u2500&gt; CodeGenerator.create_test_case() \u2192 TestCaseProgram\n        \u251c\u2500&gt; DataGenerator.generate() \u2192 List[InputData]\n        \u2514\u2500&gt; Fuzzer.fuzzing_round(program, inputs)\n              \u251c\u2500&gt; Model.trace_test_case() \u2192 List[CTrace]\n              \u251c\u2500&gt; Executor.trace_test_case() \u2192 List[HTrace]\n              \u251c\u2500&gt; Analyser.filter_violations() \u2192 List[Violation]\n              \u2514\u2500&gt; if violation: multi-stage filtering pipeline\n</code></pre>"},{"location":"internals/architecture/fuzz/#multi-stage-filtering","title":"Multi-stage filtering","text":"<p>When a potential violation is found, the Fuzzer runs it through several validation stages. Each stage modifies parameters and re-checks the violation to rule out false positives:</p> <ol> <li><code>fast</code> \u2014 Initial fast detection using minimal speculative nesting on the model side and small sample size on the executor side</li> <li><code>nesting</code> \u2014 Re-collect ctraces with the model using full speculative nesting. This rules out false positives caused by incomplete speculation modeling</li> <li><code>taint_mistake</code> \u2014 Re-collect ctraces for the boosted inputs to rule out boosting-based generation mistakes</li> <li><code>priming</code> \u2014 Perform a so-called \"priming test\" (swap the order of violating inputs) to rule out false positives caused by inconsistent microarchitectural state across executions</li> <li><code>noise</code> \u2014 Increase sample size on the executor side to increase statistical confidence and rule out noise-induced violations</li> <li><code>arch_mismatch</code> \u2014 Compare the architectural output (i.e., register/memory states) of the model and executor to rule out violations caused by functional mismatches (i.e., by bugs in the model or executor)</li> </ol> <p>If a violation survives all stages, Revizor saves a reproduction package (called \"violation artifact\") containing the test case, inputs, configuration, and detailed report.</p>"},{"location":"internals/architecture/fuzz/#fuzzer-variants","title":"Fuzzer variants","text":"<p>The <code>Fuzzer</code> class is abstract. There are several variants modifying the baseline logic:</p> <ul> <li><code>X86Fuzzer</code> / <code>ARM64Fuzzer</code> \u2014 Architecture-specific implementations</li> <li><code>ArchitecturalFuzzer</code> \u2014 Validates model correctness (i.e., performs stage 6 <code>arch_mismatch</code> for all test cases, even non-violating ones)</li> <li><code>ArchDiffFuzzer</code> \u2014 Completely discards the model, and instead compares two hardware executions, one with a normal test case and one with a speculation fence added after every instruction. This variant is used to detect speculation-induced architectural bugs, like zenbleed.</li> </ul>"},{"location":"internals/architecture/isa/","title":"Instruction Set Specification","text":"Module <code>rvzr/isa_spec.py</code> Public interface <code>InstructionSet</code> Inputs <code>base.json</code> Outputs <code>InstructionSet</code> <p>This module manages the instruction set available for fuzzing. It loads ISA definitions from a JSON file (<code>base.json</code>) and applies user-configured filters to create a pool of allowed instructions.</p> <p>Each instruction is represented by an <code>InstructionSpec</code> containing instruction name and category, operand specifications, and instruction properties.</p> <p>Processing pipeline:</p> <ol> <li>Load ISA specification from JSON</li> <li>Apply filters (allowlist, blocklist, categories, register restrictions)</li> <li>Remove duplicates</li> <li>Categorize instructions by type (control flow, memory access, etc.)</li> </ol>"},{"location":"internals/architecture/logging/","title":"Logging","text":"Module <code>rvzr/logs.py</code> Public interface <code>FuzzLogger</code>, etc. Inputs N/A Outputs Log messages (stdout, stderr) <p>Revizor uses a centralized logging system with configurable verbosity. The system uses the Borg pattern to share state across modules.</p> <p>Available logging modes:</p> <ul> <li>info \u2014 General messages and progress</li> <li>stat \u2014 Statistics</li> <li>dbg_* \u2014 Debug modes for specific components</li> </ul> <p>Logging components:</p> <ul> <li>Basic functions: <code>error()</code>, <code>warning()</code>, <code>inform()</code>, <code>dbg()</code></li> <li>Module-specific loggers: <code>FuzzLogger</code>, <code>GeneratorLogger</code>, <code>ISALogger</code>, <code>ExecutorLogger</code>, <code>AnalyserLogger</code></li> </ul>"},{"location":"internals/architecture/mini/","title":"Post-violation Analysis","text":"Module <code>rvzr/postprocessing/</code> Public interface <code>Minimizer</code> Inputs Violation artifact (.asm, .bin) Outputs Minimized test case and inputs <p>After confirming a violation, users can run post-processing to simplify the test case and identify the root cause. The postprocessing module applies minimization passes that reduce complexity while preserving the violation.</p> <p>Class hierarchy:</p> <pre><code>Minimizer\n  \u2514\u2500 Orchestrates passes, manages files\n\nBaseMinimizationPass\n  \u251c\u2500 Instruction passes (modify code)\n  \u251c\u2500 Data passes (modify inputs)\n  \u2514\u2500 Analysis passes (add annotations)\n</code></pre> <p>Instruction passes (operate on test case code):</p> <ul> <li><code>InstructionRemovalPass</code> \u2014 Remove instructions one at a time to find essential ones</li> <li><code>NopReplacementPass</code> \u2014 Replace with NOPs (preserves alignment)</li> <li><code>InstructionSimplificationPass</code> \u2014 Replace complex instructions with simpler ones</li> <li><code>ConstantSimplificationPass</code> \u2014 Simplify immediate values</li> <li><code>MaskSimplificationPass</code> \u2014 Simplify bitmasks</li> <li><code>LabelRemovalPass</code> \u2014 Remove unused labels</li> <li><code>FenceInsertionPass</code> \u2014 Insert fences to identify speculation boundaries</li> </ul> <p>Data passes (operate on inputs):</p> <ul> <li><code>DifferentialInputMinimizerPass</code> \u2014 Use delta debugging to find minimal byte differences</li> <li><code>InputSequenceMinimizationPass</code> \u2014 Reduce number of inputs</li> </ul> <p>Analysis passes (add annotations):</p> <ul> <li><code>AddViolationCommentsPass</code> \u2014 Annotate assembly with memory addresses from execution</li> </ul>"},{"location":"internals/architecture/model/","title":"Contract Tracing","text":"Module <code>rvzr/model.py</code> Public interface <code>Model</code> Inputs <code>TestCaseProgram</code>, <code>InputData</code> Outputs <code>CTrace</code>"},{"location":"internals/architecture/model/#model","title":"Model","text":"<p>The Model executes test cases according to a leakage contract and produces contract traces (CTraces). These represent the information expected to leak during execution, including speculative execution.</p> <p>Revizor supports two model backends:</p> <ul> <li>Unicorn: This backend is based on the Unicorn CPU emulator. It implements the contract by hooking into instruction execution and memory access events. Documentation is provided in Unicorn Backend.</li> <li>DynamoRIO: This backend uses DynamoRIO for dynamic binary instrumentation. It instruments the test case to insert hooks for tracing and speculation simulation. Documentation is provided in DynamoRIO Backend.</li> </ul> <p>Both implement the same interface defined by the abstract <code>Model</code> class.</p>"},{"location":"internals/architecture/model/#contract-trace-representation","title":"Contract Trace Representation","text":"<p>A <code>CTrace</code> is a sequence of typed observations representing leaked information:</p> <pre><code>CTrace\n  \u2514\u2500 List[CTraceEntry]\n       \u251c\u2500 mem    Memory address\n       \u251c\u2500 pc     Program counter\n       \u251c\u2500 val    Data value\n       \u251c\u2500 reg    Register value\n       \u2514\u2500 ind    Indirect branch target\n</code></pre> <p>CTraces use <code>xxhash</code> for fast equality checking, enabling efficient grouping into equivalence classes.</p>"},{"location":"internals/architecture/overview/","title":"Architecture Overview &amp; Code Structure","text":"<p>This document introduces Revizor's architecture and key components. It is designed to provide an overview of how the codebase is organized and how the main pieces work together.</p> <p>Prerequisites</p> <p>This document assumes familiarity with the concepts of side-channel attacks, speculative execution, and Speculation Contracts and Model-based Relational Testing (MRT).</p>"},{"location":"internals/architecture/overview/#how-revizor-works","title":"How Revizor Works","text":"<p>Revizor detects CPU security vulnerabilities using Model-based Relational Testing (MRT). The core idea is to compare what a CPU should leak (according to a leakage model) with what it actually leaks during execution.</p> <p>Basic process:</p> <ol> <li>Generate random assembly programs</li> <li>Execute them on both a leakage model and real hardware</li> <li>Compare the observed hardware behavior with the model's predictions</li> <li>If they match, the CPU behaves as expected (discard the test)</li> <li>If they differ, a potential vulnerability has been found</li> </ol> <p>The leakage model acts as a reference model of the expected CPU behavior. If the real CPU leaks more information than the model predicts (i.e., if it diverges from the reference), this indicates a potential security vulnerability. For details on how leakage models work, see Speculation Contracts.</p> <p>Revizor runs the following loop until it finds a violation or completes the configured number of test cases:</p> <p></p>"},{"location":"internals/architecture/overview/#1-initialization","title":"1. Initialization","text":"<p>This step runs once at startup. Revizor reads the fuzzing configuration, which specifies:</p> <ul> <li>Target CPU architecture</li> <li>ISA (instruction set) specification</li> <li>Which instructions to test</li> <li>Which side channels to monitor</li> <li>Other fuzzing parameters</li> </ul> <p>The <code>cli.py</code> module handles command-line arguments and creates the main objects: <code>InstructionSet</code> (from <code>isa_spec.py</code>), <code>Config</code> (from <code>config.py</code>), and <code>Fuzzer</code> (from <code>fuzzer.py</code>).</p>"},{"location":"internals/architecture/overview/#2-code-generation","title":"2. Code Generation","text":"<p>Each fuzzing round starts by generating a random test program. This is an assembly program with semi-random control flow, built from a pool of allowed instructions.</p> <p>The code generator can be configured to control the shape of the control flow graph, which instructions to include, and how often each instruction appears. It also (optionally) instruments the program to prevent faults like division by zero.</p> <p>The <code>Fuzzer</code> calls <code>CodeGenerator.create_test_case()</code> (in <code>code_generator.py</code>), which returns a <code>TestCaseProgram</code> object representing the generated assembly program.</p>"},{"location":"internals/architecture/overview/#3-data-generation","title":"3. Data Generation","text":"<p>Next, Revizor generates random inputs for the test program. Each input contains initial values for registers and memory. These values are pseudo-random but use fixed seeds for reproducibility.</p> <p>The <code>DataGenerator</code> class (in <code>data_generator.py</code>) creates these inputs and returns them as <code>InputData</code> objects. See binary formats for the structure of input data.</p>"},{"location":"internals/architecture/overview/#35-test-case-filtering-optional","title":"3.5 Test Case Filtering (Optional)","text":"<p>Some test cases are unlikely to reveal vulnerabilities, so Revizor can filter them out early to save time. This is optional and disabled by default.</p> <p>Two filters are available:</p> <ul> <li>Speculation filter: Uses performance counters to check if the test case triggers branch mispredictions. Without mispredictions, the test cannot expose speculative leaks.</li> <li>Observation filter: Compares the original test case with a \"fenced\" version (with serialization instructions added). If both produce identical traces, speculation left no observable effects.</li> </ul> <p>These filters are implemented in architecture-specific fuzzer classes (like <code>X86Fuzzer</code> in <code>rvzr/arch/x86/fuzzer.py</code>).</p>"},{"location":"internals/architecture/overview/#4-model-execution","title":"4. Model Execution","text":"<p>The model executes the test program with each generated input and produces contract traces (CTraces). These traces represent what the model predicts should leak during execution.</p> <p>The <code>Model</code> class (in <code>model.py</code>) provides two key methods:</p> <ul> <li><code>load_test_case()</code>: Loads the program into the model</li> <li><code>trace_test_case()</code>: Executes the program with each input and returns CTraces</li> </ul> <p>Revizor supports multiple model backends: Unicorn (CPU emulator) and DynamoRIO (dynamic instrumentation). Both implement the same interface.</p>"},{"location":"internals/architecture/overview/#5-hardware-execution","title":"5. Hardware Execution","text":"<p>The executor runs the test program on the target hardware with each input and collects hardware traces (HTraces). A hardware trace is a set of observable microarchitectural effects (like cache state or timing) caused by the test case execution. Traces are typically collected using side-channel techniques (e.g., Prime+Probe, Flush+Reload) or by reading performance counters.</p> <p>To ensure that the measurements reflect the test case execution (rather than noise), the executor creates a controlled measurement environment by disabling interrupts, flushing caches, and repeating executions multiple times.</p> <p>The <code>Executor</code> class (in <code>executor.py</code>) works through a kernel module (<code>executor_km/</code>) that performs measurements in kernel space. It provides the same interface as the model: <code>load_test_case()</code> and <code>trace_test_case()</code>.</p>"},{"location":"internals/architecture/overview/#6-trace-analysis","title":"6. Trace Analysis","text":"<p>The analyzer compares contract traces (what should leak) with hardware traces (what actually leaked) to detect violations. Instead of directly comparing traces, it uses an equivalence class approach.</p> <p>How it works:</p> <ol> <li>Group by contract: Inputs with identical CTraces form a ContractEqClass. According to the model, these inputs should be indistinguishable.</li> <li>Group by hardware: Within each ContractEqClass, inputs with similar HTraces form HardwareEqClasses. These inputs are actually indistinguishable on real hardware.</li> <li>Detect violations: If a ContractEqClass splits into multiple HardwareEqClasses, a violation has occurred. The model says the inputs should look the same, but hardware reveals differences between them.</li> </ol> <p>This approach focuses on information leakage rather than exact trace values, and it essentially implements a non-interference check (see Theoretical Foundations).</p> <p>The <code>Analyser</code> class (in <code>analyser.py</code>) implements this logic in its <code>filter_violations()</code> method.</p>"},{"location":"internals/architecture/overview/#7-post-violation-analysis","title":"7. Post-violation Analysis","text":"<p>When Revizor detects a potential violation, it runs additional tests to filter out false positives. These tests modify execution parameters and verify the violation still occurs. See post-violation tests for details.</p> <p>If the violation survives all filters, Revizor reports it to the user and saves reproduction artifacts. The user can then use minimization tools to simplify the test case and identify the root cause.</p> <p>The post-violation logic is implemented in <code>Fuzzer.fuzzing_round()</code>, and the <code>FuzzLogger</code> class handles reporting.</p>"},{"location":"internals/contributing/guidelines-code-style/","title":"Code Style","text":"<p>Please follow these coding standards when writing code for inclusion in Revizor.</p>"},{"location":"internals/contributing/guidelines-code-style/#python","title":"Python","text":"<ul> <li>Unless otherwise specified, follow PEP 8. But remember that PEP 8 is only a guide, so respect the style of the surrounding code as a primary goal.</li> <li>An exception to PEP 8 is our rules on line lengths. Don\u2019t limit lines of code to 79 characters if it means the code looks significantly uglier or is harder to read. We allow up to 100 characters.</li> <li>All files should be formatted using the <code>flake8</code> auto-formatter. Use all default settings except for the line width (<code>--max-line-length 100</code>)</li> <li>The Python and C files use 4 spaces for indentation, and YAML uses 2 spaces.</li> <li>The project repository includes an .editorconfig file. We recommend using a text editor with EditorConfig support to avoid indentation and whitespace issues.</li> <li>Use underscores, not camelCase, for variable, function and method names (i.e. poll.get_unique_voters(), not poll.getUniqueVoters()).</li> <li>Use InitialCaps for class names (or for factory functions that return classes).</li> <li>In docstrings, follow PEP 257.</li> </ul>"},{"location":"internals/contributing/guidelines-code-style/#c","title":"C","text":"<ul> <li>All files should be formatted using the <code>clang-format</code>. The settings are included into the <code>.clang-format</code> files in the directories with C files. Just run the formatter with: <code>clang-format -i *.c</code></li> </ul>"},{"location":"internals/contributing/guidelines-code-style/#misc","title":"Misc","text":"<ul> <li>Remove import statements that are no longer used when you change code. flake8 will identify these imports for you. If an unused import needs to remain for backwards-compatibility, mark the end of with <code># NOQA</code> to silence the flake8 warning.</li> <li>Systematically remove all trailing whitespaces from your code as those add unnecessary bytes, add visual clutter to the patches and can also occasionally cause unnecessary merge conflicts. Some IDE\u2019s can be configured to automatically remove them and most VCS tools can be set to highlight them in diff outputs.</li> </ul>"},{"location":"internals/contributing/guidelines-general/","title":"General Development Guidelines","text":""},{"location":"internals/contributing/guidelines-general/#testing","title":"Testing","text":"<p>To run automated tests you will need to install a few more dependencies:</p> <ul> <li>Bash Automated Testing System</li> <li>mypy</li> <li>flake8</li> </ul> <p>With the dependencies installed, you can run the tests with:</p> <pre><code>./tests/runtests.sh\n</code></pre> <p>Note that some of the acceptance tests are microarchitecture-dependent. These tests are labeled \"Detection\" (e.g., <code>\"Detection [spectre-type] Spectre V1; load variant\"</code>), and they may fail if the CPU under test does not have a given vulnerability. Generally, if a few of these tests fail, it is not a problem, but if all of them (or a significant portion) fail, it indicates an issue with the fuzzer.</p>"},{"location":"internals/contributing/guidelines-general/#submitting-patches","title":"Submitting Patches","text":"<p>To submit a patch, use the following procedure:</p> <ul> <li> <p>Fork Revizor on github:</p> <p>https://docs.github.com/en/github/getting-started-with-github/fork-a-repo</p> </li> <li> <p>Create a topic branch:</p> </li> </ul> <pre><code>git checkout -b my_branch\n</code></pre> <ul> <li>Make sure all tests pass (see Testing)</li> <li>Make sure your code follows the guidelines in Code Style</li> <li>Push to your branch</li> </ul> <pre><code>git push origin my_branch\n</code></pre> <ul> <li> <p>Initiate a pull request on github:</p> <p>https://docs.github.com/en/github/collaborating-with-issues-and-pull-requests/creating-a-pull-request</p> </li> <li> <p>Wait for the PR to get reviewed and merged</p> </li> </ul>"},{"location":"internals/contributing/guidelines-general/#contributor-license-agreement-and-code-of-conduct","title":"Contributor License Agreement and Code of Conduct","text":"<p>Most contributions require you to agree to a Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us the rights to use your contribution. For details, visit https://cla.opensource.microsoft.com.</p> <p>When you submit a pull request, a CLA bot will automatically determine whether you need to provide a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions provided by the bot. You will only need to do this once across all repos using our CLA.</p> <p>This project has adopted the Microsoft Open Source Code of Conduct. For more information see the Code of Conduct FAQ or contact opencode@microsoft.com with any additional questions or comments.</p>"},{"location":"internals/contributing/guidelines-git/","title":"Git Workflow Guidelines","text":""},{"location":"internals/contributing/guidelines-git/#git-messages","title":"Git Messages","text":"<p>We practice the following conventions for commit messages:</p> <pre><code>&lt;scope&gt;: [&lt;type&gt;] &lt;subject&gt;\n</code></pre> <p>Where:</p> <ul> <li><code>&lt;scope&gt;</code>: The scope of the change.</li> <li><code>&lt;type&gt;</code>: The type of the change.</li> <li><code>&lt;subject&gt;</code>: A short description of the change.</li> </ul>"},{"location":"internals/contributing/guidelines-git/#scopes","title":"Scopes","text":"<p>The following scopes are typical:</p> Scope Description <code>all</code> Changes that affect the entire project (e.g., major refactoring) <code>root</code> Root directory changes (e.g., readme, git, author list) <code>fuzz</code> Changes to the core fuzzer algorithm. <code>cli</code> Changes to the command-line interface. <code>exec</code> Changes to the executor. <code>model</code> Changes to the model. <code>analyser</code> Changes to the analyser. <code>mini</code> Changes to the postprocessor (i.e., minimizer). <code>code_gen</code> Changes to the program generator <code>data_gen</code> Changes to the input generator <code>tests</code> Changes to the tests <code>isa</code> Changes to the ISA loader or to <code>get_spec</code> files <p>If a commit covers several scopes, use the most relevant one.</p> <p>If a commit targets a specific architecture (e.g., x86), add the architecture to the scope (e.g., <code>fuzz/x86</code>).</p>"},{"location":"internals/contributing/guidelines-git/#types","title":"Types","text":"<p>Use one of the following types:</p> Type Description <code>feat</code> A new feature. <code>fix</code> A bug fix. <code>docs</code> Documentation changes. <code>chore</code> Changes to the build process or auxiliary tools. <code>ft</code> Fault tolerance changes (e.g., adding error handling or recovery mechanisms). <code>refact</code> Refactoring of the codebase. This includes code style change. <code>perf</code> Performance improvements. <code>revert</code> Reverts a previous commit. <p>If possible, try to use only these types. If you need to use a different type, please discuss it with a maintainer.</p>"},{"location":"internals/contributing/guidelines-git/#git-branches","title":"Git Branches","text":"<p>We practice the git workflow, with a few modifications.</p> <p></p> <p>We use the following branches for graduation:</p> <ul> <li><code>main</code>: The latest release. This branch should always be stable, and it is the last branch to receive changes.</li> <li><code>main-fixes</code>: Commits that go in the next maintenance release. This branch is created from the last release branch.</li> <li><code>dev</code>: The development branch. This branch is the first to receive changes.</li> </ul> <p>Commits should be merged upwards:</p> <ul> <li><code>dev</code> -&gt; <code>pre-release</code> -&gt; <code>main</code></li> <li>In case of hot fixes, <code>main-fixes</code> -&gt; <code>main</code> AND <code>main-fixes</code> -&gt; <code>pre-release</code></li> </ul> <p>For working on unstable code (e.g., progress on features or bug fixes), use either forks or feature branches. Use forks if you are the only one working on the feature, and use a pull request to merge the changes back into the main repository. Use a feature branch if multiple people are working on the feature, in which case name the branch <code>feature-&lt;name&gt;</code> or <code>bugfix-&lt;name&gt;</code>, and make sure to branch from the <code>dev</code> branch.</p> <p>The only exception is the <code>gh-pages</code> branch, which is used for the project's website. This branch is used by automated tools and should never be used for development.</p>"},{"location":"internals/model-backends/model-dr/","title":"DynamoRIO-based Model Backend","text":"<p>This document describes the DynamoRIO-based model. As any other model, this backend is responsible for collecting contract traces for generated test cases.</p>"},{"location":"internals/model-backends/model-dr/#design-overview","title":"Design Overview","text":"<p>This backend is composed of several parts:</p> <ul> <li>The Python adapter (<code>rvzr/model_dynamorio/model.py</code>) is responsible for receiving a test case from Revizor, transforming it into a format that can be executed by the backend, triggering the backend to execute the test case, and returning the collected contract traces to Revizor.</li> <li>The Test Case Loader (<code>rvzr/model_dynamorio/adapter.c</code>) is a C program that loads a test case program and a batch of inputs into its memory, and executes the test case program with each input in a sequence.</li> <li>The DynamoRIO components (<code>rvzr/model_dynamorio/backend</code>) are executed together with the test case loader, and they instrument the loader binary to collect contract traces.</li> </ul> <p>These components can be roughly divided into the instrumentation-time components that are responsible for modifying the binary, and execution-time components that implement the model logic (i.e., the contract).</p> <p></p>"},{"location":"internals/model-backends/model-dr/#python-adapter","title":"Python Adapter","text":"<p>Revizor communicates with the backend through a Python adapter (<code>rvzr/model_dynamorio/model.py:DynamoRIOModel</code>).</p> <p>At the beginning of the fuzzing process, Revizor configures the backend by calling <code>configure_clauses</code> method. This configuration will be later passed down to the backend when the test case is executed.</p> <p>During the fuzzing process, Revizor sends test cases to the backend by calling <code>load_test_case</code> method, and then triggers the backend to execute the test case by calling <code>trace_test_case</code> method. Internally, <code>trace_test_case</code> will call the backend to execute the test case and collect the contract traces. The adapter will then parse the traces and return them back to the caller.</p> <p>The <code>trace_test_case</code> method implements the following algorithm:</p> <ul> <li>Convert test case program and inputs into RCBF and RDBF files, respectively</li> <li>For each input, call the test case loader with the RCBF and RDBF files. Attach the DynamoRIO backend to the call so that the binary instrumentation is performed: <pre><code>~/.local/dynamorio/drrun -c ~/.local/dynamorio/libdr_model.so --tracer &lt;observation-clause&gt; -- ~/.local/dynamorio/adapter &lt;rcbf&gt; &lt;rdbf&gt;\n</code></pre></li> <li>Parse contract traces from the backend and convert them into <code>CTrace</code> objects</li> <li>Return the list of collected <code>CTrace</code> objects to the caller (usually, <code>fuzzer.py</code>)</li> </ul>"},{"location":"internals/model-backends/model-dr/#test-case-loader","title":"Test Case Loader","text":"<p>Since the test cases produced by Revizor are raw binaries, they cannot be directly executed (e.g., they don't have <code>libc</code> linked). The test case loader (<code>rvzr/model_dynamorio/adapter.c</code>) is a simple C program that fixes this issue by providing a wrapper around the test case binary.</p> <p>The loader implements the following algorithm:</p> <ul> <li>Receive the test case binary and an input from the Python adapter via CLI arguments</li> <li>Load the test case binary and the input into dedicated memory regions</li> <li>Print the addresses of the test case and input memory regions (for trace normalization)</li> <li>Initialize registers based on the input</li> <li>Jump to the test case binary entry point</li> <li>Return</li> </ul>"},{"location":"internals/model-backends/model-dr/#dynamorio-tool","title":"DynamoRIO Tool","text":"<p>The DynamoRIO tool (<code>rvzr/model_dynamorio/backend</code>) is responsible for instrumenting the test case loader binary and collecting contract traces.</p>"},{"location":"internals/model-backends/model-dr/#implementation-overview","title":"Implementation Overview","text":"<p>All instrumentation logic is implemented as a DynamoRIO client. In particular, <code>model.cpp</code> contains the event callbacks that are executed at instrumentation time, while <code>dispatcher.cpp</code> contains the body of the callbacks that are inserted by the DR client and are executed before every instruction at runtime. Finally, the <code>Dispatcher</code> object holds the state that is shared between instrumentation-time callbacks and execution-time callbacks.</p> <p>The following figure provides an overview of the implementation.</p> <p></p> <ol> <li><code>dr_client_main()</code> is responsible of installing the initial instrumentation callbacks to hook all relevant DR events (<code>module_load</code>, <code>bb_translation</code>, exceptions and the <code>exit</code> event)</li> <li><code>dr_client_main()</code> also sets the name of the function to instrument (passed by <code>cli.cpp</code>)</li> <li>on <code>module_load</code>, the instrumentation checks for the presence of the target function in the loaded module. If found, the callback adds a <code>drwarp</code> callback (<code>event_instrumentation_start</code>) which will be executed at the start of the target function</li> <li>once a call to the target function is found, the <code>event_instrumentation_start</code> will save the return address in a global object (<code>instrumented_func</code>) and call <code>start()</code> on the dispatcher</li> <li>from that moment on, every translated basic block is instrumented by our client, in particular:<ul> <li>a <code>dispatch_callback()</code> is inserted before every instruction</li> <li>at the function exit point (i.e. the previously saved return addres) an <code>exit_callback</code> is inserted</li> </ul> </li> <li>these callbacks are executed at runtime with the following effects:<ul> <li>the <code>dispatch_callback()</code> implements the observation and execution clauses (see next section)</li> <li>the <code>exit_callback()</code> checks the current speculation state before exiting:<ul> <li>speculative exits cause a rollback</li> <li>architectural exit causes the instrumentation to stop</li> </ul> </li> </ul> </li> </ol> <p>Finally, exceptions and the <code>exit</code> event are also forwarded to the Dispatcher:</p> <ul> <li>Speculative exceptions will cause a rollback, while architectural ones are forwarded to the target program</li> <li>The exit event stops instrumentation and flushes all logs (in case the exit callback has not been executed architecturally)</li> </ul>"},{"location":"internals/model-backends/model-dr/#instrumentation-components","title":"Instrumentation Components","text":"<p>The instrumentation components modify the binary of the test case loader by adding a call to the function <code>dispatch_callback</code> before every instruction in the binary (or more specifically, every instruction in the <code>test_case_entry</code> function of the loader).</p> <p>The tool interacts with DynamoRIO through the <code>model.cpp</code> module. This module registers an event for entering the <code>test_case_entry</code>, which triggers the flush of the internal DynamoRIO code fragment cache and the start of instrumentation. The module also registers an event for every instruction in the <code>test_case_entry</code>, and the event in turn calls the <code>Dispatch::instrument_instruction()</code>. Finally, exceptions are hooked and passed to the dispatcher through <code>Dispatch::handle_exception()</code>, which can decide to either handle the signal (e.g. on speculative paths) or forward it to the test case (e.g. architectural exceptions).</p> <p>The <code>Dispatch</code> class implements the actual instrumentation logic. When the <code>instrument_instruction()</code> method is called, it inserts a clean call to the <code>dispatch_callback</code> function before the instruction. The call receives the PC and opcode of the instruction as arguments. DynamoRIO also automatically saves the complete register state before the call, thus making it available to <code>dispatch_callback</code>.</p>"},{"location":"internals/model-backends/model-dr/#execution-time-components","title":"Execution-Time Components","text":"<p>The execution-time components are responsible for implementing the contract logic, and are triggered by the <code>dispatch_callback</code> function. At the current state of the backend, the dispatch callback invokes only two classes, Tracer and Speculator, that implement the observation and execution clauses, respectively. Optionally, each component can log additional events, e.g. speculation rollbacks or the current register state, through a shared <code>Logger</code> component.</p> <p>Subclasses of <code>TracerABC</code> record contract-relevant information via <code>observe_instruction</code> and <code>observe_mem_access</code> methods. E.g., <code>TracerCT</code> implements <code>CT</code> observation clause by recording the PC of instructions upon <code>observe_instruction</code> and the address of memory accesses upon <code>observe_mem_access</code>. Currently, <code>observe_exception</code> simply adds a special entry to the trace to indicate that the program ended due to an (architectural) exception.</p> <p>Subclasses of <code>SpeculatorABC</code> implement the contract speculation logic. E.g., <code>SpeculatorCond</code> implements <code>speculate_instruction</code>. When this method is called with a branch instruction, the class takes a checkpoint of the process state, flips the branch condition (i.e., modified <code>FLAGS</code> register), and continues the execution. During the simulated speculation, each call to <code>speculate_instruction</code> counts the number of executed instructions, and when the number reaches the limit (e.g., 256), the class restores the checkpoint and continues the execution from the original state. (Actually, the algorithm is more complex, but this is the general idea.)</p> <p>When the instrumentation ends (according to <code>model.cpp</code>), the tracer's <code>tracing_finalized</code> method is called, during which any remaining traces are flushed into the trace file, together with an \"End Of Trace\" entry. The Python adapter will then read the trace file, decode it, and return the corresponding CTrace to Revizor.</p>"},{"location":"internals/model-backends/model-dr/#standalone-usage","title":"Standalone Usage","text":"<p>The DR tool can be used as a standalone tool to collect the runtime trace of any program, independently from the rest of Revizor's infrastructure.</p> <p>A typical usage is for example:</p> <pre><code>~/.local/dynamorio/drrun -c ~/.local/dynamorio/libdr_model.so --tracer &lt;observation-clause&gt; --speculator &lt;speculation-clause&gt; -- ls /dev/null\n</code></pre> <p>By default, this will instrument <code>ls</code> starting from <code>__libc_start_main</code> until the end of the program, run it with <code>/dev/null</code> as an argument, and generate a binary file called <code>rvzr_trace.dat</code> that contains the collected trace. Other flags can be printed using <code>~/.local/dynamorio/drrun -c ~/.local/dynamorio/libdr_model.so -h</code></p> <p>The trace file location can be changed by adding <code>--trace-output &lt;PATH&gt;</code>. Additionally, the tool can also dump the trace in human-readable format to STDOUT using the <code>--print-trace</code> flag.</p> <p>To decode and analyze the trace file, downstream tools should always use the <code>TraceDecoder</code> class provided by <code>trace_decoder.py</code>. For internal usage, this module also provides a simple entrypoint for trace printing:</p> <pre><code>python3 trace_decoder.py rzvr_trace.dat\n</code></pre>"},{"location":"internals/model-backends/model-dr/#debugging","title":"Debugging","text":"<p>Attaching a debugger like GDB to the DR tool might not always be the best debugging option, as the program has three separate states:</p> <ol> <li>the state of the program being instrumented (e.g. <code>ls</code>)</li> <li>the state of the DR client (<code>libdr_model.so</code>) instrumentation</li> <li>the state of DynamoRIO itself (<code>drrun</code>)</li> </ol> <p>More information about debugging DR clients can be found here.</p> <p>For our instrumentation, other (possibly simpler) options are available:</p> <ol> <li>Inspecting Debug Traces: the DR tool can optionally log extra information, e.g. the complete state of the register file before each instruction, each value being read and written to memory, and speculation events like checkpoints are rollbacks, in a separate debug trace:<ul> <li>This option can be enabled using <code>--log-level &lt;N&gt;</code></li> <li>By default, the tool will dump debug entries to <code>rzvr_dbg_trace.dat</code> in binary format; to change the path of the debug trace file use <code>--debug-output &lt;PATH&gt;</code></li> <li><code>--print-debug-trace</code> can be used to pretty-print debug entries to STDOUT during execution</li> <li><code>trace_decoder.py</code> also provides a decoder for debug entries</li> <li>WARNING: debug traces can become very big, especially for nested speculation</li> </ul> </li> <li>Running DynamoRIO with logging: DynamoRIO can also produce logs (see DR documentation):</li> </ol> <pre><code>~/.local/dynamorio/drrun -debug -loglevel 3 -c ~/.local/dynamorio/libdr_model.so --tracer &lt;observation-clause&gt; --speculator &lt;speculation-clause&gt; -- ls /dev/null\n</code></pre>"},{"location":"internals/model-backends/model-unicorn/","title":"Unicorn Backend","text":"<p>Unicorn backend architecture:</p> <pre><code>UnicornModel (main orchestrator)\n  \u251c\u2500 UnicornTracer            Records observations (PC, memory addresses, etc.)\n  \u251c\u2500 UnicornSpeculator        Simulates speculative execution\n  \u251c\u2500 UnicornTaintTracker      Tracks data flow for boosted input generation\n  \u251c\u2500 ExtraInterpreter         Handles features Unicorn doesn't support\n  \u2514\u2500 InstructionCoverage      Tracks which instructions were tested\n</code></pre> <p>Key components:</p> <ul> <li><code>UnicornModel</code>:   Manages the emulator and coordinates components through hooks on instruction and memory events.</li> <li><code>UnicornTracer</code>:   Implements the observation clause of the contract. Different tracers record different information (program counters, memory addresses, data values).</li> <li><code>UnicornSpeculator</code>:   Implements the speculation clause using checkpoint-rollback mechanisms. When speculation triggers (branch misprediction, CPU exception), it saves state and executes speculatively up to a window limit (default 250 instructions). It rolls back on serializing instructions or window expiration.</li> <li><code>UnicornTaintTracker</code>:   Performs dynamic taint analysis to identify which input bytes affect the contract trace. Used for boosted input generation.</li> </ul>"},{"location":"intro/00_start_here/","title":"Getting started","text":"<p>New to Revizor? Or to side-channel testing in general? You came to the right place: read this material to quickly get up and running.</p>"},{"location":"intro/00_start_here/#introductory-materials","title":"Introductory Materials","text":"<ul> <li>Revizor at a Glance: Understand what Revizor is, what problems it solves, and see a quick example of violation detection.</li> <li>Installation Guide: Get Revizor installed on your system and verify your setup.</li> <li>Core Concepts: Learn about contracts, traces, speculation, and other fundamental concepts needed to use Revizor effectively.</li> <li>Tutorial Series: Follow a series of hands-on tutorials that walk you through running your first tests, detecting violations, and rump up all the way to root-cause analysis and design of custom campaigns.</li> <li>Glossary: A quick reference for key terms used throughout the documentation.</li> </ul>"},{"location":"intro/00_start_here/#academic-deep-dives","title":"Academic Deep Dives","text":"<p>Interested in the academic research behind Revizor? Check out these papers:</p> <ol> <li>Original paper that introduced the concept of Model-based Relation Testing as well as the Revizor tool: \"Revizor: Testing Black-box CPUs against Speculation Contracts\"</li> <li>Theoretical foundations of leakage contract: \"Hardware-software contracts for secure speculation\"</li> <li>Accessible summary of the two papers above, in a journal format: \"Revizor: Testing Black-box CPUs against Speculation Contracts\". In IEEE Micro, 2023.</li> <li>Paper that introduced speculation filtering, observation filtering, and contract-based input generation: \"Hide and Seek with Spectres: Efficient discovery of speculative information leaks with random testing\"</li> <li>Paper that introduced exception-based testing (i.e., focus on Meltdown, Foreshadow) into Revizor: \"Speculation at Fault: Modeling and Testing Microarchitectural Leakage of CPU Exceptions.\"</li> <li>Paper that introduced testing of cross-VM and user-kernel leaks in Revizor, as well as presented TSA attacks on AMD CPUs: \"Enter, Exit, Page Fault, Leak: Testing Isolation Boundaries for Microarchitectural Leaks\"</li> </ol>"},{"location":"intro/00_start_here/#need-help","title":"Need Help?","text":"<p>If you have any questions or need further assistance, please reach out to the Revizor community through our GitHub repository or via our Zulip chat.</p>"},{"location":"intro/01_overview/","title":"Revizor at a Glance","text":""},{"location":"intro/01_overview/#what-is-revizor","title":"What is Revizor?","text":"<p>Revizor is a security-oriented fuzzer that detects microarchitectural information leaks in CPUs\u2014the vulnerabilities behind attacks like Spectre and Meltdown. It tests processors \"blindly,\" requiring no prior knowledge of specific flaws or hardware internals. Instead, it compares actual CPU behaviour against a leakage contract: a specification defining known sources of information leakage. Any discrepancy reveals a potential vulnerability.</p>"},{"location":"intro/01_overview/#what-problems-does-revizor-solve","title":"What Problems Does Revizor Solve?","text":"<p>Modern CPUs achieve their speed through speculative execution, out-of-order processing, complex caching, and other microarchitectural optimizations. These optimizations create side channels\u2014timing variations, cache-state changes, buffer contentions\u2014that can leak sensitive data. Such leaks are notoriously difficult to catch: they cause no crashes, depend on precise timing, and emerge only under specific conditions. Revizor automates the detection of these elusive side-channel leaks.</p> <p>Specifically, Revizor addresses several key challenges:</p> <ul> <li>Automated discovery: Finding side-channel attacks manually demands deep (often undocumented) microarchitectural knowledge and extensive trial-and-error. Revizor automates this process, systematically exploring the CPU's behaviour by probing the microarchitecture with lots of automatically generated test cases.</li> <li>Variant analysis: Side-channel vulnerabilities spawn many variants. Revizor can search for new attack vectors that might bypass existing patches.</li> <li>Validation of mitigations: Vendor patches meant to close side channels have sometimes proven incomplete. Revizor verifies whether fixes actually eliminate the leakage.</li> </ul>"},{"location":"intro/01_overview/#quick-example-detecting-spectre-v1","title":"Quick Example: Detecting Spectre V1","text":"<p>To illustrate how Revizor works, consider a simple fuzzing campaign that will lead to a detection of a known vulnerability in most modern CPUs, namely Spectre V1.</p> <p>Prerequisites</p> <p>Before running this example, ensure you have Revizor installed and set up correctly. Follow the Installation Guide if you haven't done so already.</p> <p>We will use a configuration file in <code>demo/detecting-v1.yaml</code>. This config file tells Revizor to test a small subset of x86-64 ISA (arithmetic instructions + conditional branches) against a contract that states that the CPU should not speculate and should only leak information about loads, stores, and the program counter. As most modern CPUs implement branch prediction, we expect to see a violation of this contract.</p> <p>Run the fuzzer with the following command:</p> <pre><code>$ rvzr fuzz -s base.json -n 1000 -i 100 -c demo/detecting-v1.yaml -w ./\n</code></pre> <p>After a short while, you should see output similar to this:</p> <pre><code>INFO: [prog_gen] Setting program_generator_seed to random value: 562112\n\nINFO: [fuzzer] Starting at 14:00:51\n13    ( 2%)| Stats: Cls:100/100,In:200,R:9,SF:5,OF:6,Fst:2...\n\n================================ Violations detected ==========================\nViolation Details:\n\n-----------------------------------------------------------------------------------\n                             HTrace                              | ID:71  | ID:171|\n-----------------------------------------------------------------------------------\n^................^..^.....^.....................^.....^......... | 599    | 0     |\n^...................^.....^..................................... | 28     | 23    |\n^................^..^.....^.......^...^......................... | 0      | 604   |\n\n\n================================ Statistics ===================================\n\nTest Cases: 14\nInputs per test case: 200.0\nViolations: 1\nEffectiveness:\n  Total Cls: 100.0\n  Effective Cls: 100.0\nDiscarded Test Cases:\n  Speculation Filter: 5\n  Observation Filter: 6\n  Fast Path: 2\n  Max Nesting Check: 0\n  Tainting Check: 0\n  Early Priming Check: 0\n  Large Sample Check: 0\n  Priming Check: 0\n\nDuration: 52.1\nFinished at 14:01:43\n</code></pre> <p>This message indicates that Revizor found a violation of the specified contract, and the tool will store the corresponding violation artifact in <code>./violation-&lt;timestamp&gt;/</code>.</p> <p>What happened here is that Revizor generated a series of random test programs, executed them on the target CPU and the reference model that implement the contract, collected the side-channel observations on both sides, and compared them. In this case, one of the generated test programs produced two different hardware traces for two different inputs while the model (contract) produced the same trace for both inputs. This discrepancy indicates that the CPU leaked information through microarchitectural side channels in a way that violates the specified contract.</p> <p>The corresponding program and the inputs are stored in the violation artifact (<code>./violation-&lt;timestamp&gt;/</code>), and it will contain an assembly file <code>program.asm</code> that surfaced a violation, a sequence of inputs <code>input_*.bin</code> to this program, and some details about the violation in <code>report.txt</code>.</p> <p>If we inspect the assembly code in <code>program.asm</code> and do an analysis of the violation, we will most likely find that it is a gadget that implements a typical Spectre V1 pattern: a conditional branch and a speculative memory access that leaks data through the cache. (This is a most likely outcome because the pattern is statistically very common for the given configuration). For example, the program may look like this (simplified for illustration):</p> <pre><code>.section .data.main\n...\njnp .bb_0.1  // conditional branch\njmp .exit_0\n.bb_0.1:\n    ...\n    or byte ptr [r14 + rcx], al  // data-dependent memory access\n    ...\n.exit_0:\n.test_case_exit:\n</code></pre> <p>On violation analysis</p> <p>This example was intentionally chosen to have a straightforward output that directly corresponds to a known vulnerability pattern. In practice, analyzing violations can be more complex, especially for novel or less understood leaks. We won't go into the details of the analysis here as it is a relatively complex topic; refer to the this guide if you want to dive into the details.</p> <p>The power of this approach is that Revizor doesn't need to know the specific vulnerability it's looking for. It simply tests whether the CPU matches the expected security specification. When it finds a discrepancy, that's a potential vulnerability worth investigating.</p>"},{"location":"intro/01_overview/#whats-next","title":"What's Next?","text":"<p>Now that you understand what Revizor is and what it does, here are your next steps:</p> <ul> <li>Dive Deeper into Concepts: For a more detailed explanation of the information flow analysis used in Revizor, the concepts of leakage contracts, and other related topics, see the Core Concepts Guide.</li> <li>Follow a Tutorial: Our step-by-step tutorial series guides you through detecting your first vulnerability, understanding the results, and designing effective fuzzing campaigns.</li> <li>Explore the Glossary: Familiarize yourself with key terms and definitions in the Glossary to better understand Revizor's terminology (we have quite a few unique terms!).</li> <li>Get Help: If you run into issues or have questions, visit our FAQ for common questions, or join the discussion on our GitHub Discussions page.</li> </ul>"},{"location":"intro/02_install/","title":"Installation","text":"<p>Warning: Revizor runs randomly-generated code in kernel space. This means that a misconfiguration (or a bug) can crash the system and potentially lead to data loss. Make sure you're not running Revizor on a production machine, and that you have a backup of your data.</p>"},{"location":"intro/02_install/#1-requirements","title":"1. Requirements","text":"<ul> <li> <p>Architecture: Revizor supports Intel and AMD x86-64 CPUs. We have experimental support for ARM CPUs (see <code>arm-port</code> branch) but it is at very early stages, so use it on your own peril.</p> </li> <li> <p>No virtualization: You will need a bare-metal OS installation. Testing from inside a VM is not supported.</p> </li> <li> <p>OS: The target machine has to be running Linux v4.15 or later.</p> </li> </ul>"},{"location":"intro/02_install/#2-python-package","title":"2. Python Package","text":"<p>The preferred installation method is using <code>pip</code> within a virtual environment. The python version must be 3.9 or later.</p> <pre><code>sudo apt install python3.9 python3.9-venv\n/usr/bin/python3.9 -m pip install virtualenv\n/usr/bin/python3.9 -m virtualenv ~/venv-revizor\nsource ~/venv-revizor/bin/activate\npip install revizor-fuzzer\n</code></pre>"},{"location":"intro/02_install/#3-executor","title":"3. Executor","text":"<p>In addition to the Python package, you will need to build and install the executor, which is a kernel module.</p> <pre><code># building a kernel module require kernel headers\nsudo apt-get install linux-headers-$(uname -r) linux-headers-generic\n\n# get the source code\ngit clone https://github.com/microsoft/sca-fuzzer.git\n\n# build executor\ncd sca-fuzzer/rvzr/executor_km\nmake uninstall  # the command will give an error message, but it's ok!\nmake clean\nmake\nmake install\n</code></pre>"},{"location":"intro/02_install/#4-optional-dynamorio-backend","title":"4. (Optional) DynamoRIO Backend","text":"<p>If you want to use the DynamoRIO-based model, it has to be installed separately:</p> <pre><code># install dependencies\nsudo apt-get install cmake g++ g++-multilib doxygen git zlib1g-dev libunwind-dev libsnappy-dev liblz4-dev\n\n# install DynamoRIO and the model\nmake -C rvzr/model_dynamorio\n\n# check installation\n~/.local/dynamorio/drrun -c ~/.local/dynamorio/libdr_model.so --list-tracers -- ls\n# expected output:\n#   ct\n#   ...\n#   /dev/null\n</code></pre>"},{"location":"intro/02_install/#5-download-isa-spec","title":"5. Download ISA spec","text":"<pre><code>rvzr download_spec -a x86-64 --extensions ALL_SUPPORTED --outfile base.json\n\n# Alternatively, use the following command to include system instructions;\n# however, mind that testing these instructions may crash the system if misconfigured!\n# rvzr download_spec -a x86-64 --extensions ALL_AND_UNSAFE --outfile base.json\n</code></pre>"},{"location":"intro/02_install/#6-test-the-installation","title":"6. Test the Installation","text":"<p>To make sure that the installation was successful, run the following command:</p> <pre><code>./tests/quick-test.sh\n\n# The expected output is:\nDetection: OK\nFiltering: OK\n</code></pre> <p>If you see any other output, check if the previous steps were executed correctly. If you still have issues, please open an issue.</p>"},{"location":"intro/02_install/#7-optional-system-configuration","title":"7. (Optional) System Configuration","text":"<p>External processes can interfere with Revizor's measurements. To minimize this interference, we recommend the following system configuration:</p> <ul> <li>Disable Hyperthreading (BIOS option);</li> <li>Disable Turbo Boost (BIOS option);</li> <li>Boot the kernel on a single core (add <code>-maxcpus=1</code> to Linux boot parameters).</li> </ul> <p>If you skip these steps, Revizor may produce false positives, especially if you use a low value for <code>executor_sample_sizes</code> for measurements. However, a large sample size (&gt; 300-400) usually mitigates this issue.</p>"},{"location":"intro/03_primer/","title":"Primer: Speculation Contracts and Model-Based Relational Testing","text":"<p>Below is a brief primer on the theoretical foundations of speculation contracts and model-based relational testing\u2014concepts that underlie the Revizor tool. This primer provides a high-level overview of the topic, introducing the concepts of noninterference, speculation contracts, and model compliance.</p> <p>This document is intended for those new to the topic, particularly people without a background in information-flow analysis. For a more detailed and technical explanation, refer to the original contracts paper.</p>"},{"location":"intro/03_primer/#information-flow-properties","title":"Information-Flow Properties","text":"<p>We will start with the basics: the concepts of confidentiality and noninterference, which are fundamental to understanding how speculation contracts work.</p> <p>Traditionally, security mechanisms like access control and encryption have focused on protecting data at rest or in transit. However, these mechanisms do not address the problem of information flow within a system. For example, consider a program that reads a secret input and then writes it to a public output, such as a web server that logs failed login attempts along with the username and masked password entered. Even if the program is secure in the sense that it does not allow unauthorized access to the secret data, it may still leak the secret through its public output, such as logging \"User admin failed login with password starting with 'P@ss'\" \u2014 revealing partial information about the secret password. This is where information-flow security comes into play.</p> <p>Information-flow security is concerned with how data moves through a computation and how it can be observed by an attacker. The goal is to ensure that secret information does not leak to observers who are unauthorized to access it. An end-to-end confidentiality policy might be stated as: \u201cNo secret input data can be inferred by an attacker through observations of system output.\u201d In other words, even if an adversary can see all public outputs of a computation, they should learn nothing about the secret inputs.</p> <p>Information-flow properties generally classify program variables or inputs/outputs into security levels (e.g., <code>Secret</code> and <code>Public</code>). The key property for confidentiality is that no information flows from Secret to Public. But how can information flow? There are two primary routes:</p> <ul> <li> <p>Explicit flows: These occur when confidential data is directly assigned or passed into a public variable or output. For example, in code, writing <code>public = secret</code> is an explicit flow from a secret variable to a public variable (an obvious violation of confidentiality). Any mechanism that directly transfers the bits of a secret into a publicly observable sink is an explicit flow. Such flows are usually straightforward to detect.</p> </li> <li> <p>Implicit flows: These occur indirectly, through the control structure of the program. An implicit flow arises when the control path taken by a program (e.g., which branch of an <code>if</code> or how many loop iterations) depends on a secret, thereby implicitly leaking information.</p> </li> </ul> Example 1: Implicit Flow <p>Consider this pseudocode example:</p> <pre><code>if (Sec == 0) {\n    Pub = 0;\n} else {\n    Pub = 1;\n}\n</code></pre> <p>Here <code>Sec</code> is a secret input and <code>Pub</code> is a public output. There is no direct assignment of <code>Sec</code> to <code>Pub</code>. However, an observer of <code>Pub</code> can deduce information about <code>Sec</code>. In fact, this program sets <code>Pub</code> to 0 if <code>Sec</code> was 0; otherwise, it sets <code>Pub</code> to 1\u2014effectively copying the one-bit information \u201cis Sec zero?\u201d into <code>Pub</code>. This is an implicit flow of information from <code>Sec</code> to <code>Pub</code> through the control structure (the <code>if</code> condition on <code>Sec</code>).</p>"},{"location":"intro/03_primer/#noninterference-definition-and-examples","title":"Noninterference: Definition and Examples","text":"<p>Noninterference is a formal property that captures the idea of perfect confidentiality: changes in secret data have no observable effect on public outputs. This property can be formalized as: \"a system is noninterferent if variations in Secret inputs cause no differences in Public outputs\". Equivalently, confidential inputs do not interfere with the publicly visible state of the system.</p> <p>To make this more concrete, imagine we run a program twice with two different secret inputs but the same public inputs. If no attacker can distinguish the two runs by observing anything public, then the program satisfies the noninterference property. The \u201cattacker\u201d here is assumed to have complete access to all public outputs, which are formalized as a function <code>PublicOut</code>:</p> <pre><code>output = PublicOut(Sec, Pub)\n</code></pre> <p>Noninterference essentially demands that for any two secrets <code>Sec1</code> and <code>Sec2</code> and any public input <code>Pub</code>, the program\u2019s behavior from an attacker\u2019s perspective is identical when run on <code>(Sec1, Pub)</code> versus <code>(Sec2, Pub)</code>:</p> Definition 1: Noninterference A program <code>P</code> is noninterferent if, for allpublic inputs <code>Pub</code> and all pairs of secret inputs <code>Sec1</code>, <code>Sec2</code> it holds that <code>PublicOut(P, Sec1, Pub) = PublicOut(P, Sec2, Pub)</code>. <p>Here are some examples to illustrate this principle:</p> Example 2: Interfering program <p>Suppose our program simply copies a secret to output:</p> <pre><code>void copy(int* sec, int* output) {\n    *output = *sec;\n}\n</code></pre> <p>Running it with two different secrets clearly yields different public outputs (e.g., <code>output</code> becomes 5 in one run and 7 in another). An attacker would distinguish these runs, so the program is not noninterferent\u2014it blatantly leaks information.</p> Example 3: Noninterfering program <p>A trivial example of a noninterferent program is one that produces no output dependent on the secret. For instance:</p> <pre><code>void assign_zero(int* sec, int* output) {\n    *output = 0;\n}\n</code></pre> <p>This program ignores secret <code>sec</code> entirely and always sets the public output <code>output</code> to 0. No matter what the secret input is, the public output is constant (0), so an attacker gains no information about <code>sec</code>. Indeed, any two runs are indistinguishable (both runs output 0). This satisfies noninterference (albeit by doing nothing useful with the secret).</p> Example 4: Allowed benign dependency <p>It is possible for a program to use secret data internally yet still be noninterferent as long as the final public outputs don\u2019t reveal those secrets. For instance:</p> <pre><code>void mask_secret(int* sec, int* output) {\n    int temp = *sec;\n    temp = temp * 0;   // multiply secret by 0\n    *output  = temp;\n}\n</code></pre> <p>Here the program did read the secret (<code>sec</code>) and even manipulated it, but it \u201cwashed out\u201d the secret by multiplying by 0. The value assigned to <code>output</code> is always 0. From an external view, this is just like the previous example\u2014no dependence of <code>output</code> on <code>sec</code>. Noninterference is concerned only with what can be observed by the attacker, not with whether the program internally used the secret. As long as any use of the secret eventually has no effect on outputs, the policy holds.</p> <p>Naturally, this example is not useful either, as it does nothing with the secret. In practice, however, there are techniques to ensure noninterference while still making use of secret data for useful computations. We won't go into these techniques here as they are beyond the scope of this primer.</p> <p>One important insight is that noninterference is relative to a given specification of what is \u201cobservable.\u201d If you consider only the functional outputs as observable, a program might be noninterferent in that model. But if in reality the attacker can observe more (e.g., the execution time of a program), then the program that was secure in theory might be insecure in practice. This leads us to examine how side channels break the assumptions of basic noninterference.</p>"},{"location":"intro/03_primer/#beyond-direct-outputs-side-channels","title":"Beyond Direct Outputs: Side Channels","text":"<p>The original works on information-flow properties focused on direct outputs of a program (e.g., writing to a file or a network socket). However, in practice, attackers can extract information from more than just the \u201cofficial\u201d outputs of a program. For example, the attacker might observe how long a computation takes or measure the power consumption of a device. These additional sources of information are called side channels. Side channels are unintended channels through which secret data can be inferred by observing the system\u2019s behavior, even if the direct outputs are secure.</p> <p>These side channels can reveal information about the secret inputs, and so we must include them in the definition of noninterference. Similarly to how we defined <code>PublicOut(Sec, Pub)</code> as the observable output, we can define <code>Trace</code> as the observable side-channel information for a given program <code>P</code>.</p> <pre><code>trace = Trace(P, Sec, Pub)\n</code></pre> <p>For example, a trace might be the execution time of the program or its cache access pattern.</p> <p>Noninterference then requires that the traces of two runs with different secrets - <code>(Sec1, Pub)</code> versus <code>(Sec2, Pub)</code> - are indistinguishable to an attacker. This is a stronger requirement than just looking at the functional outputs.</p> Definition 2: Side-Channel Noninterference Given a side channel that produces a trace <code>Trace</code>, a program <code>P</code> is noninterferent with respect to this side channel if, for all public inputs\u00a0<code>Pub</code> and all pairs of secret inputs <code>Sec1</code>, <code>Sec2</code> it holds that <code>Trace(P, Sec1, Pub) = Trace(P, Sec2, Pub)</code>. <p>Here are some examples of side channels and how they can violate noninterference:</p> Example 5A: Timing side channel <p>Consider a program that reads a compares a password with a user\u2019s input:</p> <pre><code>bool check_password(const char *attempt, const char *pswd) {\n    for (int i = 0; i &lt; length(pswd); i++) {\n        if (attempt[i] != pswd[i]) {\n            return false;  // mismatch found, return early\n        }\n    }\n    return true; // all characters matched\n}\n</code></pre> <p>If the attacker can measure how long the function takes to reject a guess, they can infer the password one character at a time. This leakage surfaces as a violation of the noninterference property with respect to timing observations.</p> <p>A counterexample to Definition 2 could be as follows: Let's say we use the same input on two different secrets:</p> <ul> <li><code>input1={attempt=\"aaa\", pswd=\"abc\"}</code></li> </ul> <ul> <li><code>input2={attempt=\"aaa\", pswd=\"aab\"}</code></li> </ul> <p>The traces of these inputs will be:</p> <ul> <li><code>trace1 = Trace(check_password, input1) = 1</code></li> </ul> <ul> <li><code>trace2 = Trace(check_password, input2) = 2</code></li> </ul> <p>These inputs constitute a violation of Definition 2, as <code>trace1 != trace2</code> even though the two inputs have the same public values.</p> Example 5B: Timing side channel - Password length <p>Noninterference is able to model different kinds of secret-dependent leaks. Let's take for example a patched version of the previous program:</p> <pre><code>bool check_password(const char *attempt, const char *pswd) {\n    int len = min(length(attempt), length(pswd));\n    bool same = true;\n    for (int i = 0; i &lt; len; i++) {\n        same = same &amp;&amp; (attempt[i] == pswd[i]); // all the loop is executed\n    }\n    return same;\n}\n</code></pre> <p>In this version there is no early-exit condition, yet the attacker is still able to infer the length of the password through a side-channel. This is captured by the following counterexample:</p> <ul> <li><code>input1={attempt=\"aaaaaa\", pswd=\"b\"}</code>, <code>trace1 = 1</code></li> </ul> <ul> <li><code>input2={attempt=\"aaaaaa\", pswd=\"bbb\"}</code>, <code>trace2 = 3</code></li> </ul> <p>Which shows that the program still violates Definition 2.</p> Example 6: Cache side channel <p>Consider a program that uses a secret value to index into an array, as in the following code:</p> <pre><code>int multiply(const char *array, int pub, int sec) {\n    char x = array[sec];\n    return x * pub;\n}\n</code></pre> <p>A co-located attacker could observe the cache access pattern of the program by using Prime+Probe or Flush+Reload attack. Such traces can reveal the addresses accessed by the program and thus leak the secret value. This leakage would violate the noninterference property with respect to cache observations.</p> <p>A violation could be surfaced by two inputs:</p> <ul> <li><code>input1={array=0x10000, pub=1, sec=0x40}</code></li> </ul> <ul> <li><code>input2={array=0x10000, pub=1, sec=0x80}</code></li> </ul> <p>Let's assume that the cache line size is 64 bytes, and the cache is direct-mapped, meaning that the cache line ID is based on the memory access address <code>addr</code> as <code>line_id = (addr % 0x1000) // 0x40</code>. Since the array access in the first line of <code>multiply</code> will access two different addresses for the two inputs, they will also produce two different traces:</p> <ul> <li><code>trace1 = Trace(multiply, input1) = ((0x10000 + 0x40) % 0x1000) // 0x40 = 1</code></li> </ul> <ul> <li><code>trace2 = Trace(multiply, input2) = ((0x10000 + 0x80) % 0x1000) // 0x40 = 2</code></li> </ul> <p>Since we have two inputs that match on the secret value <code>sec</code> but differ on the cache trace, this constitutes a violation of Definition 2.</p>"},{"location":"intro/03_primer/#challenges-of-side-channel-noninterference","title":"Challenges of Side-Channel Noninterference","text":"<p>Despite its completeness, the above formalization of side-channel noninterference is too simplistic to faithfully capture the side effects of program execution on modern, highly optimized hardware, especially CPUs. There are two key challenges:</p> <ul> <li> <p>Challenge 1 - Noisy and Non-Deterministic Traces: The traces observed by the attacker over a side channel are typically noisy, non-deterministic, and depend on the microarchitectural state of the CPU. For example, cache access patterns can be influenced by other programs running on the machine, the operating system and its interrupts, and can depend on microarchitectural buffers like store buffers or branch history tables. This means that the <code>Trace</code> function is not a simple deterministic function of the program inputs, but a complex function of many factors, some of which affect the result concurrently and in a non-deterministic fashion.</p> </li> <li> <p>Challenge 2 - Unknown Side Channels: Modern CPUs have a plethora of side channels, including cache timing, branch prediction, and many others. To ensure complete confidentiality, we need to check that the program does not leak information over any of them. This is a challenging task, as we do not know the full set of possible side channels when it comes to commercial hardware with proprietary microarchitectures. For example, a CPU might have an obscure microarchitectural optimization that vastly expands possibilities for information leaks, as was the case with Spectre and Meltdown vulnerabilities. Not including this optimization will undermine the noninterference analysis. Therefore, to test for noninterference comprehensively, we need a way to discover and reason about all possible side channels that could leak information.</p> </li> </ul> <p>The next two sections discuss how speculation contracts address these challenges.</p>"},{"location":"intro/03_primer/#speculation-contracts-dealing-with-the-complexity-of-modern-hardware","title":"Speculation Contracts: Dealing with the Complexity of Modern Hardware","text":"<p>As a solution to the first challenge, Guarnieri et al. (2021) introduced the concept of speculation contracts. A speculation contract is a simplified and deterministic model of the hardware, designed to capture the information that a given program could leak over side channels when executed with the given inputs. The key term here is \"could\"\u2014the contract is not meant to exactly predict the side-channel traces, but instead, it errs on the side of caution, overestimating the possible leaks to achieve deterministic and noise-free traces.</p> <p>A speculation contract works by defining two key aspects for every instruction in the CPU's ISA:</p> <ol> <li> <p>Observation Clause: For each instruction that may have an observable side effect, the contract declares an observation clause. It describes the data exposed by the instruction.</p> </li> <li> <p>Execution Clause: For each instruction whose semantics may be affected by hardware optimizations (e.g., speculative execution), the contract declares an execution clause. It describes the effect of such optimizations, but without specifying the exact mechanism of the optimization.</p> </li> </ol> <p>At a high level, a contract implements a function <code>ContractTrace</code> that maps a program <code>P</code> and its inputs <code>Sec, Pub</code> to a contract trace <code>ctrace</code>. It is essentially a conservative approximation of the <code>Trace</code> function.</p> <pre><code>ctrace = ContractTrace(P, Sec, Pub)\n</code></pre> <p>The contract trace is a sequence of all data that is exposed when a program is executed according to a contract. It captures the side-channel observations that could be visible if the CPU followed the speculation contract's rules for a given program execution.</p> <p>Accordingly, the noninterference property is redefined in terms of the contract trace:</p> Definition 3: Contract Noninterference Given a contract that produces a contract trace\u00a0<code>ContractTrace</code>, a program <code>P</code> is noninterferent with respect to this contract if,for all public inputs\u00a0<code>Pub</code> and all secret inputs <code>Sec1</code>, <code>Sec2</code>, it holds that <code>ContractTrace(P, Sec1, Pub) = ContractTrace(P, Sec2, Pub)</code>. <p>The following examples illustrate how a contract can be used to model side-channel leaks on a CPU.</p> Example 7: Memory Observation Contract, MEM-SEQ <p>Let's imagine a CPU with a shared data cache and no other optimizations (i.e., no speculation). A co-located attacker can recover the addresses of loads/stores by observing which of the cache sets changed their state via a cache timing side-channel attack (e.g., Prime+Probe). We can encode these expectations in an observation clause for loads and stores by specifying that they expose their address. Since the CPU does not speculate, the execution clause for all instructions is empty. We call this contract MEM-SEQ (memory leakage with sequential execution), and it can be summarized as a table:</p> Observation Clause Execution Clause Load Expose Address - Store Expose Address - Other - - <p>Note that MEM-SEQ intentionally overestimates the leaks by assuming that the attacker observes complete addresses loads/stores (in contrast to a subset of bits that are actually leaked in practice) and that all loads/stores are observable (in reality, they might be masked by noise or other factors). This overestimation is intentional to ensure that the contract is conservative and captures all possible corner cases.</p> <p>Let's now consider how we can produce a contract trace using MEM-SEQ. We will use a slightly modified version of the <code>multiply</code> function from Example 6:</p> <pre><code>int multiply(const char *array, int pub, int sec) {\n    char x = array[sec];   // MEM-SEQ exposes: &amp;array[sec]\n    char y = array[pub];   // MEM-SEQ exposes: &amp;array[pub]\n    return x * y;\n}\n</code></pre> <p>The inputs are:</p> <ul> <li><code>input1 = {array=0x10000, pub=1, sec=2}</code></li> </ul> <ul> <li><code>input2 = {array=0x10000, pub=1, sec=3}</code></li> </ul> <p>The model collects a trace by executing the program line-by-line according to the rules in the table above (in practice, this is usually done using a modified CPU emulator). The first line has a load from memory, so the model records the address <code>&amp;array[sec]</code> as exposed. The second line has another load, so the model records the address <code>&amp;array[pub]</code> as exposed. The contract traces for this program would be:</p> <ul> <li><code>ctrace1 = ContractTrace(multiply, input1) = [0x10002, 0x10001]</code></li> </ul> <ul> <li><code>ctrace2 = ContractTrace(multiply, input2) = [0x10003, 0x10001]</code></li> </ul> <p>Finally, this model can be used to check for noninterference by comparing contract traces according to Definition 3. In this case, we have two inputs with matching public values and different secrets, and they produced different contract traces, <code>ctrace1 != ctrace2</code>. This constitutes a violation and means that the <code>multiply</code> function is not noninterferent with respect to MEM-SEQ.</p> Example 8: Branch Prediction Contract, MEM-COND <p>Now let's consider a more complex scenario, with a CPU that implements branch prediction\u2014a common form of speculative execution. In this case, the CPU may incorrectly predict branch targets and execute instructions that are not part of the correct control flow. We can model this behavior in a contract by introducing an execution clause for conditional jumps that specifies the mispredicted target. To make the example useful, we will assume that the CPU also has a data cache, so the observation clause for loads and stores remains the same as in MEM-SEQ. We call this contract MEM-COND (memory leakage with conditional branch misprediction).</p> Observation Clause Execution Clause Load Expose Address - Store Expose Address - Cond. Jump - Mispredict Target Other - - <p>As a target program we will use the following function:</p> <pre><code>int conditional_multiply(char *array, int pub, int sec) {\n    int z = array[pub];   // MEM-COND exposes: &amp;array[pub]\n    if (z &lt; 10) {         // MEM-COND mispredicts (assume z = 10)\n        z *= array[sec];  // MEM-COND exposes: &amp;array[sec]\n    }\n    return z;\n}\n</code></pre> <p>and a pair of inputs with the same public value but different secrets:</p> <ul> <li><code>input1 = {array=0x10000, pub=1, secret=2}</code></li> </ul> <ul> <li><code>input2 = {array=0x10000, pub=1, secret=3}</code></li> </ul> <p>The first line of <code>conditional_multiply</code> has a load, so it exposes its address, <code>&amp;array[pub]</code>. For the sake of this example, let's assume this load returns <code>10</code>, so the next branch is not supposed to be taken. However, according to MEM-COND, branches take the wrong target, so the model executes the third line anyway. This line is a load, so it exposes the address <code>&amp;array[sec]</code>. After this, the program terminates, and the resulting traces are:</p> <ul> <li><code>ctrace1 = ContractTrace(conditional_multiply, input1) = [0x10002, 0x10001]</code></li> </ul> <ul> <li><code>ctrace2 = ContractTrace(conditional_multiply, input2) = [0x10003, 0x10001]</code></li> </ul> <p>Again, the traces are different, so the program violates noninterference with respect to MEM-COND.</p> <p>Notably, however, these two inputs would not violate noninterference with respect to MEM-SEQ, as the branch at line 2 would not be mispredicted, and the traces would be identical:</p> <p><code>ctrace_mem_seq1 = ctrace_mem_seq2 = [0x10001]</code></p>"},{"location":"intro/03_primer/#building-and-testing-speculation-contracts","title":"Building and Testing Speculation Contracts","text":"<p>Speculation contracts are typically built by hand, with the initial versions based on public knowledge of the CPU's microarchitecture and its side-channel vulnerabilities. However, in the case of commercial CPUs, the exact details of the microarchitecture are often proprietary and not publicly disclosed. In these cases, the contract could\u2014and often will\u2014be incomplete. This is where the testing of speculation contracts becomes crucial: the initial \"draft\" of a contract is tested against the real hardware to ensure that it captures all side-channel leaks that the CPU exhibits. If the contract misses something, it is refined based on the results of the testing, and the process is repeated until the contract is deemed safe to use.</p> <p>But how do we test a speculation contract? A naive approach might be to directly compare the traces produced by the model with the traces collected from the real CPU for the same program and inputs. However, this approach is generally not feasible because the contract traces intentionally overestimate the hardware traces, so mismatches are expected. Moreover, the model might expose information differently than the real hardware (e.g., the model might expose load/store addresses, while the hardware exposes cache set indexes), meaning direct comparison is often impossible.</p> <p>Instead, a more precise approach is to compare the information contained in the traces. The idea is to check that the information exposed by the model is a strict superset of the information exposed by the real hardware. This is done by verifying that all inputs producing identical contract traces for a given program also produce identical hardware traces. If this property holds for all possible programs and inputs (ignore the complexity question for now), then any program that would be noninterferent with respect to the real hardware is guaranteed to be noninterferent with respect to the speculation contract. At this point, the model is safe to use as a proxy for real hardware when analyzing side-channel leaks.</p> <p>To formalize this idea, let's introduce a new function <code>HardwareTrace</code> to denote the hardware trace collected from the real hardware, and it will take an extra argument <code>Ctx</code> to capture the fact that real-world hardware traces depend on the microarchitectural state (e.g., on the state of branch predictors or caches).</p> Definition 4: Contract Compliance A CPU complies with a speculation contract if, for all programs <code>P</code>, all input pairs <code>(Sec1, Pub), (Sec2, Pub)</code>, and all initial microarchitectural states\u00a0<code>Ctx</code>, if <code>ContractTrace(P, Sec1, Pub) = ContractTrace(P, Sec2, Pub)</code>, then <code>HardwareTrace(P, Sec1, Pub, Ctx) = HardwareTrace(P, Sec2, Pub, Ctx)</code>. <p>and conversely</p> Definition 5: Contract Violation A CPU violates a speculation contract if there exists a program\u00a0<code>P</code>, a microarchitectural state\u00a0<code>Ctx</code>, and two inputs <code>(Sec1, Pub), (Sec2, Pub)</code> such that <code>ContractTrace(P, Sec1, Pub) = ContractTrace(P, Sec2, Pub)</code> and  <code>HardwareTrace(P, Sec1, Pub, Ctx) != HardwareTrace(P, Sec2, Pub, Ctx)</code>. <p>We call the tuple <code>(P, Ctx, Sec1, Sec2)</code> a contract counterexample. The counterexample demonstrates that an adversary can learn more information from hardware traces than what the contract specifies. A counterexample indicates a potential microarchitectural leakage that was not accounted for by the contract. The goal of Revizor is to find such counterexamples.</p>"},{"location":"intro/03_primer/#model-based-relational-testing-and-revizor","title":"Model-Based Relational Testing and Revizor","text":"<p>Revizor applies the principles above, and provides a framework for building executable speculation contracts together with a mechanism to test real hardware (currently only CPUs) against these contracts by searching for contract counterexamples, as in Definition 5. However, there are certain issues that appear when the theory from the previous section is applied in practice, which we had to address in Revizor.</p> <p>The first issue is the search space: testing all possible programs and inputs is literally impossible. We mitigate this issue by relying on a sampling-based approach, similar to fuzzing, where we approximate the complete search space via random sampling. Specifically, Revizor generates small (50-100 instructions long) programs, creates random inputs for them, collects both the contract and hardware traces for these inputs, and checks whether any of the traces constitute a contract counterexample. This process is called Model-based Relational Testing, and it is detailed further in the Architecture Overview.</p> <p>This approach works well in practice because any given hardware optimization can typically be triggered by many different programs, and we need to find only one instance to detect a violation. Evidence of this is the list of trophies that Revizor has already amassed.</p> <p>The second issue we encountered is nondeterminism. As mentioned earlier, hardware traces can be non-deterministic due to various factors like interrupts or other programs running on the machine. To handle this, we use statistical methods: Revizor collects hardware traces for each program-input pair multiple times and then compares their distributions. If the distributions of the traces are statistically similar, Revizor considers the traces to be equivalent. This approach helps us account for noise in the hardware traces while still making reliable decisions about contract compliance.</p> <p>For more details, see Architecture Overview.</p>"},{"location":"intro/03_primer/#conclusion","title":"Conclusion","text":"<p>In this primer, we have introduced the concepts of noninterference, side channels, and speculation contracts, which all underlie the design of Revizor:</p> <ul> <li>The hardware fuzzer in Revizor uses speculation contracts and the concepts of noninterference (1) to detect unexpected side channels and dangerous microarchitectural optimizations in commercial CPUs, and (2) to aid in building sound leakage models for those CPUs.</li> <li>The software fuzzer in Revizor (NOTE: currently under construction) uses the leakage models produced by the hardware fuzzer, and applies the principles of noninterference testing to detect side-channel vulnerabilities in real-world software.</li> </ul> <p>With these two components, we aim to provide a comprehensive tool for discovering and mitigating side-channel vulnerabilities software that can handle even the most obscure and complex microarchitectural optimizations in modern hardware.</p>"},{"location":"intro/03_primer/#sources-and-further-reading","title":"Sources and Further Reading","text":"<ul> <li>A. Sabelfeld and A. C. Myers. Language-Based Information-Flow Security. IEEE Journal on Selected Areas in Communications, 21(1), 2003. (Survey of information-flow security, implicit/explicit flows, covert channels, etc.)</li> <li>J. A. Goguen and J. Meseguer. Security Policies and Security Models. IEEE Symposium on Security and Privacy, 1982. (Origin of noninterference as a security policy formalism.)</li> <li>J. B. Almeida et al. Verifying Constant-Time Implementations. USENIX Security Symposium, 2016. (Constant-time programming principles and the ct-verif tool for automated verification.)</li> <li>M. Guarnieri, B. K\u00f6pf, J. Reineke, P. Vila. Hardware-Software Contracts for Secure Speculation. IEEE Symposium on Security and Privacy, 2021. (Original paper on speculation contracts.)</li> <li>O. Oleksenko, C. Fetzer, B. K\u00f6pf, M. Silberstein. Revizor: Testing Black-box CPUs against Speculation Contracts. ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), 2022. (Paper describing Model-based Relational Testing and Revizor.)</li> </ul>"},{"location":"intro/04_tutorials_start/","title":"Starting with Tutorials","text":"<p>Let's learn by example.</p> <p>This is a starting point for a tutorial series that will teach you how to use Revizor for testing CPUs, from the most basic cases, to detection of Spectre and Meltdown, to building custom campaigns for detecting new vulnerabilities, and up to building custom extensions for Revizor for the most advanced cases.</p> <p>Prerequisites</p> <p>Before proceeding with this tutorial, ensure that you have completed the installation steps outlined in the Installation Guide.</p> <p>Need Help?</p> <ul> <li>Questions about the tutorial? Check the FAQ or open a GitHub discussion</li> <li>Found a bug? Report it in GitHub issues</li> </ul>"},{"location":"intro/04_tutorials_start/#lets-get-started","title":"Let's get started!","text":"<p>Ready to dive in? Proceed to Tutorial 1</p>"},{"location":"intro/tsa-sq/","title":"Tutorial: Detecting TSA-SQ with Revizor","text":"<p>This tutorial demonstrates how we used Revizor to detect TSA-SQ (Transient Scheduler Attack - Store Queue), a microarchitectural vulnerability discovered in AMD Zen4 processors. We'll walk through the design rationale behind the fuzzing campaign configuration and template, explaining how each component contributes to successful vulnerability detection.</p> <p>You can reproduce this campaign using the provided configuration and template files, which are available in the Revizor repository under <code>demo/tsa-sq/</code>.</p>"},{"location":"intro/tsa-sq/#prerequisites","title":"Prerequisites","text":"<p>To follow this tutorial, you should have:</p> <ul> <li>Non-virtualized access to an AMD Zen4 processor for testing</li> <li>A working installation of Revizor. See installation guide for setup instructions.</li> <li>Basic understanding of Revizor's fuzzing framework, in particular the concepts of model-based relational testing, actors, templates, macros.</li> <li>Familiarity with microarchitectural vulnerabilities and side-channel attacks</li> </ul>"},{"location":"intro/tsa-sq/#background-understanding-tsa-sq","title":"Background: Understanding TSA-SQ","text":"<p>Before diving into the Revizor configuration, let's briefly understand what TSA-SQ is. According to the AMD security bulletin, TSA-SQ exploits timing variations in the CPU's store queue during \"false completion\" events. When a load instruction matches the address of an older store whose data isn't yet available, it may complete falsely using stale data from a previous store that occupied the same store queue entry. This creates timing differences that an attacker can observe to infer information about previous stores, even from different privilege levels.</p> <p>The key insight is that an unprivileged user process can potentially observe timing variations that depend on data from kernel stores, creating a kernel-to-user information leak channel.</p>"},{"location":"intro/tsa-sq/#design-rationale","title":"Design Rationale","text":"<p>When this campaign was designed, we were not yet aware of the TSA-SQ vulnerability (in fact, the vulnerability was discovered as result of this campaign). Therefore, the campaign design is not specifically tailored to detect TSA-SQ, but rather to stress-test the general isolation between kernel and user modes in a way that could reveal microarchitectural vulnerabilities.</p>"},{"location":"intro/tsa-sq/#threat-model-and-actor-configuration","title":"Threat Model and Actor Configuration","text":"<p>Our fuzzing campaign targets a common and high-impact threat model: a malicious user process attempting to extract sensitive data from the kernel. This scenario is particularly relevant for privilege escalation attacks where an attacker seeks to leak kernel secrets.</p> <p>The actor section of <code>config.yaml</code> reflects this threat model:</p> <pre><code>actors:\n  - main:\n    - mode: \"host\"\n    - privilege_level: \"kernel\"\n    ...\n  - user:\n    - observer: true\n    - mode: \"host\"\n    - privilege_level: \"user\"\n</code></pre> <p>The <code>main</code> actor represents the victim kernel, while the <code>user</code> actor represents the attacker. The <code>observer: true</code> flag designates the user actor as the attacker attempting to extract information. This configuration, in combination with the noninterference contract, tells Revizor that any information leakage from <code>main</code> to <code>user</code> should be flagged as a violation.</p>"},{"location":"intro/tsa-sq/#template-design-simulating-attack-patterns","title":"Template Design: Simulating Attack Patterns","text":"<p>The template structure follows the typical flow of a microarchitectural side-channel attack, specifically implementing a Flush+Reload pattern across privilege transitions.</p> <p></p> <p>Let's examine each phase:</p> <p>Phase 1: Setup and Flush (function_main_0 and function_user_0)</p> <p>The first stage represent the attacker preparing the microarchitectural state for measurements. The first action in the template is in the <code>function_user_0</code>, where the <code>user</code> actor initializes the microarchitectural state by flushing the cache lines that will be used for measurements. This is done using the <code>measurement_start</code> macro, which is translated into a Flush stage of Flush+Reload attack. Revizor does this translation automatically based on the <code>executor_mode: F+R</code> setting in the configuration file.</p> <p>Note that the template does not actually start from the <code>function_user_0</code> actor function. Instead, it starts with the <code>function_main_0</code>, which is a function belonging to the <code>main</code> actor. This is because Revizor requires that the entry point to the test case must be within the <code>main</code> actor's code.</p> <p>Phase 2: Secret Injection (function_main_1)</p> <p>After the initial setup, the attacker transitions to the victim and let's it do some computations on the victim's secret data. The victim actor execute a sequence of random instructions in the <code>function_main_1</code> macro, which simulates the kernel performing operations on sensitive data. Here, \"random instructions\" means a sequence of instructions that is randomly generated in each fuzzing round (i.e., each generated test case will have a different sequence of instructions in <code>function_main_1</code>).</p> <p>This randomness is crucial because it allows us to test a wide range of ways how secret data can impact microarchitectural state, without knowing a priori what specific instruction sequences might trigger a leak. This was one of the key factors that allowed us to discover TSA vulnerabilities without knowing about them beforehand.</p> <p>Phase 3: Secret Extraction (function_user_1)</p> <p>Back in user mode, we first clear the architectural state to eliminate any architectural information flow between actors. This is necessary to prevent any architectural information flows between the actors, which could otherwise lead to false positives in the analysis because Revizor is unable to distinguish between architectural and microarchitectural information flows (to be precise, Revizor would be able to distinguish them with a more subtle contract, but re-initializing the registers is a simpler solution).</p> <pre><code>xor rax, rax  # noremove\nmov rax, qword ptr [r14 + 0x2000] # noremove\nmov rbx, qword ptr [r14 + 0x2008] # noremove\n# ... more register initialization\n</code></pre> <p>After that, the attacker execute another sequence of random instructions, which simulates the user process attempting to access the sensitive data that was just processed by the kernel. Note that this sequence may include an attempt to access kernel memory from the user mode (see the <code>user-to-kernel-access</code> fault allowlist in the configuration). As we found out post-factum, this is not strictly necessary for TSA-SQ, but it helps to create complex microarchitectural conditions that can trigger the leak.</p> <p>Depending on whether random instruction sequence triggers the fault, the user actor will either switch to the kernel mode explicitly (using the <code>switch_u2k.main.user_1</code> macro) or the CPU will transfer control to the fault handler (<code>fault_handler</code> macro in the <code>function_main_2</code>). In this experiment, we were not particularly interested in fault handling, so both paths lead to the same point in the template.</p> <p>Phase 4: State Measurement (function_user_2)</p> <p>Finally, the \"Reload\" stage in <code>function_user_2</code> measures which cache lines were accessed by the random code in the previous stage. If the accessed cache lines were somehow influenced by the kernel's secret data, this will lead to a discrepancy in the \"Reload\" measurements, leading to diverging hardware traces for different inputs, and ultimately to Revizor detecting a violation.</p>"},{"location":"intro/tsa-sq/#configuration-overview","title":"Configuration Overview","text":"<p>Beyond the actor configuration, <code>config.yaml</code> contains several other important settings that guide the fuzzing campaign, as described next:</p> <ul> <li>Contract: The contract configuration specifies what information leakage we consider acceptable</li> </ul> <pre><code>contract_observation_clause: ct\ncontract_execution_clause:\n  - noninterference\n</code></pre> <p>The <code>noninterference</code> execution clause implements the security property that observer actors cannot learn information about non-observer actors through microarchitectural channels. Combined with the <code>ct</code> (constant-time) observation clause, this allows the observer to see memory access patterns and control flow but prohibits leakage of raw data values.</p> <ul> <li>Exceptions: The configuration includes <code>user-to-kernel-access</code> in the fault allowlist, which enables testing for Meltdown-type vulnerabilities. This was part of our original experimental design when we didn't yet know about TSA's existence. Revizor's program generator will randomly select memory accesses in the user actor and modify them to target kernel memory, triggering page faults.</li> </ul> <p>Interestingly, this exception-based approach helped discover TSA-SQ because the false completion events in the store queue can lead to timing differences in subsequent instructions, and the faults provide a constant-time reference point for the timing differences to get transformed into persistent cache state. Namely, when a variable-latency instruction is executed concurrently with a faulting instruction, it creates a race condition, where the cache impact of the variable-latency instruction can be influenced by whether the faulting instruction completes before or after it.</p> <p>Note the fault configuration quirk: we enable <code>user-to-kernel-access</code> globally but block it specifically for the main actor using <code>fault_blocklist</code>. This is the only way to enable a fault for a specific actor, because Revizor does not allow faults to be allow-listed for a specific actor.</p> <ul> <li>Statistical Analysis: The statistical analysis parameters balance sensitivity with noise tolerance:</li> </ul> <pre><code>analyser_stat_threshold: 0.05\nexecutor_sample_sizes: [15, 40, 160, 320]\n</code></pre> <p>The low threshold of 0.05 makes the analysis sensitive to subtle timing differences, while the adaptive sample sizes allow Revizor to start with quick tests and increase precision when potential violations are detected.</p> <ul> <li>Instruction Set: The instruction set is defined as <code>x86-64</code> because we are targeting AMD CPUs, and the instruction categories include all base instructions, which allows for a wide range of microarchitectural interactions in the randomly generated code. Ideally, we would include even more categories, such as SIMD extensions and other advanced instructions, but Revizor does not yet support them (coming up soon, though!).</li> </ul>"},{"location":"intro/tsa-sq/#running-the-campaign","title":"Running the Campaign","text":"<p>With the configuration and template in place, we can run the detection campaign using Revizor's <code>tfuzz</code> command. This command generates test cases based on the provided template and configuration, executes them, and analyzes the results for violations.</p> <pre><code>./revizor.py tfuzz -s base.json --save-violations t -w ./results/ \\\n    -c config.yaml -t template.asm -n 100000 -i 25\n</code></pre> <p>This runs 100,000 test cases with 25 inputs each. The <code>--save-violations</code> flag preserves any detected violations for later analysis. When TSA-SQ is present, you'll eventually see output similar to:</p> <pre><code>================================ Violations detected ==========================\nContract trace:\n 14140085380608124960 (hash)\nHardware traces:\n  Input group 1: [11]\n  Input group 2: [36]\n  ^^^.........^.................................^^................ [287    | 36    ]\n  ^^^.........^.................................^................. [31     | 284   ]\n</code></pre> <p>The different hardware trace patterns for inputs 11 and 36, despite having the same contract trace hash, indicate that the CPU is leaking information not predicted by the noninterference contract.</p> <p>On our machine, the campaign typically takes about 5 hours to detect a leak, but your mileage may vary depending on the CPU model and due to the inherent randomness of the process.</p>"},{"location":"intro/tsa-sq/#verifying-genuine-violations","title":"Verifying Genuine Violations","text":"<p>To confirm that a detected violation is genuine, reproduce it using:</p> <pre><code>./revizor.py reproduce -s base.json -c ./results/violation-*/reproduce.yaml \\\n    -t ./results/violation-*/program.asm -i ./results/violation-*/input_*.bin\n</code></pre> <p>A genuine violation will reproduce consistently across multiple runs with the same statistical pattern, confirming that the timing differences represent a real microarchitectural information leak.</p> <p>The next step is to do root-cause analysis of the violation, which is beyond the scope of this tutorial. See Root-Causing a Violation Detected by Revizor for details on this process.</p>"},{"location":"intro/tutorial1-first-fuzz/part1/","title":"Tutorial 1: Your First Fuzz (Part 1)","text":"<p>This is the first part of the tutorial on the basic usage of Revizor.</p>"},{"location":"intro/tutorial1-first-fuzz/part1/#overview","title":"Overview","text":"<p>In this first tutorial, we'll start with a baseline experiment to verify your Revizor installation and familiarize yourself with the basic workflow. This tutorial walks you through a simple fuzzing campaign that should find no violations.</p> <p>The goal of this first campaign is verification, not vulnerability detection. We'll deliberately choose an instruction set that should not trigger speculation on Intel or AMD CPUs\u2014specifically, simple arithmetic operations without any branches or memory speculation sources. Since there are no conditional branches to mispredict and no page faults to speculate around, we expect the CPU to execute sequentially without any speculative side effects.</p> <p>This baseline is useful for two reasons. First, it confirms your installation is working correctly. If the fuzzer crashes or behaves unexpectedly, you'll know there's a setup issue rather than discovering problems later during more complex campaigns. Second, it establishes what \"no violations\" looks like, so you can recognize the difference when you do find a vulnerability in the next tutorial.</p>"},{"location":"intro/tutorial1-first-fuzz/part1/#create-your-first-configuration-file","title":"Create your first configuration file","text":"<p>Revizor's behavior is controlled by a YAML configuration file that specifies which instructions to test and what contract to check against. Create a file named <code>config.yaml</code> with the following content:</p> <pre><code># tested instructions\ninstruction_categories:\n  - BASE-BINARY\n\n# prevent branch generation\nmax_bb_per_function: 1\nmin_bb_per_function: 1\n\n# contract\ncontract_observation_clause: loads+stores+pc\ncontract_execution_clause:\n  - no_speculation\n</code></pre> <p>Let's understand each section. The <code>instruction_categories</code> field tells Revizor which instructions to include in generated test cases. We're using <code>BASE-BINARY</code>, which includes only arithmetic and logical operations like <code>add</code>, <code>sub</code>, <code>and</code>, <code>xor</code>, and <code>mov</code>. These operations are data-processing instructions that don't involve control flow or special memory access patterns.</p> <p>The <code>max_bb_per_function</code> and <code>min_bb_per_function</code> settings both set to 1 ensure that Revizor generates programs with exactly one basic block\u2014meaning no branches at all. This simplifies our test cases to pure arithmetic sequences, eliminating any possibility of branch misprediction.</p> <p>The contract configuration section is set to use the simplest contract, CT-SEQ. This contract assumes nothing about the target CPU except the presence of CPU caches, making it a zero-knowledge baseline for detecting unknown vulnerabilities. With CT-SEQ, Revizor reports any information leaks beyond the most trivial non-speculative cache accesses.</p> <p>For a complete reference of all configuration options, see the Configuration Reference.</p>"},{"location":"intro/tutorial1-first-fuzz/part1/#whats-next","title":"What's Next","text":"<p>In Part 2, we'll use this configuration to run your first fuzzing campaign.</p>"},{"location":"intro/tutorial1-first-fuzz/part2/","title":"Tutorial 1: Your First Fuzz (Part 2)","text":"<p>This tutorial picks up where part1 left off. We will run the fuzzer with the configuration you've created, and learn how to read the results.</p>"},{"location":"intro/tutorial1-first-fuzz/part2/#run-the-campaign","title":"Run the Campaign","text":"<p>Let's run the fuzzer with your baseline configuration:</p> <pre><code>rvzr fuzz -s base.json -c config.yaml -n 100 -i 50 -w .\n</code></pre> <p>This command tells Revizor to execute 100 test cases (<code>-n 100</code>) with 50 inputs per test case (<code>-i 50</code>), using the ISA specification from <code>base.json</code> and your configuration file. The <code>-w .</code> flag specifies the working directory for saving any violations.</p> <p>You'll see output similar to this:</p> <pre><code>INFO: [fuzzer] Starting at 14:32:18\n100   (100%)| Stats: Cls:50/50,In:100,R:5,SF:0,OF:0,Fst:0,CN:0,CT:0,P1:0,CS:0,P2:0,V:0\n================================ No Violations detected ===========================\n</code></pre> <p>The campaign should complete in under a minute with no violations detected. This is exactly what we expect\u2014our simple arithmetic instructions don't trigger speculation, so the hardware behaves according to the strict sequential contract.</p>"},{"location":"intro/tutorial1-first-fuzz/part2/#interpret-the-statistics","title":"Interpret the statistics","text":"<p>Let's examine the statistics line to understand what Revizor is reporting:</p> <pre><code>100   (100%)| Stats: Cls:50/50,In:100,R:5,SF:0,OF:0,Fst:0,CN:0,CT:0,P1:0,CS:0,P2:0,V:0\n</code></pre>"},{"location":"intro/tutorial1-first-fuzz/part2/#100-100","title":"<code>100 (100%)</code>","text":"<p>This part shows we completed all 100 test cases. This number was continuously updated while the fuzzer was running.</p>"},{"location":"intro/tutorial1-first-fuzz/part2/#cls5050","title":"<code>Cls:50/50</code>","text":"<p>These numbers indicate the number of equivalence classes formed by the inputs. The first number is the effective classes (&gt; 1 input per class) and the second is the total number of classes.</p> <p>If you don't understand what all of this means, that's ok. The only important factors are:</p> <ul> <li>if both numbers are equal (or at least close), and they are also equal to the number of inputs that you've set via <code>-i</code> command-line argument: everything is going well.</li> <li>if the numbers are different, it means either a misconfiguration or an issue with the input generator. Ensure that <code>input_per_class</code> config option is <code>&gt; 1</code>.</li> <li>if the numbers are equal, but they are both considerably lower than the number of inputs set via <code>-i</code>: You're using an overly simple fuzzing configuration, and you're unlikely to find anything with it.</li> </ul> <p>None of the issues above should happen if you're using the config file from this tutorial. If they do, double-check your installation.</p>"},{"location":"intro/tutorial1-first-fuzz/part2/#r5","title":"<code>R:5</code>","text":"<p>This is an indirect indicator of the level of noise on the system. More concretely, it is the average sample size used by the executor. It is an adaptive number, which increases when the tool starts to encounter false positive caused by noise.</p> <p>This number should be relatively small. If you see that it's going above 10-20 range, it is likely because something is polluting the measurements. Consider applying the suggestions here.</p>"},{"location":"intro/tutorial1-first-fuzz/part2/#sf0of0fst0cn0ct0p10cs0p20","title":"<code>SF:0,OF:0,Fst:0,CN:0,CT:0,P1:0,CS:0,P2:0</code>","text":"<p>These numbers are the statistics on the effectiveness of various optimizations used by Revizor, such as speculation and observation filtering.</p> <p>You can ignore these numbers for now, as they are useful only when you're trying to optimize performance of the fuzzer. If you're still curious, though, see the Fuzzing Statistics Reference.</p>"},{"location":"intro/tutorial1-first-fuzz/part2/#understand-what-this-means","title":"Understand what this means","text":"<p>The successful completion of this baseline campaign tells you several things. Your Revizor installation is working correctly\u2014the fuzzer can generate test cases, execute them on your hardware, collect traces, and analyze the results. Your system is stable enough for fuzzing\u2014there's no excessive noise preventing measurement. The kernel module loaded correctly and can execute test programs in the sandbox environment.</p> <p>Setup Verified</p> <p>If you've successfully completed this baseline campaign with no violations, your Revizor installation is ready for real vulnerability detection. You can now proceed to Tutorial 2 with confidence.</p> <p>Troubleshooting Common Issues</p> <p>If the fuzzer crashes or produces errors, check these common problems:</p> <p>Module not loaded: Ensure the kernel module is loaded with <code>lsmod | grep rvzr_executor</code>. If not, run <code>cd rvzr/executor_km &amp;&amp; make &amp;&amp; sudo make install</code>.</p> <p>Permission denied: Revizor needs root privileges to access performance counters. Check that your user account on the system has <code>sudo</code> privileges.</p> <p>ISA specification missing: If you see \"base.json not found\", run <code>rvzr download_spec</code> first to download the instruction set specification.</p>"},{"location":"intro/tutorial1-first-fuzz/part2/#whats-next","title":"What's Next?","text":"<p>You've finished the first tutorial. Congrats!</p> <p>If you're ready to go further and start detecting violations, proceed to Tutorial 2.</p>"},{"location":"intro/tutorial2-first-vuln/part1/","title":"Tutorial 2: Detecting Your First Vulnerability (Part 1)","text":"<p>This tutorial is the first step into actual vulnerability detection. You'll learn how to set up a fuzzing campaign that tests conditional branches. And, most likely, it will end with a detection of Spectre V1.</p>"},{"location":"intro/tutorial2-first-vuln/part1/#testing-workflow","title":"Testing Workflow","text":"<p>Before we begin with actual testing, let's take a step back and consider how a typical testing workflow looks like.</p> <p>The process of using Revizor normally constitutes of the following steps:</p> <ol> <li>Design the campaign by selecting which instructions to test and choosing an appropriate contract that defines what behavior we consider a violation.</li> <li>Create a configuration file that captures these decisions.</li> <li>Run the fuzzer to generate and execute random test cases.</li> <li>Validate the violation to ensure it's genuine and not a false positive.</li> <li>Minimize the test case to remove unnecessary complexity, making it easier to understand.</li> <li>Analyze the minimized program to identify the root cause of the vulnerability.</li> </ol> <p>In the following, we will go step-by-step through this workflow.</p>"},{"location":"intro/tutorial2-first-vuln/part1/#plan-the-campaign","title":"Plan the campaign","text":"<p>Let's imagine we have a new CPU and want to determine if conditional branches produce any information leakage on it. These instructions are infamous for causing Spectre V1, therefore it is always useful to start with them when testing a new CPU.</p> <p>The first step is planning our fuzzing campaign strategically.</p> <p>For effective testing, we'll focus on a minimal instruction subset rather than the entire ISA. Spectre V1 requires only two capabilities: conditional branches (to trigger misprediction) and memory accesses (to leak information through side channels). By limiting our instruction set to just arithmetic operations and conditional branches, we accomplish two goals. First, the fuzzer will find violations faster because there are fewer instruction combinations to explore. Second, when we do find a violation, it will be much easier to analyze because the test case will be simpler.</p> <p>Warning</p> <p>Note that this focused approach is not representative of a real fuzzing campaign. This tutorial is intentionally simplified to help with understanding. In a real campaign, you'll need to find balance between having a broad scope (increases changes of finding unknown vulnerabilities) and having focus on specific CPU features (simplifies root-cause analysis). For more guidance on campaign design, see How to Design a Fuzzing Campaign.</p> <p>We'll pair this minimal instruction set with the strictest possible contract\u2014one that forbids any speculation whatsoever. This means Revizor will flag any speculative behavior as a violation. While this contract is more restrictive than what modern CPUs actually guarantee, it's perfect for our purposes. Since we're only testing conditional branches and simple arithmetic, any speculation we detect will almost certainly be Spectre V1.</p> <p>With this campaign plan, we are trying to answer a specific question: \"Does this CPU leak information through conditional branches?\"</p>"},{"location":"intro/tutorial2-first-vuln/part1/#create-the-configuration-file","title":"Create the configuration file","text":"<p>Now that we've planned our campaign, let's translate it into a configuration file. Create a YAML file with the following content:</p> <pre><code># tested instructions\ninstruction_categories:\n  - BASE-BINARY\n  - BASE-COND_BR\n\n# contract\ncontract_observation_clause: loads+stores+pc\ncontract_execution_clause:\n  - no_speculation\n\n# enable perf. optimizations\nenable_speculation_filter: true\nenable_observation_filter: true\nenable_fast_path_model: true\n</code></pre> <p>The <code>instruction_categories</code> section implements our decision to use a minimal instruction set. We're including <code>BASE-BINARY</code> for arithmetic operations like addition and comparison, and <code>BASE-COND_BR</code> for conditional branches like <code>jz</code> and <code>jne</code>. These two categories give the fuzzer everything it needs to express Spectre V1 patterns.</p> <p>The contract configuration consists of two clauses. The <code>contract_observation_clause</code> tells Revizor what microarchitectural side effects to track. We're using <code>loads+stores+pc</code>, which observes memory access addresses and the program counter\u2014exactly what an attacker would monitor through cache timing attacks. The <code>contract_execution_clause</code> defines what execution behavior is allowed. By setting it to <code>no_speculation</code>, we're telling Revizor that any speculative execution is a violation.</p> <p>The performance optimization flags at the bottom significantly speed up fuzzing without affecting correctness. The <code>enable_speculation_filter</code> skips test cases that don't trigger speculation at all. The <code>enable_observation_filter</code> skips test cases that leave no observable traces. The <code>enable_fast_path_model</code> allows Revizor to reuse contract traces across similar inputs, reducing the model execution overhead.</p> <p>For a complete reference of all configuration options, see the Configuration Reference.</p>"},{"location":"intro/tutorial2-first-vuln/part1/#whats-next","title":"What's Next?","text":"<p>Part 2 will walk you through running the campaign.</p>"},{"location":"intro/tutorial2-first-vuln/part2/","title":"Tutorial 2: Detecting Your First Vulnerability (Part 2)","text":"<p>This tutorial picks up where part 1 left off. We will run the fuzzer with the configuration you've created, and see the results.</p>"},{"location":"intro/tutorial2-first-vuln/part2/#run-the-fuzzer","title":"Run the fuzzer","text":"<p>Now we're ready to start fuzzing. Run Revizor with the following command:</p> <pre><code>./revizor.py fuzz -s base.json -c config.yaml -n 1000 -i 10 -w .\n</code></pre> <p>This command tells Revizor to run 1000 test cases (<code>-n 1000</code>), with 10 inputs per test case (<code>-i 10</code>), using the ISA specification from <code>base.json</code> (<code>-s</code>) and our configuration file (<code>-c</code>). The <code>-w .</code> flag tells Revizor to save any violations it finds to the current directory.</p> <p>As the fuzzer runs, you'll see a continuously updating progress line:</p> <pre><code>50    ( 5%)| Stats: Cls:10/10,In:20,R:7,SF:38,OF:6,Fst:6,CN:0,CT:0,P1:0,CS:0,P2:0,V:0\n</code></pre>"},{"location":"intro/tutorial2-first-vuln/part2/#view-the-detected-violation","title":"View the detected violation","text":"<p>After a minute or so, you should see a violation. It will be reported in a format similar to this:</p> <pre><code>================================ Violations detected ==========================\nViolation Details:\n\n-----------------------------------------------------------------------------------\n                             HTrace                              | ID:4   | ID:14 |\n-----------------------------------------------------------------------------------\n^......^...^........^.................^...........^............. | 626    | 0     |\n^......^...^........^........................................... | 1      | 18    |\n^^.....^...^........^....^...................................... | 0      | 609   |\n</code></pre> <p>Excellent! We've successfully detected a contract violation. Let's understand what this violation report is telling us.</p> <p>The report shows us the violation details in a table format. The header row displays the input IDs that triggered the violation\u2014in this case, inputs 4 and 14:</p> <p><code>| ID:4   | ID:14 |</code></p> <p>These are two inputs from our test case that the contract predicted would behave identically, but the hardware traces show they behaved differently.</p> <p>The three rows below show the different hardware traces that were observed:</p> <pre><code>^......^...^........^.................^...........^.............\n^......^...^........^...........................................\n^^.....^...^........^....^......................................\n</code></pre> <p>Each row represents a distinct cache access pattern, visualized as a bitmap where <code>^</code> marks an accessed cache line and <code>.</code> marks an untouched cache line. We're using Prime+Probe cache side channel measurements (default), so each position in the bitmap corresponds to one of the 64 cache sets in the L1D cache. (A cache set is a group of cache lines that compete for the same position in the cache\u2014when the CPU accesses memory at a particular address, the data goes into a specific cache set determined by the address bits.)</p> <p>For example, the first trace reads like this:</p> <pre><code>Cache Set 0 accessed\n|          Cache Set 11 accessed\n|          |                          Cache set 38 accessed\n|          |                          |\n^......^...^........^.................^...........^.............\n       |            |                             |\n       |            |                             Cache Set 50 accessed\n       |            Cache Set 20 accessed\n       Cache Set 7 accessed\n</code></pre> <p>Finally, the numbers in the columns tell us how often each trace appeared for each input:</p> <pre><code>... | 626    | 0     |\n... | 1      | 18    |\n... | 0      | 609   |\n</code></pre> <p>Looking at the first hardware trace we see it appeared 626 times for input 4 but never for input 14. The third trace shows the opposite pattern\u20140 times for input 4 but 609 times for input 14. This clear separation in the distributions confirms this is a genuine violation, not random noise.</p> <p>What we're seeing is a data-dependent cache access pattern. The test case accessed different cache lines depending on the input data, creating an observable side channel. We don't know yet what caused this channel, but we can already tell that it's likely to be caused by speculation; non-speculative cache accesses are permitted by our reference contract, so they wouldn't be reported as violations.</p> <p>For more details on interpreting violation reports, see How to Interpret Violation Results.</p>"},{"location":"intro/tutorial2-first-vuln/part2/#violation-artifact","title":"Violation Artifact","text":"<p>The artifact for this violation is stored in a directory named <code>violation-&lt;timestamp&gt;</code>:</p> <pre><code>$ ls -l violation-251203-103338\ninput_0000.bin  input_0004.bin  input_0008.bin  input_0012.bin  input_0016.bin  minimize.yaml    reproduce.yaml\ninput_0001.bin  input_0005.bin  input_0009.bin  input_0013.bin  input_0017.bin  org-config.yaml\ninput_0002.bin  input_0006.bin  input_0010.bin  input_0014.bin  input_0018.bin  program.asm\ninput_0003.bin  input_0007.bin  input_0011.bin  input_0015.bin  input_0019.bin  report.txt\n</code></pre> <p>The <code>program.asm</code> file holds the test case program that triggered the violation. The <code>input_*.bin</code> files contain the input sequence that exposed the leak. The <code>report.txt</code> file provides additional details including hardware and contract traces. The configuration files include <code>org-config.yaml</code> (the original configuration), <code>reproduce.yaml</code> (for reproducing the violation), and <code>minimize.yaml</code> (for test case minimization).</p>"},{"location":"intro/tutorial2-first-vuln/part2/#validate-the-violation","title":"Validate the violation","text":"<p>Let's verify this violation is genuine and reproducible. First, we'll move the violation artifacts to a simpler path:</p> <pre><code>mv violation-251203-103338 ./violation\n</code></pre> <p>Now we'll reproduce the violation using the saved artifacts:</p> <pre><code>./revizor.py reproduce -s base.json -c ./violation/reproduce.yaml -t ./violation/program.asm -i ./violation/input*.bin\n</code></pre> <p>If the violation is genuine, we should see Revizor report it again:</p> <pre><code>================================ Violations detected ==========================\nViolation Details:\n\n-----------------------------------------------------------------------------------\n                             HTrace                              | ID:4   | ID:14 |\n-----------------------------------------------------------------------------------\n^......^...^........^.................^...........^............. | 626    | 0     |\n^......^...^........^........................................... | 1      | 20    |\n^^.....^...^........^....^...................................... | 0      | 607   |\n</code></pre> <p>Perfect! The hardware traces are roughly the same as before, confirming this is a stable, reproducible violation.</p> <p>Dealing with False Positives</p> <p>In most cases, violations are genuine. However, if you're on a high-noise system, you might occasionally see non-reproducible violations. If this happens, adjust the noise tolerance by increasing <code>analyser_stat_threshold</code> or <code>executor_sample_sizes</code> in your configuration file (see the Configuration Reference for details), then rerun the fuzzer. Also, consider trying to mitigate the noise, for example by disabling hyperthreading or by turning prefetchers off.</p>"},{"location":"intro/tutorial2-first-vuln/part2/#whats-next","title":"What's Next?","text":"<p>Part 3 will walk you through minimizing and root-causing the violation.</p>"},{"location":"intro/tutorial2-first-vuln/part3/","title":"Tutorial 2: Detecting Your First Vulnerability (Part 3)","text":"<p>This tutorial picks up where part 2 left off. We will minimize and root-cause the violation.</p>"},{"location":"intro/tutorial2-first-vuln/part3/#minimize-the-test-case","title":"Minimize the test case","text":"<p>Now that we've confirmed the violation is real, let's simplify it for easier analysis. The minimizer will systematically remove unnecessary instructions while keeping the violation reproducible.</p> <p>Use the following command. We won't go into it's details now as they are irrelevant to this tutorial. If you're curious, check our How to Minimize guide.</p> <pre><code>./revizor.py minimize -s base.json \\\n    -c ./violation/minimize.yaml -t ./violation/program.asm \\\n    -o ./violation/min.asm -i 10 --num-attempts 3 \\\n    --enable-instruction-pass 1 \\\n    --enable-simplification-pass 1 \\\n    --enable-nop-pass 1 \\\n    --enable-constant-pass 1 \\\n    --enable-mask-pass 1 \\\n    --enable-label-pass 1\n</code></pre> <p>We'll see the minimization progress as it works through multiple passes:</p> <pre><code>[PASS 1] Reproducing the violation\n  &gt; Violation reproduced. Proceeding with minimization\n  &gt; Violating input IDs: [4, 14]\n[INFO] Minimization attempt 1/3\n[PASS 2] Instruction Removal Pass\n\n........---...--\n[PASS 3] Instruction Simplification Pass\n\n--..-\n[PASS 4] NOP Replacement Pass\n\n(and so on...)\n</code></pre> <p>This process typically takes 5-10 minutes. Each <code>.</code> indicates a failed removal attempt (the violation disappeared), while each <code>-</code> shows a successful simplification (the violation persisted with fewer instructions). After it finishes, we'll find the minimized program in <code>./violation/min.asm</code>.</p> <pre><code>.intel_syntax noprefix\n.section .data.main\n.function_0:\n.macro.measurement_start: nop qword ptr [rax + 0xff]\nadd al, -118 # instrumentation\nand rdi, 0b1111111111100 # instrumentation\nadc al, byte ptr [r14 + rdi]\nmov rax, -1332388169\nimul eax, eax, -75\nand rcx, 0b1111111111000 # instrumentation\nadd dword ptr [r14 + rcx], eax\nand rax, 0b1111111111000 # instrumentation\nimul qword ptr [r14 + rax]\nand rcx, 0b1111111000000 # instrumentation\nlock inc qword ptr [r14 + rcx]\nand rdi, 0b1111111111000 # instrumentation\nadd byte ptr [r14 + rdi], al\nsub dl, al\njp .bb_0.1\njmp .exit_0\n.bb_0.1:\nand rbx, 0b1111111111000 # instrumentation\ncmp dword ptr [r14 + rbx], eax\nand rdi, 0b1111111111000 # instrumentation\ncmp qword ptr [r14 + rdi], rbx\nand rbx, 0b1111111000000 # instrumentation\nlock sub word ptr [r14 + rbx], dx\nand rbx, 0b1111111111000 # instrumentation\ndec word ptr [r14 + rbx]\nand rsi, 0b1111111111000 # instrumentation\nneg qword ptr [r14 + rsi]\nand rbx, 0b1111111111000 # instrumentation\nadc ax, word ptr [r14 + rbx]\n.exit_0:\n.macro.measurement_end: nop qword ptr [rax + 0xff]\n.section .data.main\n.test_case_exit:nop\n</code></pre> <p>Let's verify the minimized program still triggers the violation:</p> <pre><code>$ ./revizor.py reproduce -s base.json -c ./violation/reproduce.yaml -t ./violation/min.asm -i ./violation/input*.bin\n\nINFO: [prog_gen] Setting program_generator_seed to random value: 112509\n\nINFO: [fuzzer] Starting at 11:04:52\n&gt; Entering slow path...&gt; Priming  1             &gt; Increasing sample size... to 50&gt; Increasing sample size... to 100&gt; Increasing sample size... to 500&gt; Priming  1\n\n================================ Violations detected ==========================\nViolation Details:\n\n-----------------------------------------------------------------------------------\n                             HTrace                              | ID:5   | ID:15 |\n-----------------------------------------------------------------------------------\n^^................^..^.......................................... | 404    | 15    |\n^^.........^....^.^..^.......................................... | 223    | 0     |\n^^................^..^.......^....................^............. | 0      | 612   |\n</code></pre> <p>Excellent! The violation still reproduces with the minimized program. We've successfully reduced the test case while preserving the vulnerability.</p> <p>The program is still fairly complex, though. Let's run input minimization to identify exactly which values are being leaked.</p>"},{"location":"intro/tutorial2-first-vuln/part3/#analyze-the-leak-through-input-minimization","title":"Analyze the leak through input minimization","text":"<pre><code>$ revizor ./revizor.py minimize -s base.json -c ./violation/minimize.yaml -t ./violation/min.asm -o ./violation/min.asm -i 25  --input-outdir ./violation/min-inputs \\\n    --enable-input-diff-pass 1 \\\n    --enable-input-seq-pass 1 \\\n    --enable-instruction-pass false\n</code></pre> <p>Among other information, the minimizer prints the leaked values:</p> <pre><code>  &gt; Minimizing the difference between inputs 2 and 3\n\nAddress    +0x0     +0x40    +0x80    +0xc0    +0x100   +0x140   +0x180   +0x1c0\n0x00000000 ........ ....=... ........ ........ ........ ........ ........ ........\n0x00000200 ........ ........ ........ ........ ........ ........ ........ ........\n0x00000400 ........ ........ ........ ........ ........ ........ ........ ........\n0x00000600 ........ ........ ........ ........ ........ ........ ........ ........\n0x00000800 ........ ........ ........ ........ ........ ........ ........ ........\n0x00000a00 ........ ........ ........ ........ ........ ........ ........ ........\n0x00000c00 ........ ........ ........ ........ ........ ........ ........ ........\n0x00000e00 ........ ........ ........ ........ ........ ........ ........ ........\n0x00001000 ........ ........ ........ ........ ........ ........ ........ ........\n0x00001200 ........ ........ ........ ........ ........ ........ ........ ........\n0x00001400 ........ ........ ........ ........ ........ ........ ........ ........\n0x00001600 ........ ........ ........ ........ ........ ........ ........ ........\n0x00001800 ........ ........ ........ ........ ........ ........ ........ ........\n0x00001a00 ........ ........ ........ ........ ........ ........ ........ ........\n0x00001c00 ........ ........ ........ ........ ........ ........ ........ ........\n0x00001e00 ........ ........ ........ ........ ........ ........ ........ ........\n0x00002000 ....^...\n0x00002040 ........ ........ ........ ........\n  &gt; Result: Leaked 1 bytes\n  &gt; Addresses: ['0x2020']\n</code></pre> <p>There are two bits of information that we learn from here:</p> <ul> <li>Most of the input has been successfully zeroed-out (<code>.</code>). This means it is likely irrelevant to the leak.</li> <li>The only non-zero byte is at address <code>0x2020</code> (marked with <code>^</code>). This is likely the leaked byte.</li> </ul> <p>To understand how this address maps to the test case, we need to look at the layout of the input: here. We can see that the leak is within the GPR region of actor 0 (the only actor in this test case). Specifically, 0x2020 - 0x2000 = 0x20, is the offset used to initialize RSI (GPRs are ordered as: <code>rax</code>, <code>rbx</code>, <code>rcx</code>, <code>rdx</code>, <code>rsi</code>, <code>rdi</code>, <code>flags</code>, <code>rsp</code>).</p> <p>Now we just need to find how the test case uses RSI (possibly speculatively), and we will have a good idea of the root-cause of the leak.</p> <p>Let's inspect the minimized program in <code>./violation/min.asm</code>:</p> <pre><code>.intel_syntax noprefix\n.section .data.main\n.function_0:\n.macro.measurement_start: nop qword ptr [rax + 0xff]\nadd al, -118\nand rdi, 0b1111111111100\nadc al, byte ptr [r14 + rdi]\n# mem access: [5] 0x1578 cl 21:56 | [15] 0x1578 cl 21:56\nmov rax, -1332388169\nimul eax, eax, -75\nand rcx, 0b1111111111000\nadd dword ptr [r14 + rcx], eax\n# mem access: [5] 0x2498-0x2498 cl 18:24 | [15] 0x2498-0x2498 cl 18:24\nand rax, 0b1111111111000\nimul qword ptr [r14 + rax]\n# mem access: [5] 0x1060 cl 1:32 | [15] 0x1060 cl 1:32\nand rcx, 0b1111111000000\nlock inc qword ptr [r14 + rcx]\n# mem access: [5] 0x2480-0x2480 cl 18:0 | [15] 0x2480-0x2480 cl 18:0\nand rdi, 0b1111111111000\nadd byte ptr [r14 + rdi], al\n# mem access: [5] 0x1578-0x1578 cl 21:56 | [15] 0x1578-0x1578 cl 21:56\nsub dl, al\njp .bb_0.1\njmp .exit_0\n.bb_0.1:\nand rbx, 0b1111111111000\ncmp dword ptr [r14 + rbx], eax\nand rdi, 0b1111111111000\ncmp qword ptr [r14 + rdi], rbx\nand rbx, 0b1111111000000\nlock sub word ptr [r14 + rbx], dx\nand rbx, 0b1111111111000\ndec word ptr [r14 + rbx]\nand rsi, 0b1111111111000\nneg qword ptr [r14 + rsi] # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; HERE: RSI is used here\nand rbx, 0b1111111111000\nadc ax, word ptr [r14 + rbx]\n.exit_0:\n.macro.measurement_end: nop qword ptr [rax + 0xff]\n.section .data.main\n.test_case_exit:nop\n</code></pre> <p>We can see that RSI is used in the instruction at line 36:</p> <pre><code>neg qword ptr [r14 + rsi]\n</code></pre> <p>That already gives most of the information we need. We can see a clear Spectre V1 pattern here:</p> <ol> <li>There is a conditional branch at line 24 (<code>jp .bb_0.1</code>)</li> <li>And a load of a previously-unused value on a mispredicted path (line 36)</li> </ol> <p>To verify that, let's inspect the actual value of RSI in the violating inputs (inputs 2 and 3 according to the minimizer output above). We can use <code>hexdump</code> for that:</p> <pre><code>$ hexdump -C ./violation/min-inputs/min_input_0002.bin | grep 2020\n00002020  93 22 00 00 93 22 00 00  00 00 00 00 00 00 00 00  |.\"...\"..........|\n$ hexdump -C ./violation/min-inputs/min_input_0003.bin | grep 2020\n00002020  40 00 00 00 40 00 00 00  00 00 00 00 00 00 00 00  |@...@...........|\n</code></pre> <p>So the value of RSI were:</p> <ul> <li>Input 2: <code>rsi=0x0000229300002293</code></li> <li>Input 3: <code>rsi=0x0000004000000040</code></li> </ul> <p>These values were masked by the instruction at line 35:</p> <pre><code>and rsi, 0b1111111111000 # instrumentation\n</code></pre> <p>Which means that the values of RSI used in memory accesses at line 36 were:</p> <ul> <li>Input 2: <code>0x0000229300002293 &amp; 0b1111111111000 = 0x290</code></li> <li>Input 3: <code>0x0000004000000040 &amp; 0b1111111111000 = 0x040</code></li> </ul> <p>All memory accesses within the test case are relative to <code>r14</code>, which is page-aligned and points to the base of the sandbox memory.</p> <p>Therefore, we can calculate the ID of the cache lines accessed by the instruction at line 36 as follows:</p> <ul> <li>Input 2: cache line ID = <code>0x290 // 0x40 = 0xa = 10</code></li> <li>Input 3: cache line ID = <code>0x040 // 0x40 = 0x1 = 1</code></li> </ul> <p>So, if our hypothesis is correct, we should see that in the hardware trace of the violation, cache lines 10 and 1 were accessed when executing inputs 2 and 3. Let's verify it by running rvzr in the reproduce mode:</p> <pre><code>$ ./revizor.py reproduce -s base.json -c ./violation/reproduce.yaml -t ./violation/min.asm -i ./violation/min-inputs/min_input_*.bin\n\n-----------------------------------------------------------------------------------\n                             HTrace                              | ID:2   | ID:3  |\n-----------------------------------------------------------------------------------\n^^........^..................................................... | 626    | 0     |\n^^.............................................................. | 1      | 627   |\n</code></pre> <p>The first hardware trace (dominant for input 2) is:</p> <pre><code>^^........^.....................................................\n||        |\n||        Cache set 10 accessed\n|Cache set 1\nCache set 0 accessed\n</code></pre> <p>The second hardware trace (dominant for input 3) is:</p> <pre><code>^^..............................................................\n||\n| Cache set 1 accessed\nCache set 0 accessed\n</code></pre> <p>Indeed, we see that our hypothesis is correct! The instruction at line 36 accessed different cache lines depending on the value of RSI, which was influenced by speculative execution after the conditional branch at line 24.</p> <p>This tells us that the root-cause of the leak was misprediction of a conditional branch that led to speculative leak of a value (RSI) through a data access.</p>"},{"location":"intro/tutorial2-first-vuln/part3/#summary","title":"Summary","text":"<p>Congratulations! We've successfully detected and analyzed a Spectre V1 vulnerability from start to finish.</p> <p>What We've Learned</p> <p>In this section, we've walked through the complete workflow for detecting speculative execution vulnerabilities:</p> <ul> <li>Strategic planning: Choosing a minimal instruction set and appropriate contract focused our search</li> <li>Violation detection: Revizor found the vulnerability automatically in under two minutes</li> <li>Validation: Reproduction confirmed the violation was genuine and stable</li> <li>Minimization: We reduced a complex test case to its essential components</li> <li>Root-cause analysis: By examining register values and cache access patterns, we identified the exact mechanism of the leak</li> </ul> <p>This same workflow applies to discovering and analyzing any speculative execution vulnerability.</p>"},{"location":"intro/tutorial2-first-vuln/part3/#whats-next","title":"What's Next?","text":"<p>Proceed to Tutorial 3 to see how the same principles can be applied to detect more complex vulnerabilities based on CPU exceptions and faults.</p>"},{"location":"intro/tutorial3-faults/part1/","title":"Tutorial 3: Testing faults with Revizor (Part 1)","text":"<p>Having detected Spectre V1, let's now apply the same methodology to find a different vulnerability class. Meltdown-style vulnerabilities exploit speculative execution around exception handling rather than branch misprediction.</p> <p>Important</p> <p>This tutorial relies on the knowledge about sandboxed execution and the memory layout of the sandbox. If you haven't read about it yet, please refer to the Sandbox Reference and the Actors and Isolation Topic Guide before proceeding.</p>"},{"location":"intro/tutorial3-faults/part1/#plan-the-campaign","title":"Plan the campaign","text":"<p>The key difference in this campaign is the speculation source. Instead of conditional branches, we'll test page faults. Meltdown and related vulnerabilities occur when a CPU speculatively executes instructions that follow a faulting memory access, potentially leaking data from inaccessible memory regions.</p> <p>From the practical standpoint, the key difference that we will need to configure the sandbox to make it possible for the test case to trigger page faults. Namely, we will make one of the pages accessible by the test cases non-readable.</p>"},{"location":"intro/tutorial3-faults/part1/#create-the-configuration-file","title":"Create the configuration file","text":"<p>Our configuration for this campaign makes three important changes from the Spectre V1 setup. First, we remove <code>BASE-COND_BR</code> from the instruction categories since we already know conditional branches cause Spectre V1 violations. This focuses our testing on other speculation sources.</p> <p>Second, we add an <code>actors</code> section with <code>data_properties</code> to configure the sandbox memory layout. Revizor's sandbox allocates each actor two 4KB memory regions: a main area with normal read-write permissions and a faulty area where we can configure special permissions. By setting <code>present: false</code> in the data properties, we mark the faulty area as non-present in the page tables. When the test case attempts to access this region, the CPU will raise a page fault, giving us the exception-based speculation source we want to test.</p> <p>Third, we change the contract execution clause to <code>delayed-exception-handling</code>. Modern CPUs implement out-of-order execution, so data-independent instructions after a fault may execute before the exception is recognized. This is expected behavior and would cause trivial violations under the strict <code>no_speculation</code> contract. The <code>delayed-exception-handling</code> clause accommodates this expected speculation, allowing Revizor to focus on more interesting leaks. For more details on contract selection, see How to Choose a Contract.</p> <pre><code># contract\ncontract_observation_clause: loads+stores+pc\ncontract_execution_clause:\n  - delayed-exception-handling\n\n# tested instructions\ninstruction_categories:\n  - BASE-BINARY\n  # - BASE-COND_BR\n\nactors:\n  - main:\n    - data_properties:\n      - present: false\n\nenable_speculation_filter: true\nenable_observation_filter: true\nenable_fast_path_model: true\n</code></pre>"},{"location":"intro/tutorial3-faults/part1/#whats-next","title":"What's Next?","text":"<p>Part 2 will walk you through running the campaign.</p>"},{"location":"intro/tutorial3-faults/part2/","title":"Tutorial 3: Testing faults with Revizor (Part 2)","text":"<p>This tutorial picks up where part 1 left off. We will run the fuzzer with the configuration you've created, and see the results.</p>"},{"location":"intro/tutorial3-faults/part2/#run-the-fuzzer","title":"Run the fuzzer","text":"<p>With the configuration ready, let's run the fuzzer.</p> <pre><code>$ ./revizor.py fuzz -s base.json -c dbg/tut/2.yaml -n 1000 -i 20 -w .\n\nINFO: [fuzzer] Starting at 12:05:26\n66    ( 7%)| Stats: Cls:19/19,In:40,R:19,SF:0,OF:0,Fst:6,CN:60,CT:0,P1:0,CS:0,P2:0,V:0\n</code></pre> <p>Notice in the statistics that <code>SF:0,OF:0</code>\u2014unlike the Spectre V1 campaign, none of our test cases are filtered by the speculation or observation filters since every test case with a page fault exhibits speculation.</p> <p>Eventually (after a few minutes), Revizor detects a violation:</p> <pre><code>================================ Violations detected ==========================\nViolation Details:\n\n-----------------------------------------------------------------------------------\n                             HTrace                              | ID:3   | ID:23 |\n-----------------------------------------------------------------------------------\n^^.^.......^.........^..^.........................^............^ | 627    | 0     |\n^^.^...^...^............^.........................^............^ | 0      | 627   |\n</code></pre> <p>The output is similar to what we saw in the Spectre V1 campaign, so we won't go into the details of reading the violation report again. The key takeaway is that we've successfully detected a contract violation, and the hardware traces show different cache access patterns for the two inputs.</p>"},{"location":"intro/tutorial3-faults/part2/#validate-the-violation","title":"Validate the violation","text":"<p>As before, we validate the violation by reproducing it:</p> <pre><code>$ ./revizor.py reproduce -s base.json -c ./violation/reproduce.yaml -t ./violation/program.asm -i ./violation/input*.bin\n</code></pre> <p>The output should be similar to the original:</p> <pre><code>================================ Violations detected ==========================\nViolation Details:\n\n-----------------------------------------------------------------------------------\n                             HTrace                              | ID:3   | ID:23 |\n-----------------------------------------------------------------------------------\n^^.^.......^.........^..^.........................^............^ | 627    | 0     |\n^^.^...^...^............^.........................^............^ | 0      | 627   |\n</code></pre> <p>Great! The violation reproduces successfully, confirming it's genuine.</p>"},{"location":"intro/tutorial3-faults/part2/#whats-next","title":"What's Next?","text":"<p>Part 3 will walk you through minimizing and root-causing the violation.</p>"},{"location":"intro/tutorial3-faults/part3/","title":"Tutorial 3: Testing faults with Revizor (Part 3)","text":"<p>This tutorial picks up where part 2 left off. We will minimize and root-cause the violation.</p>"},{"location":"intro/tutorial3-faults/part3/#minimize-the-test-case","title":"Minimize the test case","text":"<p>Now we minimize the test case to make it easier to analyze:</p> <pre><code>./revizor.py minimize -s base.json -c ./violation/minimize.yaml -t ./violation/program.asm  -o ./violation/min.asm -i 10 --num-attempts 3 \\\n    --enable-instruction-pass 1 \\\n    --enable-simplification-pass 1 \\\n    --enable-nop-pass 1 \\\n    --enable-constant-pass 1 \\\n    --enable-mask-pass 1 \\\n    --enable-label-pass 1\n</code></pre> <p>After the minimization completes, verify that the minimized program still reproduces the violation:</p> <pre><code>./revizor.py reproduce -s base.json -c ./violation/reproduce.yaml -t ./violation/min.asm -i ./violation/input*.bin\n\nINFO: [prog_gen] Setting program_generator_seed to random value: 578824\n\nINFO: [fuzzer] Starting at 12:14:08\n&gt; Entering slow path...&gt; Priming  6             &gt; Increasing sample size... to 50&gt; Increasing sample size... to 100&gt; Increasing sample size... to 500&gt; Priming  6\n\n================================ Violations detected ==========================\nViolation Details:\n\n-----------------------------------------------------------------------------------\n                             HTrace                              | ID:11  | ID:31 |\n-----------------------------------------------------------------------------------\n^^.^.......^...^........^.........................^...^........^ | 627    | 0     |\n^^.^.......^...^........^.........................^............^ | 0      | 627   |\n</code></pre>"},{"location":"intro/tutorial3-faults/part3/#identify-the-leaked-value","title":"Identify the leaked value","text":"<p>Next, we minimize the inputs to identify which specific values are being leaked:</p> <pre><code>./revizor.py minimize -s base.json -c ./violation/minimize.yaml -t ./violation/min.asm -o ./violation/min.asm -i 10 --input-outdir ./violation/min-inputs \\\n    --enable-input-diff-pass 1 \\\n    --enable-input-seq-pass 1 \\\n    --enable-comment-pass 1 \\\n    --enable-instruction-pass false\n\n(skipping output for brevity)\n  &gt; Minimizing the difference between inputs 0 and 1\n\nAddress    +0x0     +0x40    +0x80    +0xc0    +0x100   +0x140   +0x180   +0x1c0\n0x00000000 ........ ........ ........ ........ ........ ........ ........ ........\n0x00000200 ........ ........ ........ ........ ........ ........ ........ ........\n0x00000400 ........ ........ ........ ........ ........ ........ ........ ........\n0x00000600 ........ ........ ........ ........ ........ ........ ........ ........\n0x00000800 ........ ........ ........ ........ ........ ........ ........ ........\n0x00000a00 ........ ........ ........ ........ ........ ........ ........ ........\n0x00000c00 ........ ........ ........ ........ ........ ........ ........ ........\n0x00000e00 ........ ........ ........ ........ ........ ........ ........ ........\n0x00001000 ........ ........ ........ ........ ........ ........ ........ ........\n0x00001200 ........ ........ ........ ........ ........ ........ ........ ........\n0x00001400 ........ ........ ........ ........ ........ ........ ........ ........\n0x00001600 ........ ........ ........ ........ ........ ........ ........ ........\n0x00001800 ........ ........ ........ ........ ........ ........ ........ ........\n0x00001a00 ........ ........ ........ ........ ........ ........ ........ ........\n0x00001c00 ........ ........ ........ ........ ........ ........ ........ ........\n0x00001e00 ........ ........ ........ ........ ........ ........ ........ ........\n0x00002000 ..=.=^..\n0x00002040 ........ ........ ........ ........\n  &gt; Result: Leaked 1 bytes\n  &gt; Addresses: ['0x2028']\n  &gt; Saving new inputs in '/home/t-oleksenkoo/revizor/violation/min-inputs'\n  &gt; Violating input IDs: [5, 15]\n</code></pre> <p>Key takeaways:</p> <ul> <li>The leaked value originates from address <code>0x2028</code> in the input, which corresponds to offset <code>0x28</code> in the GPR initialization region of the sandbox memory, used to initialize the <code>RDI</code> register.</li> <li>Two other values in the input were not zeroed out, which indicates they are somehow relevant to triggering the violation. Namely, those are offsets <code>0x10</code> and <code>0x20</code>, which correspond to <code>RCX</code> and <code>RSI</code>.</li> </ul>"},{"location":"intro/tutorial3-faults/part3/#perform-root-cause-analysis","title":"Perform root-cause analysis","text":"<p>With the minimized program and inputs, we can now investigate the root cause. The minimized program is as follows:</p> <pre><code>.intel_syntax noprefix\n.section .data.main\n.function_0:\n.macro.measurement_start: nop qword ptr [rax + 0xff]\nand rsi, 0b1111111111000 # instrumentation\nadd rdi, qword ptr [r14 + rsi]\nadd cl, dl\nand rcx, 0b1111111111000 # instrumentation\nadd qword ptr [r14 + rcx], rbx\nand rbx, 0b1111111111000 # instrumentation\nadd dword ptr [r14 + rbx], ecx\nand rax, 0b1111111111000 # instrumentation\ncmp dword ptr [r14 + rax], ecx\nand rdi, 0b1111111111000 # instrumentation\nor byte ptr [r14 + rdi], 1 # instrumentation  # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; HERE: RDI is used here\nmov ax, 1 # instrumentation\ndiv byte ptr [r14 + rdi]                      # &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; HERE: RDI is used here\nand rsi, 0b1111111111000 # instrumentation\nsub byte ptr [r14 + rsi], bl\nand rcx, 0b1111111111000 # instrumentation\nsub al, byte ptr [r14 + rcx]\nand rcx, 0b1111111111000 # instrumentation\nmul qword ptr [r14 + rcx]\nand rax, 0b1111111000000 # instrumentation\nlock sub word ptr [r14 + rax], -128\n.macro.measurement_end: nop qword ptr [rax + 0xff]\n.section .data.main\n.test_case_exit:nop\n</code></pre> <p>RDI is used in two places:</p> <ol> <li>Line 15: <code>or byte ptr [r14 + rdi], 1</code> (a write)</li> <li>Line 17: <code>div byte ptr [r14 + rdi]</code> (a read)</li> </ol> <p>This is a clear data-dependent pattern, which explains why RDI is being leaked. But normally, these patterns should not be reported as violations of CT-DEH (our selected contract), since the contract permits cache-based leakage. So if the violation was reported, it means these instructions were not executed in the model. Let's investigate why.</p> <p>We will inspect how the model executes this program. To this end, we will add a debug flag to the config file:</p> <pre><code>logging_modes:\n    - dbg_model\n</code></pre> <p>Then, we will reproduce the violation again, now with a verbose log of test case execution on the model:</p> <pre><code>./revizor.py reproduce -s base.json -c ./violation/reproduce.yaml -t ./violation/min.asm -i ./violation/min-inputs/min_input_0000.bin\n\n                     ##### Input 0 #####\n0x0 : macro .measurement_start, .noarg\n  rax=0x0000000000000000 rbx=0x0000000000000000 rcx=0x0000d04a0000d04a rdx=0x0000000000000000\n  rsi=0x0000d0510000d051 rdi=0x000056b8000056b8 flags=0b000000000010\n  xmm0=0x00000000000000000000000000000000 xmm1=0x00000000000000000000000000000000\n  xmm2=0x00000000000000000000000000000000 xmm3=0x00000000000000000000000000000000\n  xmm4=0x00000000000000000000000000000000 xmm5=0x00000000000000000000000000000000\n  xmm6=0x00000000000000000000000000000000 xmm7=0x00000000000000000000000000000000\n\n0x8 : and rsi, 0b1111111111000\n  rax=0x0000000000000000 rbx=0x0000000000000000 rcx=0x0000d04a0000d04a rdx=0x0000000000000000\n  rsi=0x0000d0510000d051 rdi=0x000056b8000056b8 flags=0b000000000010\n  xmm0=0x00000000000000000000000000000000 xmm1=0x00000000000000000000000000000000\n  xmm2=0x00000000000000000000000000000000 xmm3=0x00000000000000000000000000000000\n  xmm4=0x00000000000000000000000000000000 xmm5=0x00000000000000000000000000000000\n  xmm6=0x00000000000000000000000000000000 xmm7=0x00000000000000000000000000000000\n\n0xf : add rdi, [r14 +rsi]\n  rax=0x0000000000000000 rbx=0x0000000000000000 rcx=0x0000d04a0000d04a rdx=0x0000000000000000\n  rsi=0x0000000000001050 rdi=0x000056b8000056b8 flags=0b000000000110\n  xmm0=0x00000000000000000000000000000000 xmm1=0x00000000000000000000000000000000\n  xmm2=0x00000000000000000000000000000000 xmm3=0x00000000000000000000000000000000\n  xmm4=0x00000000000000000000000000000000 xmm5=0x00000000000000000000000000000000\n  xmm6=0x00000000000000000000000000000000 xmm7=0x00000000000000000000000000000000\n\n    &gt; load from +0x2050 value 0x0\nEXCEPTION #13: Read from non-readable memory (UC_ERR_READ_PROT)\n0x13: [transient, nesting = 1] add cl, dl\n  rax=0x0000000000000000 rbx=0x0000000000000000 rcx=0x0000d04a0000d04a rdx=0x0000000000000000\n  rsi=0x0000000000001050 rdi=0x000056b8000056b8 flags=0b000000000110\n  xmm0=0x00000000000000000000000000000000 xmm1=0x00000000000000000000000000000000\n  xmm2=0x00000000000000000000000000000000 xmm3=0x00000000000000000000000000000000\n  xmm4=0x00000000000000000000000000000000 xmm5=0x00000000000000000000000000000000\n  xmm6=0x00000000000000000000000000000000 xmm7=0x00000000000000000000000000000000\n\n0x15: [transient, nesting = 1] and rcx, 0b1111111111000\n  rax=0x0000000000000000 rbx=0x0000000000000000 rcx=0x0000d04a0000d04a rdx=0x0000000000000000\n  rsi=0x0000000000001050 rdi=0x000056b8000056b8 flags=0b000000000010\n  xmm0=0x00000000000000000000000000000000 xmm1=0x00000000000000000000000000000000\n  xmm2=0x00000000000000000000000000000000 xmm3=0x00000000000000000000000000000000\n  xmm4=0x00000000000000000000000000000000 xmm5=0x00000000000000000000000000000000\n  xmm6=0x00000000000000000000000000000000 xmm7=0x00000000000000000000000000000000\n\n0x1c: [transient, nesting = 1] add [r14 +rcx], rbx\n  rax=0x0000000000000000 rbx=0x0000000000000000 rcx=0x0000000000001048 rdx=0x0000000000000000\n  rsi=0x0000000000001050 rdi=0x000056b8000056b8 flags=0b000000000110\n  xmm0=0x00000000000000000000000000000000 xmm1=0x00000000000000000000000000000000\n  xmm2=0x00000000000000000000000000000000 xmm3=0x00000000000000000000000000000000\n  xmm4=0x00000000000000000000000000000000 xmm5=0x00000000000000000000000000000000\n  xmm6=0x00000000000000000000000000000000 xmm7=0x00000000000000000000000000000000\n\n    &gt; load from +0x2048 value 0x0\nEXCEPTION #13: Read from non-readable memory (UC_ERR_READ_PROT)\nROLLBACK to 0x7f\n</code></pre> <p>This log shows in detail which instructions from the test case were executed by the model, whether they were transient or non-transient, and the register/memory state before each instruction.</p> <p>We can see that, early in the execution of the test case, a page fault occurs when trying to read from memory at address <code>0x2050</code>. This is because of the configuration we're using, where the second page of the sandbox memory (the faulty page) is set as non-readable.</p> <p>Accordingly, since we're using <code>delayed-exception-handling</code> execution clause, the model will not execute any instructions that are data-dependent on this faulting load. This includes the two instructions that use RDI (lines 15 and 17), since RDI was computed based on the value loaded from address <code>0x2050</code>.</p> <p>From this, we can conclude that the CPU implements some sort of speculation on page faults: The RDI-dependent instructions were not supposed to be executed, but we see leakage of RDI in cache traces nonetheless.</p> <p>To understand what specific value is returned speculatively, we can manually modify the test case, and replace the instructions after the faulting load with a gadget that will specifically leak RDI:</p> <pre><code>.intel_syntax noprefix\n.section .data.main\n\n.macro.measurement_start: nop qword ptr [rax + 0xff]\nand rsi, 0b1111111111000 # instrumentation\nmov rdi, qword ptr [r14 + rsi]\n\nand rdi, 0b111111111111  # mask the value of RDI\nmov rdi, qword ptr [r14 + rdi]\n.macro.measurement_end: nop qword ptr [rax + 0xff]\n\n.test_case_exit:\n</code></pre> <p>Will will also enable another debug mode to see the hardware traces even when no violation is detected:</p> <pre><code>logging_modes:\n    # - dbg_model\n    - dbg_dump_htraces\n</code></pre> <p>Then, we can run the modified test case:</p> <pre><code>$ ./revizor.py reproduce -s base.json -c ./violation/reproduce.yaml \\\n    -t ./violation/min.asm -i ./violation/min-inputs/min_input_0000.bin\n\n================================ Collected Traces =============================\n- Input 0:\n  HTr:\n    ^^.^.......^............^.........................^............^ [10]\n\n  Feedback: (816, 685, 64, 0, 0)\n</code></pre> <p>We see that multiple cache lines were accesses, so it is hard to pinpoint the exact one that belongs to the speculative leak. (We likely have all these evictions due to the page walk triggered by the page fault.)</p> <p>We can identify the specific cache line by further modifying the test case to add an hard offset to the speculative memory access, e.g., changing:</p> <pre><code>mov rdi, qword ptr [r14 + rdi + 0x100]\n</code></pre> <p>Then, we can run it again and see how the hardware trace changes:</p> <pre><code>./revizor.py reproduce -s base.json -c ./violation/reproduce.yaml -t ./violation/min.asm -i ./violation/min-inputs/min_input_0000.bin\n\n================================ Collected Traces =============================\n- Input 0:\n  HTr:\n    ^^.^^......^............^.........................^............^ [10]\n\n  Feedback: (816, 685, 71, 0, 0)\n</code></pre> <p>Let's compare it side-by-side with the previous trace:</p> <pre><code>Before: ^^.^.......^............^.........................^............^\nAfter:  ^^.^^......^............^.........................^............^\n            |\n            + Added cache set access due to +0x100 offset\n              (cache set ID 4)\n</code></pre> <p>This shows that the speculative access used cache set ID 4. From this, we can do a simple calculation to deduce the value of RDI that was used for the memory access:</p> <pre><code>Cache ID = 4\nCache Line Size = 0x40\nHardcoded Offset = 0x100\nSpeculative Address = (Cache ID * Cache Line Size) = rdi + Hardcoded Offset // ignore r14\n=&gt;\nrdi_masked = (Cache ID * Cache Line Size) - Hardcoded Offset = (4 * 0x40) - 0x100 = 0x0\n</code></pre> <p>Now we know that the masked value of RDI used in the speculative access was <code>0x0</code>. The remaining part is to figure out what was the original value of RDI before masking. For that, we can shift the pre-mask value of RDI by 12 bits (since the mask is <code>0b111111111111</code> = 0xfff = 12 bits) and repeat the procedure. We'll do 6 times to reveal the whole value.</p> <p>The resulting traces are as follows:</p> <pre><code>no shift: ^^.^.......^............^.........................^............^\n12 bits:  ^^.^.......^............^.........................^............^\n24 bits:  ^^.^.......^............^.........................^............^\n36 bits:  ^^.^.......^............^.........................^............^\n48 bits:  ^^.^.......^............^.........................^............^\n60 bits:  ^^.^.......^............^.........................^............^\n</code></pre> <p>We can see that in all cases, the cache set accessed is 0, which means that the masked value of RDI was always 0, regardless of how much we shifted it.</p> <p>This tells us that the faulting load returned 0 speculatively, which reveals to us the root cause of the violation. This is an instance of a previously-discovered vulnerability called LVI-Null, which we have successfully and independently rediscovered using Revizor!</p> <p>What We've Learned</p> <p>In this section, we applied the same systematic workflow to a different vulnerability class:</p> <ul> <li>Flexible configuration: By changing just a few configuration options (removing branches, adding page faults, adjusting the contract), we refocused our search entirely</li> <li>Contract selection matters: The <code>delayed-exception-handling</code> contract helped filter out trivial violations while exposing genuine leaks</li> <li>Deep analysis techniques: We manually modified test cases and used offset manipulation to precisely identify what value the CPU returned speculatively</li> </ul> <p>The same workflow\u2014plan, configure, fuzz, validate, minimize, analyze\u2014works across all speculative execution vulnerability classes.</p>"},{"location":"intro/tutorial3-faults/part3/#whats-next","title":"What's Next?","text":"<p>Proceed to Tutorial 4 to see how we can go even further and start testing high-level isolation properties.</p>"},{"location":"intro/tutorial4-isolation/part1/","title":"Tutorial 4: Testing Security Domain Isolation with Revizor","text":"<p>In the previous tutorials, we used random test generation to find Spectre V1 and LVI-Null. While random fuzzing is powerful for discovering unexpected vulnerabilities, some attack scenarios require more structure. In this tutorial, we'll transition to template-based fuzzing to test isolation between security domains\u2014specifically, whether privileged kernel code can leak information to unprivileged user code through speculation.</p>"},{"location":"intro/tutorial4-isolation/part1/#41-understand-the-need-for-templates","title":"4.1. Understand the need for templates","text":"<p>So far, Revizor has been generating completely random test cases. This approach works well when we're testing general speculation sources like branch misprediction or page faults. However, some vulnerability classes require specific execution patterns that are unlikely to appear through pure randomness.</p> <p>Consider testing privilege-based isolation. We want to detect whether a kernel function can leak secrets to user space through speculative execution. This requires a specific structure: user code calls into the kernel, the kernel performs some operation on secret data, control returns to user space, and user space attempts to observe side effects from the kernel's speculative execution. Generating this pattern randomly would be extremely unlikely.</p> <p>Templates solve this problem by letting us specify the high-level structure of test cases while still benefiting from randomization. We define a skeleton that captures the essential attack pattern, then let Revizor fill in the details with random instructions. This combines the best of both worlds: targeted testing for specific scenarios with the coverage benefits of fuzzing.</p>"},{"location":"intro/tutorial4-isolation/part1/#42-write-a-simple-template","title":"4.2. Write a simple template","text":"<p>Let's start with a basic template to understand the syntax. Create a file named <code>simple-template.asm</code>:</p> <pre><code>.intel_syntax noprefix\n\n.section .data.main\n.test_case_enter:\n\n.macro.start_measurement:\n    nop\n\n.function_main:\n    .macro.generate_random_code:\n        instruction_categories: BASE-BINARY\n        min_instructions: 5\n        max_instructions: 10\n\n.macro.end_measurement:\n    nop\n\n.test_case_exit:\n    nop\n</code></pre> <p>This template introduces several new concepts. The <code>.macro.start_measurement</code> and <code>.macro.end_measurement</code> markers tell Revizor when to begin and end side-channel observation. Only code between these markers contributes to the hardware trace\u2014anything outside is setup or cleanup that we don't want to measure.</p> <p>The <code>.macro.generate_random_code</code> directive is where Revizor injects random instructions. The parameters control what gets generated: <code>instruction_categories</code> specifies which instruction types to use, <code>min_instructions</code> and <code>max_instructions</code> set bounds on how many instructions to generate. This gives us controlled randomization\u2014the structure is fixed, but the content varies.</p> <p>The <code>.test_case_enter</code> and <code>.test_case_exit</code> labels mark the entry and exit points of the test case. Revizor's executor uses these to know where to start and stop execution.</p>"},{"location":"intro/tutorial4-isolation/part1/#43-run-template-based-fuzzing","title":"4.3. Run template-based fuzzing","text":"<p>Let's test our template with a simple configuration. Create <code>template-config.yaml</code>:</p> <pre><code># contract\ncontract_observation_clause: loads+stores+pc\ncontract_execution_clause:\n  - no_speculation\n\n# filters\nenable_speculation_filter: true\nenable_observation_filter: true\nenable_fast_path_model: true\n</code></pre> <p>Now run template-based fuzzing:</p> <pre><code>rvzr fuzz -s base.json -c template-config.yaml -t simple-template.asm -n 100 -i 50 -w .\n</code></pre> <p>This command is similar to random fuzzing, but we add the <code>-t</code> flag to specify our template. Revizor will generate 100 test cases, each using the template structure but with different random instructions filled in.</p> <p>The campaign should complete with no violations, just like our baseline in Tutorial 1. This makes sense\u2014we're still just testing arithmetic operations without any speculation sources.</p>"},{"location":"intro/tutorial4-isolation/part1/#44-configure-multi-actor-testing","title":"4.4. Configure multi-actor testing","text":"<p>Now let's move to the real goal: testing isolation between privilege levels. We'll configure a two-actor scenario with a kernel actor and a user actor. Create <code>actors-config.yaml</code>:</p> <pre><code># contract for isolation testing\ncontract_observation_clause: ct-noninterference\ncontract_execution_clause:\n  - delayed-exception-handling\n\n# instruction categories\ninstruction_categories:\n  - BASE-BINARY\n  - BASE-COND_BR\n\n# actor configuration\nactors:\n  - kernel:\n      mode: kernel\n      data_properties:\n        - present: true\n      observer: false\n  - user:\n      mode: user\n      data_properties:\n        - present: true\n      observer: true\n\n# filters\nenable_speculation_filter: true\nenable_observation_filter: true\nenable_fast_path_model: true\n</code></pre> <p>This configuration introduces several important concepts. The <code>contract_observation_clause</code> is set to <code>ct-noninterference</code>, which is specifically designed for testing isolation between actors. This contract checks whether one actor's execution can influence another actor's observations\u2014exactly what we need for detecting cross-privilege leaks.</p> <p>The <code>actors</code> section defines two execution contexts. The <code>kernel</code> actor runs in kernel mode (<code>mode: kernel</code>) and has <code>observer: false</code>, meaning it's the victim whose secrets might leak. The <code>user</code> actor runs in user mode (<code>mode: user</code>) and has <code>observer: true</code>, meaning it's the attacker trying to observe kernel secrets through side channels.</p> <p>Each actor gets its own sandbox memory region configured through <code>data_properties</code>. By setting <code>present: true</code> for both actors, we ensure their memory pages are valid and accessible at their respective privilege levels.</p> <p>For more details on actor configuration, see Topic Guide: Actors.</p>"},{"location":"intro/tutorial4-isolation/part1/#45-write-a-privilege-crossing-template","title":"4.5. Write a privilege-crossing template","text":"<p>Now we need a template that exercises the kernel-user boundary. Create <code>privilege-template.asm</code>:</p> <pre><code>.intel_syntax noprefix\n\n.section .data.main\n.test_case_enter:\n\n.macro.switch_actor:\n    target: kernel\n\n.function_kernel_victim:\n    .macro.generate_random_code:\n        instruction_categories: BASE-BINARY, BASE-COND_BR\n        min_instructions: 10\n        max_instructions: 20\n\n.macro.switch_actor:\n    target: user\n\n.macro.start_measurement:\n    nop\n\n.function_user_observer:\n    .macro.generate_random_code:\n        instruction_categories: BASE-BINARY\n        min_instructions: 5\n        max_instructions: 10\n\n.macro.end_measurement:\n    nop\n\n.test_case_exit:\n    nop\n</code></pre> <p>This template structures the test case to match a typical privilege-crossing attack. The <code>.macro.switch_actor</code> directive tells Revizor to change execution context. We start in kernel mode where we generate random code that might include conditional branches\u2014potential speculation sources. Then we switch to user mode and observe side effects.</p> <p>The measurement markers are positioned to capture only the user actor's execution. This is intentional\u2014we're testing whether the kernel's speculative execution leaves observable traces that user code can detect. By measuring only during user execution, we focus on what an unprivileged attacker could actually observe.</p> <p>Notice that the kernel function allows both <code>BASE-BINARY</code> and <code>BASE-COND_BR</code> instructions, giving it opportunities for branch misprediction. The user function uses only <code>BASE-BINARY</code>, keeping the observation code simple and deterministic.</p>"},{"location":"intro/tutorial4-isolation/part1/#46-run-the-isolation-test","title":"4.6. Run the isolation test","text":"<p>Execute the multi-actor fuzzing campaign:</p> <pre><code>rvzr fuzz -s base.json -c actors-config.yaml -t privilege-template.asm -n 500 -i 30 -w .\n</code></pre> <p>We're running 500 test cases with 30 inputs each. Multi-actor testing often requires more iterations to find violations because we're looking for interactions between actors, which adds complexity.</p> <p>The fuzzer will run and search for isolation violations. Depending on your hardware and microarchitecture, you may or may not find violations. Modern CPUs with properly implemented speculation barriers typically prevent cross-privilege leaks, but older hardware or specific microarchitectural conditions might reveal violations.</p> <pre><code>INFO: [fuzzer] Starting at 16:45:12\n50    (10%)| Stats: Cls:28/30,In:60,R:15,SF:125,OF:18,Fst:12,CN:0,CT:0,P1:0,CS:0,P2:0,V:0\n100   (20%)| Stats: Cls:27/30,In:60,R:15,SF:248,OF:35,Fst:24,CN:0,CT:0,P1:0,CS:0,P2:0,V:0\n150   (30%)| Stats: Cls:29/30,In:60,R:15,SF:372,OF:53,Fst:36,CN:0,CT:0,P1:0,CS:0,P2:0,V:0\n[...]\n</code></pre> <p>Notice that the statistics show non-zero values for speculation filter (<code>SF</code>) and observation filter (<code>OF</code>). This is expected\u2014many of the generated test cases don't produce interesting speculation patterns or observable side effects, so they get filtered out early.</p>"},{"location":"intro/tutorial4-isolation/part1/#47-interpret-noninterference-violations","title":"4.7. Interpret noninterference violations","text":"<p>If a violation is detected, the output format differs from what we saw in previous tutorials:</p> <pre><code>================================ Violations detected ==========================\nNoninterference violation:\n\nActor: kernel (victim)\n  Input 3: &lt;PLACEHOLDER_VALUE_A&gt;\n  Input 7: &lt;PLACEHOLDER_VALUE_B&gt;\n\nActor: user (observer)\n  Observable difference detected between inputs 3 and 7\n  HTrace for input 3:  ^^.....^....^...........................................\n  HTrace for input 7:  ^^.........^....^.......................................\n</code></pre> <p>This violation format reflects the noninterference contract. The report shows that two inputs (3 and 7) differ only in the kernel actor's data, yet the user actor observes different hardware traces. This is a noninterference violation\u2014the kernel's secret data influenced what the user actor could observe, breaking isolation.</p> <p>The hardware traces show different cache access patterns for the two inputs. Even though the user code was identical and the user data was identical, the cache side channel leaked information about the kernel's execution with different secret values.</p> <p>Understanding Actor Roles</p> <p>The <code>observer</code> flag in the actor configuration is crucial. The observer actor is the attacker\u2014the one whose observations we track. The non-observer actors are victims\u2014they might be processing secrets that should remain isolated. Violations occur when observer traces differ based on victim data.</p>"},{"location":"intro/tutorial4-isolation/part1/#48-validate-and-minimize-isolation-violations","title":"4.8. Validate and minimize isolation violations","text":"<p>If you detect a violation, validate it using the same workflow from previous tutorials:</p> <pre><code>mv violation-&lt;timestamp&gt; ./violation\nrvzr reproduce -s base.json -c ./violation/reproduce.yaml -t ./violation/program.asm -i ./violation/input*.bin\n</code></pre> <p>Then minimize:</p> <pre><code>rvzr minimize -s base.json -c ./violation/minimize.yaml -t ./violation/program.asm -o ./violation/min.asm -i 10 --num-attempts 3 \\\n    --enable-instruction-pass 1 \\\n    --enable-simplification-pass 1 \\\n    --enable-nop-pass 1\n</code></pre> <p>The minimized test case will reveal the specific mechanism through which kernel execution leaked to user observation. This might be a cache-based covert channel through speculative memory access, or timing variations that reveal kernel control flow decisions.</p> <p>What We've Learned</p> <p>In this tutorial, we've progressed from random fuzzing to structured testing:</p> <ul> <li>Templates provide structure: When testing specific attack scenarios, templates let us encode the essential pattern while still benefiting from randomization</li> <li>Macros control generation: The macro system gives fine-grained control over what code gets generated and where</li> <li>Multi-actor testing: Revizor can test isolation between different privilege levels or security domains using the actor system</li> <li>Noninterference contract: This specialized contract detects when one actor's data influences another actor's observations</li> <li>Observer vs victim: The observer flag distinguishes attackers (who perform measurements) from victims (whose secrets might leak)</li> </ul> <p>Template-based fuzzing is particularly powerful for testing CPU security boundaries: user-kernel isolation, enclave isolation (SGX), hypervisor-guest isolation, and other privilege-based separations.</p>"},{"location":"intro/tutorial5-extending/part1/","title":"Tutorial 5: Extending Revizor","text":"<p>The previous tutorials covered using Revizor's existing capabilities for standard vulnerability detection. However, security research often requires testing novel attack scenarios that don't fit existing frameworks. In this tutorial, we'll explore how to extend Revizor by customizing its core components: code generators, input generators, and contract clauses. This enables you to adapt Revizor for specialized research questions and emerging vulnerability classes.</p>"},{"location":"intro/tutorial5-extending/part1/#understand-revizors-extension-points","title":"Understand Revizor's extension points","text":"<p>Revizor's architecture is designed for extensibility. The key extension points are:</p> <p>The code generator (<code>code_generator.py</code>) controls how test programs are constructed. While the default generator creates random instruction sequences, you might want to generate programs with specific properties\u2014for example, programs that stress particular execution units, programs that follow specific control flow patterns, or programs that exercise rare instruction combinations. Subclassing <code>CodeGenerator</code> lets you implement custom generation logic while reusing Revizor's infrastructure for assembly output and instrumentation.</p> <p>The input generator (<code>data_generator.py</code>) determines what register and memory values are used as test inputs. The default generator creates random inputs with optional taint-based boosting, but specialized testing might require structured inputs\u2014for example, pointer values that reference specific memory regions, aligned values for testing vector operations, or carefully crafted bit patterns that trigger specific microarchitectural conditions. Custom <code>InputGenerator</code> subclasses can encode domain knowledge about effective test inputs.</p> <p>The contract implementation (<code>model.py</code>) defines what execution behavior is considered correct. While Revizor provides standard contracts like <code>no_speculation</code> and <code>conditional-branch-misprediction</code>, emerging vulnerability classes might require novel contracts. For instance, testing a new speculation source would require a contract that permits that source while flagging others. Extending the contract system involves modifying the model's trace generation and possibly adding new observation modes.</p> <p>Understanding when to extend versus configure is important. Many research questions can be answered by writing templates or adjusting configuration parameters. Only extend Revizor's core when your requirements genuinely exceed what's possible through configuration.</p>"},{"location":"intro/tutorial5-extending/part1/#add-a-custom-instruction-sequence-generator","title":"Add a custom instruction sequence generator","text":"<p>Let's implement a custom code generator that creates programs with a specific pattern: a chain of dependent memory loads followed by a conditional branch. This pattern is useful for testing how CPUs handle speculation with long dependency chains.</p> <p>Create a file <code>custom_generator.py</code>:</p> <pre><code>from typing import List\nfrom rvzr.code_generator import X86Generator\nfrom rvzr.tc_components import Instruction, BasicBlock, Function\n\nclass DependencyChainGenerator(X86Generator):\n    \"\"\"Generates programs with chains of dependent memory loads.\"\"\"\n\n    def __init__(self, instruction_set, seed):\n        super().__init__(instruction_set, seed)\n        self.chain_length = 5  # configurable via config file\n\n    def generate_function(self, name: str) -&gt; Function:\n        \"\"\"Generate a function with a memory dependency chain.\"\"\"\n        # Create the entry basic block\n        entry_bb = BasicBlock(f\"{name}_entry\")\n\n        # Generate a chain of dependent loads\n        # Each load uses the result of the previous load as an address\n        registers = ['rax', 'rbx', 'rcx', 'rdx', 'rsi']\n\n        for i in range(self.chain_length):\n            src_reg = registers[i % len(registers)]\n            dst_reg = registers[(i + 1) % len(registers)]\n\n            # Mask the address to keep it within sandbox bounds\n            mask_insn = Instruction('and', [src_reg, '0b1111111111000'])\n            entry_bb.append(mask_insn)\n\n            # Load from the computed address\n            load_insn = Instruction('mov', [dst_reg, f'[r14 + {src_reg}]'])\n            entry_bb.append(load_insn)\n\n        # Add a conditional branch based on the final value\n        final_reg = registers[self.chain_length % len(registers)]\n        cmp_insn = Instruction('test', [final_reg, final_reg])\n        entry_bb.append(cmp_insn)\n\n        # Create taken and not-taken paths\n        taken_bb = BasicBlock(f\"{name}_taken\")\n        taken_bb.append(Instruction('nop', []))\n\n        not_taken_bb = BasicBlock(f\"{name}_not_taken\")\n        not_taken_bb.append(Instruction('nop', []))\n\n        # Connect blocks\n        entry_bb.add_successor(taken_bb, condition='jnz')\n        entry_bb.add_successor(not_taken_bb, condition='jmp')\n\n        # Build the function\n        func = Function(name)\n        func.add_basic_block(entry_bb)\n        func.add_basic_block(taken_bb)\n        func.add_basic_block(not_taken_bb)\n\n        return func\n</code></pre> <p>This generator creates structured programs instead of random instruction sequences. Each generated function contains a chain of dependent loads where each load address depends on the previous load's result, followed by a conditional branch on the final value.</p> <p>To use this generator, modify your configuration file:</p> <pre><code># custom_config.yaml\ngenerator: custom_generator.DependencyChainGenerator\n\ngenerator_config:\n  chain_length: 8\n\ninstruction_categories:\n  - BASE-BINARY\n  - BASE-COND_BR\n\ncontract_observation_clause: loads+stores+pc\ncontract_execution_clause:\n  - no_speculation\n\nenable_speculation_filter: true\nenable_observation_filter: true\nenable_fast_path_model: true\n</code></pre> <p>Run fuzzing with your custom generator:</p> <pre><code>rvzr fuzz -s base.json -c custom_config.yaml -n 1000 -i 50 -w .\n</code></pre> <p>The fuzzer will now generate test cases with your specific dependency chain pattern, letting you systematically test how the CPU handles speculation in this scenario.</p>"},{"location":"intro/tutorial5-extending/part1/#implement-a-specialized-input-generator","title":"Implement a specialized input generator","text":"<p>Next, let's create an input generator optimized for testing boundary conditions in address calculations. Many speculation vulnerabilities involve edge cases where addresses land on page boundaries or cache line boundaries. A custom input generator can systematically test these conditions.</p> <p>Create <code>boundary_input_generator.py</code>:</p> <pre><code>from typing import List\nimport numpy as np\nfrom rvzr.data_generator import X86DataGenerator\nfrom rvzr.test_case_data import InputData\n\nclass BoundaryValueGenerator(X86DataGenerator):\n    \"\"\"Generates inputs targeting boundary conditions.\"\"\"\n\n    def __init__(self, instruction_set, seed):\n        super().__init__(instruction_set, seed)\n        self.page_size = 4096\n        self.cache_line_size = 64\n\n    def generate_input(self, test_case) -&gt; InputData:\n        \"\"\"Generate an input with boundary-focused values.\"\"\"\n        input_data = InputData()\n\n        # Initialize memory with random data\n        input_data.memory = self._random_memory()\n\n        # Generate boundary-focused register values\n        registers = []\n        boundary_types = [\n            0,                          # Zero (common special case)\n            self.cache_line_size - 1,   # Last byte of cache line\n            self.cache_line_size,       # First byte of next cache line\n            self.page_size - 8,         # Near end of page\n            self.page_size,             # Page boundary\n            self.page_size + 8,         # Just past page boundary\n        ]\n\n        # Randomly select from boundary values for each register\n        for _ in range(16):  # 16 general-purpose registers\n            value = self.rng.choice(boundary_types)\n            registers.append(value)\n\n        input_data.registers = np.array(registers, dtype=np.uint64)\n\n        return input_data\n\n    def _random_memory(self) -&gt; np.ndarray:\n        \"\"\"Generate random memory content.\"\"\"\n        mem_size = self.page_size * 2  # Two pages\n        return self.rng.integers(0, 256, size=mem_size, dtype=np.uint8)\n</code></pre> <p>This generator creates inputs where register values are carefully chosen to test boundary conditions rather than being uniformly random. When combined with the dependency chain generator above, this systematically tests speculation with boundary-crossing addresses.</p> <p>Configure it in your YAML file:</p> <pre><code>input_generator: boundary_input_generator.BoundaryValueGenerator\n\ngenerator: custom_generator.DependencyChainGenerator\n\ngenerator_config:\n  chain_length: 5\n</code></pre> <p>This combination of custom code and input generators creates a highly targeted testing campaign focused on your specific research question.</p>"},{"location":"intro/tutorial5-extending/part1/#extend-the-contract-system","title":"Extend the contract system","text":"<p>Finally, let's extend Revizor's contract system to implement a custom execution clause. Suppose you're researching a hypothetical new speculation source: speculative execution beyond serializing instructions. You want a contract that permits normal speculation sources but flags speculation across serializing boundaries.</p> <p>This requires modifying the model's speculation logic. Open <code>rvzr/model_uc/x86_unicorn.py</code> (or the DynamoRIO equivalent) and locate the speculation handling code in the <code>Speculator</code> class:</p> <pre><code># In x86_unicorn.py, within the Speculator class\n\ndef should_permit_speculation(self, context) -&gt; bool:\n    \"\"\"Determine if speculation is allowed at the current program point.\"\"\"\n\n    # Get the contract execution clause\n    clause = self.contract.execution_clause\n\n    if clause == 'no_speculation':\n        return False\n\n    if clause == 'conditional-branch-misprediction':\n        # Permit speculation after conditional branches\n        if context.last_instruction_was_conditional_branch:\n            return True\n        return False\n\n    if clause == 'custom-serializing-boundary':\n        # Custom clause: permit speculation except across serializing instructions\n        if context.last_instruction_was_serializing:\n            return False\n        return True\n\n    # Default: permit speculation\n    return True\n</code></pre> <p>To support your custom clause, you also need to track serializing instructions. Modify the instruction execution handler:</p> <pre><code># In the instruction execution hook\n\ndef _hook_insn(self, uc, address, size, user_data):\n    \"\"\"Hook called for each instruction execution.\"\"\"\n\n    # Decode the instruction\n    insn = self.decoder.decode(address, size)\n\n    # Track if this is a serializing instruction\n    serializing_instructions = ['cpuid', 'lfence', 'mfence', 'sfence']\n    context.last_instruction_was_serializing = insn.mnemonic in serializing_instructions\n\n    # Continue normal execution...\n</code></pre> <p>Now you can use your custom contract clause in configuration files:</p> <pre><code>contract_observation_clause: loads+stores+pc\ncontract_execution_clause:\n  - custom-serializing-boundary\n\ninstruction_categories:\n  - BASE-BINARY\n  - BASE-COND_BR\n  - BASE-MISC  # includes serializing instructions\n</code></pre> <p>Running campaigns with this contract will specifically test whether the CPU respects serializing instruction boundaries during speculation.</p>"},{"location":"intro/tutorial5-extending/part1/#contribute-your-extensions","title":"Contribute your extensions","text":"<p>If your extension solves a general problem or enables testing for a broad class of vulnerabilities, consider contributing it back to the Revizor project. The contribution process involves:</p> <p>Fork the repository on GitHub and create a feature branch for your extension. Document your code with docstrings explaining what research question your extension addresses and how to use it. Add unit tests in the <code>tests/</code> directory demonstrating your extension's behavior. Update the relevant documentation in <code>docs/</code> to explain when and how researchers should use your extension.</p> <p>Open a pull request with a clear description of the problem your extension solves, example use cases, and any relevant research context. The maintainers will review your contribution and provide feedback. Once accepted, your extension becomes part of Revizor's standard toolkit, benefiting the broader research community.</p> <p>For detailed contribution guidelines, see How to Contribute.</p>"},{"location":"intro/tutorial5-extending/part1/#extension-best-practices","title":"Extension best practices","text":"<p>When extending Revizor, follow these principles to maintain code quality and usability:</p> <p>Document your assumptions. If your extension makes assumptions about the ISA, microarchitecture, or attack model, document them clearly. Future users need to understand when your extension is appropriate.</p> <p>Maintain separation of concerns. Keep extension logic isolated in subclasses rather than modifying core Revizor code. This makes your extensions easier to maintain and reduces the risk of breaking existing functionality.</p> <p>Provide configuration options. Hardcoded parameters limit reusability. Expose tunable parameters through the configuration system so others can adapt your extension to their needs.</p> <p>Test thoroughly. Extensions often encode subtle domain knowledge that's easy to get wrong. Write comprehensive tests covering edge cases and validate your extension's behavior against known vulnerabilities before using it for novel research.</p> <p>Share your findings. When your extension discovers a vulnerability, publish both the vulnerability details and the extension methodology. This helps other researchers understand how to apply similar techniques to their work.</p> <p>What We've Learned</p> <p>In this tutorial, we've explored Revizor's extensibility:</p> <ul> <li>Custom code generators: Create structured test programs tailored to specific attack patterns</li> <li>Specialized input generators: Generate targeted inputs that exercise boundary conditions or specific value ranges</li> <li>Contract extensions: Implement novel contracts that capture emerging vulnerability classes</li> <li>Contribution process: Share your extensions with the research community through open-source contribution</li> <li>Extension best practices: Maintain code quality and usability when customizing Revizor</li> </ul> <p>Revizor's extensibility transforms it from a tool into a research platform. By customizing its core components, you can explore novel attack surfaces and test hypotheses that standard configurations can't address.</p>"},{"location":"intro/tutorial5-extending/part1/#whats-next","title":"What's Next?","text":"<p>And that's it. You've competed the whole tutorial series. Congrats!</p> <p>Now go forth and find some vulnerabilities! And if you build some useful extensions to Revizor in the process, consider contributing them back to the project so others can benefit from your work. Happy hunting!</p>"},{"location":"ref/","title":"Reference Documentation","text":"<p>Complete technical reference for all Revizor components, commands, configuration options, and formats.</p>"},{"location":"ref/#user-facing-components","title":"User-Facing Components","text":"<ul> <li>Command Line Interface Complete reference for all <code>rvzr</code> command-line options and arguments. Covers common options and mode-specific parameters.</li> <li> <p>Execution Modes Detailed specifications for all execution modes: fuzzing, template fuzzing, reproduce, minimize, analyse, generate, and download_spec.</p> </li> <li> <p>Configuration Options Complete reference for all configuration file parameters organized by component: fuzzer, generator, executor, model, analyser, and actors.</p> </li> <li> <p>Macros Reference Complete reference for all template macros including measurement control, fault handling, code generation, and actor transitions.</p> </li> <li> <p>Minimization Passes Complete list of available minimization passes for reducing test case complexity while preserving violations.</p> </li> </ul>"},{"location":"ref/#architecture-internals","title":"Architecture &amp; Internals","text":"<p>Low-level technical references for Revizor's internal components.</p> <ul> <li> <p>Binary Formats Specifications for Revizor's binary file formats: RCBF (Revizor Contract Binary Format) and RDBF (Revizor DynamoRIO Binary Format).</p> </li> <li> <p>Registers Register specifications and conventions for x86-64 and ARM64 architectures.</p> </li> <li> <p>Sandbox Memory layout and sandboxing mechanisms used during test execution.</p> </li> </ul>"},{"location":"ref/artifact-file-formats/","title":"Artifact File Formats","text":"<p>This document describes the structure of violations artifact files stored by Revizor when it detects a contract violation.</p>"},{"location":"ref/artifact-file-formats/#program-artifact-format","title":"Program Artifact Format","text":"<p>The program artifact is stored as an assembly file named <code>program.asm</code> in the violation directory (e.g., <code>violation-&lt;timestamp&gt;/program.asm</code>).</p> <p>The file uses Intel syntax and is structured around actors, with each actor's code placed in a separate section.</p> <p>The program artifact is structured as follows:</p> <pre><code>.intel_syntax noprefix         # Required: Use Intel syntax\n.test_case_enter:              # Required: marks the beginning of the test case\n\n.section .data.main            # Start of \"main\" actor section\n...                            # Instructions for main actor,\n                               # including possible control transfers to other actors\n\n.test_case_exit:               # Required: marks the end of the test case;\n                               # Must be within the \"main\" actor section\n\n.section .data.actor2          # Start of \"actor2\" actor section\n...                            # Instructions for actor2\n</code></pre>"},{"location":"ref/artifact-file-formats/#input-data-artifact-format","title":"Input Data Artifact Format","text":"<p>The inputs to the program are stored as binary files in the violation directory, named according to their order in the input sequence (e.g., <code>violation-&lt;timestamp&gt;/input_004.bin</code>).</p> <p>The format mimics the layout of the sandbox memory, with the only exception that some of the sections are removed as they are irrelevant for input data (e.g., the MACRO STACK and the padding areas).</p> <p>The layout of the input data files is as follows:</p> Offset Actor ID Section Name Size, B 0x0 ACTOR 0 MAIN AREA 0x1000 0x1000 FAULTY AREA 0x1000 0x2000 GPR AREA 0x40 0x2040 SIMD AREA 0x100 0x2140 (unused) 0xec0 0x0 ACTOR 1 MAIN AREA 0x1000 0x1000 FAULTY AREA 0x1000 0x2000 GPR AREA 0x40 0x2040 SIMD AREA 0x100 0x2140 (unused) 0xec0 ... ... ... ..."},{"location":"ref/binary-formats/","title":"Binary Formats in Revizor","text":"<p>Advanced Topic</p> <p>This is an advanced topic describing internal implementation details of Revizor. You are unlikely to need this information unless you are extending or modifying Revizor's core components.</p> <p>This document describes the structure of the custom binary formats used by Revizor to transfer test cases and their data between different components, specifically for transferring generated test cases and their inputs to the executor kernel module and to the DynamoRIO-based model backend.</p> <p>Such custom formats are necessary because the components are implemented in different programming languages and different technologies, so passing objects directly is not possible. Using one of the standard formats (e.g., ELF) is also not an option because test cases in Revizor have special structure (e.g., multiple actors in different execution modes, some instructions are macros, etc.) and this structure is not supported by the standard formats.</p> <p>The formats are designed to as simple as possible to minimize the overhead of serialization and deserialization.</p>"},{"location":"ref/binary-formats/#revizor-code-binary-format-rcbf","title":"Revizor Code Binary Format (RCBF)","text":"<p>RCBF is a structured representation of the complete test case binary, together with its metadata. The structure is as follows:</p> RCBF Structure<pre><code>HEADER (16 bytes total)\n  n_actors:                8 bytes  # Number of Actors in the test case (also equals the number of code sections)\n  n_symbols:               8 bytes  # Number of symbols in the test case\n\nACTOR TABLE (48 x n_actors bytes)\n  actor_entry:             # (repeated n_actors times)\n    id:                    8 bytes  # Unique identifier for the actor\n    mode:                  8 bytes  # Execution mode of the actor\n    pl:                    8 bytes  # Protection level\n    data_permissions:      8 bytes  # Data access permissions\n    data_ept_permissions:  8 bytes  # EPT (Extended Page Table) data permissions\n    code_permissions:      8 bytes  # Code execution permissions\n\nSYMBOL TABLE (32 x n_symbols bytes)\n  symbol_entry:            # (repeated n_symbols times)\n    owner:                 8 bytes  # ID of the actor that owns this symbol\n    offset:                8 bytes  # (Offset of the symbol within its section\n    id:                    8 bytes  # (Symbol's unique identifier\n    args:                  8 bytes  # (Number of arguments the symbol takes (relevant for macros)\n\nMETADATA (24 x n_actors bytes)\n  metadata_entry:\n    owner:                 8 bytes  # (ID of the actor that owns this section\n    size:                  8 bytes  # (Size of the code section in bytes\n    reserved:              8 bytes  # (Reserved for future use\n\nDATA (8 kB x n_actors bytes)\n  code_section:            # (repeated n_actors times)\n    code:                  8 kB     # (Actual assembled binary code for the section\n</code></pre> <p>The file begins with a header containing the number of actors (it is also the number of sections) and the number of symbols in the test case. The term \"symbol\" in this context refers to any location in the test case that can be referenced. Two common types of symbols are functions (specifically, function entry points) and macros.</p> <p>Next, the file contains the actor table, which is an array of actor metadata entries, one for each actor in the test case. The actor metadata entry contains the actor's ID, execution mode, protection level, data permissions, EPT data permissions, and code permissions.</p> <p>After the actor table, the file contains the symbol table, which is an array of symbol entries, one for each symbol in the test case. The symbol entry contains the ID the section to which the symbol belongs, the offset of the symbol within the section, the symbol's ID, and the number of arguments the symbol takes (if it is a macro).</p> <p>The file continues with the table of metadata for each section in the test case. Each metadata entry contains the ID of the actor that owns the section and the size of the section.</p> <p>Finally, the file contains a sequence of code sections, one for each actor in the test case. These sections contain the actual assembled binary for each of the sections in the test case.</p>"},{"location":"ref/binary-formats/#revizor-data-binary-format-rdbf","title":"Revizor Data Binary Format (RDBF)","text":"<p>RDBF is a structured representation of the data used to initialize sandbox memory and registers before executing the test case.</p> <p>Note that this format combines multiple inputs into a single file. This is done because typically, a single test case program is executed multiple times with different inputs, and so it is more efficient to send a batch of inputs at once.</p> RDBF Structure<pre><code>HEADER (16 bytes)\n  n_actors:               8 bytes  # Number of Actors in the test case (also equals the number of data sections)\n  n_inputs:               8 bytes  # Number of inputs in the batch\n\nMETADATA (16 x n_actors bytes)\n  metadata_entry:         # (repeated n_actors x n_inputs times)\n    section_size:         8 bytes  # Size of the data section\n    reserved:             8 bytes  # Reserved for future use\n\nDATA (12 x n_actors x n_inputs KB)\n  input:                  # (repeated n_inputs times)\n    data_section:         # (repeated n_actors times)\n      main_area:          4 KB  # Main data area\n      faulty_area:        4 KB  # Faulty page area\n      reg_init_region:    4 KB  # Register initialization area\n</code></pre> <p>The file begins with a section containing the number of actors (equal to the number of sections) and the number of inputs in the batch.</p> <p>Next, the file contains the table of metadata for each data section, which only contains the size of the section.</p> <p>Finally, the file contains a sequence of data sections, one for each actor in the test case and each input in the batch. The data sections are arranged to mirror the data layout in the sandbox memory (see the sandbox memory layout document for more information).</p>"},{"location":"ref/cli/","title":"Command-Line Interface","text":"<p>This document provides a complete reference for all command-line options accepted by the <code>rvzr</code> command (or <code>./revizor.py</code> if running directly from the source tree).</p> <p>CLI vs Configuration Files</p> <p>Revizor is controlled via two interfaces: command line arguments and a configuration file. Command line arguments specify the mode of operation and set high-level parameters (e.g., file paths, number of fuzzing rounds), while the configuration file specifies details of the fuzzing campaign (e.g., the target contract, generation parameters, etc). This document focuses on the former; for information on configuration files, see the configuration documentation.</p>"},{"location":"ref/cli/#general-syntax","title":"General Syntax","text":"<p>The general syntax of the command line is:</p> <pre><code>rvzr MODE [OPTIONS]\n\n# Where MODE can be:\n#   fuzz            fuzzing mode\n#   tfuzz           template fuzzing mode\n#   reproduce       reproduce mode\n#   minimize        test case minimization mode\n#   analyse         stand-alone trace analysis mode\n#   generate        stand-alone generation mode\n#   download_spec   call the script that downloads the instruction set specification\n</code></pre> <p>The available options depend on the selected mode. See Execution Modes for descriptions of each mode's purpose and behavior.</p> <p>For example, a typical way to run Revizor is in fuzzing mode with a command like this:</p> <pre><code>rvzr fuzz -s base.json -n 100 -i 10  -c config.yaml -w ./violations\n</code></pre> <p>This command will run the fuzzer for 100 iterations (i.e., 100 test cases), with 10 inputs per test case. The fuzzer will use the ISA spec stored in the <code>base.json</code> file, and will read the configuration from <code>config.yaml</code>. If the fuzzer finds a violation, it will be stored in the <code>./violations</code> directory.</p>"},{"location":"ref/cli/#fuzzing-mode","title":"Fuzzing Mode","text":"<p>Command-line arguments supported in <code>fuzz</code> mode:</p> <pre><code>  -h, --help            show this help message and exit\n  -c CONFIG, --config CONFIG\n                        Path to the configuration file (YAML) that will be used during fuzzing.\n  -I INCLUDE_DIR, --include-dir INCLUDE_DIR\n                        Path to the directory containing configuration files that included by the main configuration file (received via --config).\n  -s INSTRUCTION_SET, --instruction-set INSTRUCTION_SET\n                        Path to the instruction set specification (JSON) file.\n  -n NUM_TEST_CASES, --num-test-cases NUM_TEST_CASES\n                        Number of test cases.\n  -i NUM_INPUTS, --num-inputs NUM_INPUTS\n                        Number of inputs per test case.\n  -w WORKING_DIRECTORY, --working-directory WORKING_DIRECTORY\n  -t TESTCASE, --testcase TESTCASE\n                        Use an existing test case [DEPRECATED - see reproduce]\n  --timeout TIMEOUT     Run fuzzing with a time limit [seconds]. No timeout when set to zero.\n  --nonstop             Don't stop after detecting an unexpected result\n  --save-violations SAVE_VIOLATIONS\n                        If set, store all detected violations in working directory.\n</code></pre>"},{"location":"ref/cli/#template-fuzzing-mode","title":"Template Fuzzing Mode","text":"<p>Command-line arguments supported in <code>tfuzz</code> mode:</p> <pre><code>  -h, --help            show this help message and exit\n  -c CONFIG, --config CONFIG\n                        Path to the configuration file (YAML) that will be used during fuzzing.\n  -I INCLUDE_DIR, --include-dir INCLUDE_DIR\n                        Path to the directory containing configuration files that included by the main configuration file (received\n                        via --config).\n  -s INSTRUCTION_SET, --instruction-set INSTRUCTION_SET\n                        Path to the instruction set specification (JSON) file.\n  -n NUM_TEST_CASES, --num-test-cases NUM_TEST_CASES\n                        Number of test cases.\n  -i NUM_INPUTS, --num-inputs NUM_INPUTS\n                        Number of inputs per test case.\n  -w WORKING_DIRECTORY, --working-directory WORKING_DIRECTORY\n  -t TEMPLATE, --template TEMPLATE\n                        The template to use for generating test cases\n  --timeout TIMEOUT     Run fuzzing with a time limit [seconds]. No timeout when set to zero.\n  --nonstop             Don't stop after detecting an unexpected result\n  --save-violations SAVE_VIOLATIONS\n                        If set, store all detected violations in working directory.\n</code></pre>"},{"location":"ref/cli/#reproduce-mode","title":"Reproduce Mode","text":"<p>Command-line arguments supported in <code>reproduce</code> mode:</p> <pre><code>  -h, --help            show this help message and exit\n  -c CONFIG, --config CONFIG\n                        Path to the configuration file (YAML) that will be used during fuzzing.\n  -I INCLUDE_DIR, --include-dir INCLUDE_DIR\n                        Path to the directory containing configuration files that included by the main configuration file (received\n                        via --config).\n  -s INSTRUCTION_SET, --instruction-set INSTRUCTION_SET\n                        Path to the instruction set specification (JSON) file.\n  -t TESTCASE, --testcase TESTCASE\n                        Path to the test case\n  -i [INPUTS ...], --inputs [INPUTS ...]\n                        Path to the directory with inputs\n  -n NUM_INPUTS, --num-inputs NUM_INPUTS\n                        Number of inputs per test case. [IGNORED if --input-dir is set]\n</code></pre>"},{"location":"ref/cli/#minimize-mode","title":"Minimize Mode","text":"<p>Command-line arguments supported in <code>minimize</code> mode:</p> <pre><code>  -h, --help            show this help message and exit\n  -c CONFIG, --config CONFIG\n                        Path to the configuration file (YAML) that will be used during fuzzing.\n  -I INCLUDE_DIR, --include-dir INCLUDE_DIR\n                        Path to the directory containing configuration files that included by the main configuration file (received\n                        via --config).\n  -s INSTRUCTION_SET, --instruction-set INSTRUCTION_SET\n                        Path to the instruction set specification (JSON) file.\n  --testcase TESTCASE, -t TESTCASE\n                        Path to the test case program that needs to be minimized.\n  -i NUM_INPUTS, --num-inputs NUM_INPUTS\n                        Number of inputs to the program that will be used during minimization.\n  --testcase-outfile TESTCASE_OUTFILE, -o TESTCASE_OUTFILE\n                        Output path for the minimized test case program.\n  --input-outdir INPUT_OUTDIR\n                        Output directory for storing minimized inputs.\n  --num-attempts NUM_ATTEMPTS\n                        Number of attempts to minimize the test case.\n  --enable-&lt;pass&gt;       Enable a specific pass during minimization.\n</code></pre> <p>See also the minimization documentation for a list of available minimization passes.</p>"},{"location":"ref/cli/#stand-alone-trace-analysis","title":"Stand-alone Trace Analysis","text":"<p>Command-line arguments supported in <code>analyse</code> mode:</p> <pre><code>  -h, --help            show this help message and exit\n  -c CONFIG, --config CONFIG\n                        Path to the configuration file (YAML) that will be used during fuzzing.\n  -I INCLUDE_DIR, --include-dir INCLUDE_DIR\n                        Path to the directory containing configuration files that included by the main configuration file (received\n                        via --config).\n  -s INSTRUCTION_SET, --instruction-set INSTRUCTION_SET\n                        Path to the instruction set specification (JSON) file.\n  --ctraces CTRACES\n  --htraces HTRACES\n</code></pre>"},{"location":"ref/cli/#stand-alone-generation","title":"Stand-alone Generation","text":"<p>Command-line arguments supported in <code>generate</code> mode:</p> <pre><code>  -h, --help            show this help message and exit\n  -c CONFIG, --config CONFIG\n                        Path to the configuration file (YAML) that will be used during fuzzing.\n  -I INCLUDE_DIR, --include-dir INCLUDE_DIR\n                        Path to the directory containing configuration files that included by the main configuration file (received\n                        via --config).\n  -s INSTRUCTION_SET, --instruction-set INSTRUCTION_SET\n                        Path to the instruction set specification (JSON) file.\n  -r SEED, --seed SEED  Add seed to generate test case.\n  -n NUM_TEST_CASES, --num-test-cases NUM_TEST_CASES\n                        Number of test cases.\n  -i NUM_INPUTS, --num-inputs NUM_INPUTS\n                        Number of inputs per test case.\n  -w WORKING_DIRECTORY, --working-directory WORKING_DIRECTORY\n  --permit-overwrite    Permit overwriting existing files.\n</code></pre>"},{"location":"ref/cli/#download-instruction-set-specification","title":"Download Instruction Set Specification","text":"<p>The following command-line arguments are supported in <code>download_spec</code> mode:</p> <pre><code>  -h, --help            show this help message and exit\n  -a ARCHITECTURE, --architecture ARCHITECTURE   The ISA to download the specification for (e.g., x86-64)\n  --outfile OUTFILE, -o OUTFILE   The destination file to save the downloaded specification.\n  --extensions [EXTENSIONS ...]   List of ISA extensions to include in the specification (e.g., SSE, VTX)\n</code></pre>"},{"location":"ref/config/","title":"Configuration Options","text":"<p>Below is a list of the available configuration options for Revizor, which are passed down to Revizor via a config file.</p> <p>For an example of how to write the config file, see demo/big-fuzz.yaml.</p>"},{"location":"ref/config/#fuzzing-configuration","title":"Fuzzing Configuration","text":""},{"location":"ref/config/#fuzzer","title":"<code>fuzzer</code>","text":"<p><code>basic</code> Select the variant of a fuzzer to be used.</p> SyntaxAvailable OptionsOptions Explained <pre><code>fuzzer: &lt;mode&gt;\n</code></pre> <p><code>basic</code> | <code>architectural</code> | <code>archdiff</code></p> <ul> <li><code>basic</code> - normal model-based fuzzing. A violation in this mode indicates that the CPU exposes more information than predicted by the contract. This option should be used in most testing campaigns.</li> <li><code>architectural</code> - self-fuzzing for architectural mismatches between the model and the executor. This option should be used for testing the fuzzer itself, i.e., a violation in this mode indicates a bug in the fuzzer rather then a bug in the CPU. This is useful when running the fuzzer with a previously-untested instruction set, or when a new contract is implemented.</li> <li><code>archdiff</code> - fuzzing for architectural invariants. This is a special mode targeted for for semi-microarchitectural violations, similar to ZenBleed. This mode is experimental and should be used with caution.</li> </ul>"},{"location":"ref/config/#enable_priming","title":"<code>enable_priming</code>","text":"<code>True</code> This option enables or disables priming. It should be set to True in most cases, as priming is crucial for eliminating false positives. What is priming?: Priming solves the following problem: Revizor collects hardware traces for inputs in a sequence, and the microarchitectural state is not reset between the inputs. This means that the microarchitectural state for the input at, for example, position 100 is different from the state for the input at position 200. Accordingly, the hardware traces for these inputs may differ because the measurements are taken in different microarchitectural contexts. <p>To address this issue, we use priming, which swaps the inputs in the sequence and re-runs the tests. For example, if the original sequence is <code>(i1 . . . i99,i100,i101 . . . i199,i200)</code>, the priming sequence will be <code>(i1 . . . i99,i200,i101 . . . i199,i100)</code>. If the violation persists in this sequence, it is a true positive. If the violation disappears, it is a false positive, and it will be discarded.</p> Syntax <pre><code>enable_priming: &lt;True|False&gt;\n</code></pre>"},{"location":"ref/config/#enable_speculation_filter","title":"<code>enable_speculation_filter</code>","text":"<code>False</code> If enabled, Revizor will not consider test cases that do not trigger speculation. <p>This option is useful for improving the throughput of the fuzzer, but it can discard potential violations if the leakage is not caused by speculation.</p> Syntax <pre><code>enable_speculation_filter: &lt;True|False&gt;\n</code></pre>"},{"location":"ref/config/#enable_observation_filter","title":"<code>enable_observation_filter</code>","text":"<code>False</code> If enabled, Revizor will not consider test cases that do not leave speculative traces. This is achieved by pre-filtering: For each test case, Revizor adds an <code>LFENCE</code> after each instruction in the test case, and compares the resulting hardware traces with the original. If the traces are identical, the test case is discarded without further processing. <p>This option is useful for improving the throughput of the fuzzer, but it can discard potential violations if the leakage is not caused by speculation.</p> Syntax <pre><code>enable_observation_filter: &lt;True|False&gt;\n</code></pre>"},{"location":"ref/config/#enable_fast_path_model","title":"<code>enable_fast_path_model</code>","text":"<code>True</code> If enabled, the fuzzer will assume that all boosted inputs produce the same contract trace, and thus it will re-use the contract trace of the original input for all its boosted variants. This is normally a valid assumption to make if the taint tracker in the model does not contain bugs. <p>This option is a pure performance optimization. It only impacts the speed of fuzzing, and not its correctness.</p> Syntax <pre><code>enable_fast_path_model: &lt;True|False&gt;\n</code></pre>"},{"location":"ref/config/#color","title":"<code>color</code>","text":"<p> <code>False</code> If enabled, the output will be colored. This option is helps a lot with readability, but may produce corrupted output when redirected to a file.</p> Syntax <pre><code>color: &lt;True|False&gt;\n</code></pre>"},{"location":"ref/config/#logging_modes","title":"<code>logging_modes</code>","text":"<p> <code>[info, stat]</code> Control the information logged by Revizor.</p> SyntaxAvailable OptionsOptions Explained <pre><code>logging_modes:\n  - &lt;mode1&gt;\n  - &lt;mode2&gt;\n  ...\n</code></pre> <p><code>info</code> | <code>stat</code> | <code>dbg_timestamp</code> | <code>dbg_violation</code> | <code>dbg_dump_htraces</code> | <code>dbg_dump_ctraces</code> | <code>dbg_dump_traces_unlimited</code> | <code>dbg_executor_raw</code> | <code>dbg_model</code> | <code>dbg_coverage</code> | <code>dbg_generator</code> | <code>dbg_priming</code> | <code>dbg_isa_filter</code></p> <ul> <li><code>info</code> - general information about the progress of fuzzing;</li> <li><code>stat</code> - statistics the end of the fuzzing campaign;</li> <li><code>dbg_timestamp</code> - every 1000 test cases print the timestamp during the fuzzing process;</li> <li><code>dbg_violation</code> - upon detecting a violation, print detailed information about it;</li> <li><code>dbg_dump_htraces</code> - print the first 100 hardware traces for every test case;</li> <li><code>dbg_dump_ctraces</code> - print the first 100 contract traces for every test case;</li> <li><code>dbg_dump_traces_unlimited</code> - print ALL traces (use carefully, produces LOTS of text);</li> <li><code>dbg_executor_raw</code> - prints hardware traces for every stage of the fuzzing process; this differs from <code>dbg_dump_htraces</code> in that it prints the traces collected by speculation/observation filters as well as at every iteration of multi-sample collection;</li> <li><code>dbg_model</code> - print a detailed info about EVERY instruction executed on the model (use carefully, produces LOTS of text);</li> <li><code>dbg_coverage</code> - stores instruction coverage information;</li> <li><code>dbg_generator</code> - prints a list of instructions used to generate test cases;</li> <li><code>dbg_priming</code> - prints information about the priming process; only useful for debugging the priming mechanism itself.</li> <li><code>dbg_isa_filter</code> - when rvzr loads information about the instruction set (normally, from <code>base.json</code>), it filters out some of the instructions, either because of the config options provided by the user, or because some instructions are known to cause issues in the model or executor. This debug option prints the list of instructions that were filtered out, along with the reason for filtering them out.</li> </ul>"},{"location":"ref/config/#multiline_output","title":"<code>multiline_output</code>","text":"<p> <code>False</code> If enabled, each output message will be printed on a separate line. Otherwise, the fuzzing progress will be continuously overwriting the same line (works only in the terminal).</p> Syntax <pre><code>enable_priming: &lt;True|False&gt;\n</code></pre>"},{"location":"ref/config/#program-generator-configuration","title":"Program Generator Configuration","text":""},{"location":"ref/config/#instruction_set","title":"<code>instruction_set</code>","text":"<p> The instruction set under test.</p> SyntaxAvailable Options <pre><code>instruction_set: &lt;isa&gt;\n</code></pre> <p><code>x86-64</code> | <code>arm64</code></p>"},{"location":"ref/config/#instruction_categories","title":"<code>instruction_categories</code>","text":"<p> Select a list of instruction categories to be used when generating programs. This list effectively filters out instructions from the ISA descriptor file (e.g., <code>base.json</code>) passed via the command line (<code>-s</code>).</p> <p>Priority</p> <p>This list has higher priority than <code>instruction_blocklist</code> but lower than <code>instruction_allowlist</code>.</p> <p>The resulting instruction pool is: <code>all from(instruction_categories) - instruction_blocklist + instruction_allowlist</code></p> SyntaxAvailable Options <pre><code>instruction_categories:\n  - &lt;category1&gt;\n  - &lt;category2&gt;\n  ...\n</code></pre> <p>Any category in the ISA descriptor file (<code>base.json</code>).</p>"},{"location":"ref/config/#instruction_blocklist","title":"<code>instruction_blocklist</code>","text":"<p> A list of instructions that will not be used for generating programs. This list filters out instructions from <code>instruction_categories</code>, but not from <code>instruction_allowlist</code>.</p> <p>Priority</p> <p>This list has lower priority than <code>instruction_allowlist</code>.</p> <p>The resulting instruction pool is: <code>all from(instruction_categories) - instruction_blocklist + instruction_allowlist</code></p> <p>Danger Zone</p> <p>This option has a somewhat sensible default value for each supported architecture, selected to avoid known-bad instructions. Thus, setting this option explicitly is unadvisable. Prefer using <code>instruction_blocklist_append</code> to add more instructions to the default blocklist.</p> SyntaxAvailable Options <pre><code>instruction_blocklist:\n  - &lt;instruction1&gt;\n  - &lt;instruction2&gt;\n  ...\n</code></pre> <p>Any instruction in the ISA descriptor file (<code>base.json</code>).</p>"},{"location":"ref/config/#instruction_blocklist_append","title":"<code>instruction_blocklist_append</code>","text":"<p> <code>[]</code> A list of instructions that will be appended to the default blocklist for the target ISA. This option is identical to <code>instruction_blocklist</code>, but the list is added to the default instead of replacing it.</p> <p>Priority</p> <p>This list has lower priority than <code>instruction_allowlist</code>.</p> <p>The resulting instruction pool is: <code>all from(instruction_categories) - instruction_blocklist + instruction_allowlist</code></p> SyntaxAvailable Options <pre><code>instruction_blocklist_append:\n  - &lt;instruction1&gt;\n  - &lt;instruction2&gt;\n  ...\n</code></pre> <p>Any instruction in the ISA descriptor file (<code>base.json</code>).</p>"},{"location":"ref/config/#instruction_allowlist","title":"<code>instruction_allowlist</code>","text":"<p> <code>[]</code> A list of instructions to use for generating programs.</p> <p>Priority</p> <p>This list has priority over <code>instruction_categories</code> and over <code>instruction_blocklist</code>, thus adding instructions on top of the categories.</p> <p>The resulting instruction pool is: <code>all from(instruction_categories) - instruction_blocklist + instruction_allowlist</code></p> SyntaxAvailable Options <pre><code>instruction_allowlist:\n  - &lt;instruction1&gt;\n  - &lt;instruction2&gt;\n  ...\n</code></pre> <p>Any instruction in the ISA descriptor file (<code>base.json</code>).</p>"},{"location":"ref/config/#program_generator_seed","title":"<code>program_generator_seed</code>","text":"<p> <code>0</code> Seed of the program generator (aka code generator). If set to zero, a random seed will be used for each run.</p> Syntax <pre><code>program_generator_seed: &lt;seed&gt;\n</code></pre>"},{"location":"ref/config/#program_size","title":"<code>program_size</code>","text":"<p> <code>24</code> Number of instructions in the test case programs to be produced by the code generator. Note that the actual size might be larger because of the instrumentation.</p> Syntax <pre><code>program_size: &lt;size&gt;\n</code></pre>"},{"location":"ref/config/#avg_mem_accesses","title":"<code>avg_mem_accesses</code>","text":"<p> <code>12</code> Average number of memory accesses in the test case programs to be produced by the code generator. The actual number will be random, but the average over all programs will be close to this value.</p> Syntax <pre><code>avg_mem_accesses: &lt;count&gt;\n</code></pre>"},{"location":"ref/config/#min_bb_per_function","title":"<code>min_bb_per_function</code>","text":"<p> <code>1</code> Minimal number of basic blocks per function in generated programs.</p> Syntax <pre><code>min_bb_per_function: &lt;count&gt;\n</code></pre>"},{"location":"ref/config/#max_bb_per_function","title":"<code>max_bb_per_function</code>","text":"<p> <code>2</code> Maximal number of basic blocks per function in generated programs.</p> Syntax <pre><code>max_bb_per_function: &lt;count&gt;\n</code></pre>"},{"location":"ref/config/#min_successors_per_bb","title":"<code>min_successors_per_bb</code>","text":"<p> <code>1</code> Minimal number of successors for each basic block in generated programs.</p> <p>Hint, not a rule</p> <p>This option is a hint; it could be overwritten</p> <ul> <li>if the instruction set does not have the necessary instructions to satisfy it</li> <li>if a certain number of successor is required for correctness.</li> <li>if min_successors_per_bb &gt; max_successors_per_bb, the value is overwritten with max_successors_per_bb</li> </ul> Syntax <pre><code>min_successors_per_bb: &lt;count&gt;\n</code></pre>"},{"location":"ref/config/#max_successors_per_bb","title":"<code>max_successors_per_bb</code>","text":"<p> <code>1</code> Maximal number of successors for each basic block in generated programs.</p> <p>Hint, not a rule</p> <p>This option is a hint; it could be overwritten</p> <ul> <li>if the instruction set does not have the necessary instructions to satisfy it</li> <li>if a certain number of successor is required for correctness</li> </ul> Syntax <pre><code>max_successors_per_bb: &lt;count&gt;\n</code></pre>"},{"location":"ref/config/#register_allowlist","title":"<code>register_allowlist</code>","text":"<p> <code>[]</code> A list of registers that can be used for generating programs.</p> <p>Priority</p> <p>This list has higher priority than <code>register_blocklist</code>. The resulting list is: <code>(all registers - register_blocklist) + register_allowlist</code>.</p> SyntaxAvailable Options <pre><code>register_allowlist:\n  - &lt;register1&gt;\n  - &lt;register2&gt;\n  ...\n</code></pre> <p>Any register supported by the target CPU.</p>"},{"location":"ref/config/#register_blocklist","title":"<code>register_blocklist</code>","text":"<p> A list of registers that will not be used for generating programs.</p> <p>Priority</p> <p>This list has lower priority than <code>register_allowlist</code>. The resulting list is: <code>(all registers - register_blocklist) + register_allowlist</code>.</p> <p>Danger Zone</p> <p>The default value of this option includes registers that reserved for internal use by the executor, and thus should be avoided. Modifying this option may lead to a full system crash.</p> SyntaxAvailable Options <pre><code>register_blocklist:\n  - &lt;register1&gt;\n  - &lt;register2&gt;\n  ...\n</code></pre> <p>Any register supported by the target CPU.</p>"},{"location":"ref/config/#generator_faults_allowlist","title":"<code>generator_faults_allowlist</code>","text":"<p> <code>[]</code> By default, the generator will produce programs that never trigger exceptions. This option modifies this behavior by permitting the generator to produce 'unsafe' instruction sequences that could potentially trigger an exception. The model and executor will also be configured to handle these exceptions gracefully.</p> SyntaxAvailable OptionsOptions Explained <pre><code>generator_faults_allowlist:\n  - &lt;fault1&gt;\n  - &lt;fault2&gt;\n  ...\n</code></pre> <p><code>div-by-zero</code> | <code>div-overflow</code> | <code>opcode-undefined</code> | <code>bounds-range-exceeded</code> | <code>breakpoint</code> | <code>debug-register</code> | <code>non-canonical-access</code> | <code>user-to-kernel-access</code></p> <ul> <li><code>div-by-zero</code> - generate divisions with unmasked divisor, which can cause a division by zero exception.</li> <li><code>div-overflow</code> - generate divisions with unmasked dividend, which can cause an overflow exception.</li> <li><code>opcode-undefined</code> - generate undefined opcodes, which can cause an undefined opcode exception.</li> <li><code>bounds-range-exceeded</code> - apply MPX instructions for random bounds checks. This is possible only if MPX is included in the tested instruction set.</li> <li><code>breakpoint</code> - generate breakpoints, which can cause INT3 exceptions.</li> <li><code>debug-register</code> - generate instructions that cause INT1 exceptions.</li> <li><code>non-canonical-access</code> - randomly select a memory access in a generated program and instrument it to access a non-canonical address.</li> <li><code>user-to-kernel-access</code> - randomly select memory access instructions in user-privilege actors and instrument them to access the kernel actor's (actor 0) memory. This creates cross-privilege-level memory access patterns useful for detecting CPU vulnerabilities like Meltdown. Requires at least one actor with <code>privilege_level: user</code>. The instrumentation modifies both the memory operands and the sandboxing masks to ensure accesses target the kernel's FAULTY data area.</li> </ul>"},{"location":"ref/config/#actor-configuration","title":"Actor Configuration","text":"<p>All actors are defined in the <code>actors</code> list, with the following syntax:</p> <pre><code>actors:\n  - &lt;actor1_name&gt;:\n      &lt;actor_option&gt;: &lt;value&gt;\n      &lt;actor_option&gt;:\n        &lt;sub_option1&gt;: &lt;value1&gt;\n        &lt;sub_option2&gt;: &lt;value2&gt;\n      ...\n  - &lt;actor2_name&gt;:\n      ...\n  ...\n</code></pre> <p>The following options are available for each actor:</p>"},{"location":"ref/config/#mode","title":"<code>mode</code>","text":"<p> <code>host</code> The execution mode of the actor.</p> SyntaxAvailable OptionsOptions Explained <pre><code>actors:\n  - &lt;actor_name&gt;:\n      mode: &lt;mode&gt;\n</code></pre> <p><code>host</code> | <code>guest</code></p> <ul> <li><code>host</code> - the actor runs in the normal, non-virtualized mode.</li> <li><code>guest</code> - the actor runs in a VM (one VM per actor).</li> </ul>"},{"location":"ref/config/#privilege_level","title":"<code>privilege_level</code>","text":"<p> <code>kernel</code> The privilege level of the actor.</p> SyntaxAvailable OptionsOptions Explained <pre><code>actors:\n  - &lt;actor_name&gt;:\n      privilege_level: &lt;level&gt;\n</code></pre> <p><code>user</code> | <code>kernel</code></p> <ul> <li><code>user</code> - the actor runs in user mode (CPL=3).</li> <li><code>kernel</code> - the actor runs in kernel mode (CPL=0).</li> </ul>"},{"location":"ref/config/#data_properties","title":"<code>data_properties</code>","text":"(see below) The properties of the data memory used by the actor. These properties are applied only to the faulty page of the actor's data region (see sandbox for details). <p>Note that the above properties are set in the host page tables for actors with <code>mode: host</code>, and in the guest page tables for actors with <code>mode: guest</code>.</p> SyntaxAvailable OptionsOptions Explained <pre><code>actors:\n  - &lt;actor_name&gt;:\n      data_properties:\n        present: &lt;True|False&gt;\n        writable: &lt;True|False&gt;\n        user: &lt;True|False&gt;\n        accessed: &lt;True|False&gt;\n        dirty: &lt;True|False&gt;\n        executable: &lt;True|False&gt;\n        reserved_bit: &lt;True|False&gt;\n        randomized: &lt;True|False&gt;\n</code></pre> <p><code>present</code> | <code>writable</code> | <code>user</code> | <code>accessed</code> | <code>dirty</code> | <code>executable</code> | <code>reserved_bit</code> | <code>randomized</code></p> <ul> <li><code>present</code> [default: True] - the value of the Present bit in the page table entry.</li> <li><code>writable</code> [default: True] - the value of the Writable bit in the page table entry.</li> <li><code>user</code> [default: False] - the value of the User/Supervisor bit in the page table entry.</li> <li><code>accessed</code> [default: True] - the value of the Accessed bit in the page table entry.</li> <li><code>dirty</code> [default: True] - the value of the Dirty bit in the page table entry.</li> <li><code>executable</code> [default: False] - the value of the Executable bit in the page table entry.</li> <li><code>reserved_bit</code> [default: False] - the value of the Reserved bit in the page table entry.</li> <li><code>randomized</code> [default: False] - if true, the values of the above properties will be randomized for each test case.</li> </ul>"},{"location":"ref/config/#data_ept_properties","title":"<code>data_ept_properties</code>","text":"<code>(see below)</code> The properties of the EPT entry used by the actor (on Intel) or the NPT entry (on AMD). These properties are applied only to the faulty page of the actor's data region (see sandbox for details). <p>This property has no effect on actors with <code>mode: host</code>.</p> SyntaxAvailable OptionsOptions Explained <pre><code>actors:\n  - &lt;actor_name&gt;:\n      data_ept_properties:\n        present: &lt;True|False&gt;\n        writable: &lt;True|False&gt;\n        executable: &lt;True|False&gt;\n        accessed: &lt;True|False&gt;\n        dirty: &lt;True|False&gt;\n        user: &lt;True|False&gt;\n        reserved_bit: &lt;True|False&gt;\n        randomized: &lt;True|False&gt;\n</code></pre> <p><code>present</code> | <code>writable</code> | <code>executable</code> | <code>accessed</code> | <code>dirty</code> | <code>user</code> | <code>reserved_bit</code> | <code>randomized</code></p> <ul> <li><code>present</code> [default: True] - the value of the Present bit in the EPT/NPT entry.</li> <li><code>writable</code> [default: True] - the value of the Writable bit in the EPT/NPT entry.</li> <li><code>executable</code> [default: False] - the value of the Executable bit in the EPT/NPT entry.</li> <li><code>accessed</code> [default: True] - the value of the Accessed bit in the EPT/NPT entry.</li> <li><code>dirty</code> [default: True] - the value of the Dirty bit in the EPT/NPT entry.</li> <li><code>user</code> [default: False] - the value of the User/Supervisor bit in the EPT/NPT entry.</li> <li><code>reserved_bit</code> [default: False] - the value of the Reserved bit in the EPT/NPT entry.</li> <li><code>randomized</code> [default: False] - if true, the values of the above properties will be randomized for each test case.</li> </ul>"},{"location":"ref/config/#observer","title":"<code>observer</code>","text":"<p> <code>False</code> If enabled, the actor will be an observer actor, hence modelling an attacker. This option is only used if the contract is <code>noninterference</code>, and it is ignored otherwise.</p> Syntax <pre><code>actors:\n  - &lt;actor_name&gt;:\n      observer: &lt;True|False&gt;\n</code></pre>"},{"location":"ref/config/#instruction_blocklist_1","title":"<code>instruction_blocklist</code>","text":"<code>[]</code> Actor-specific instruction blocklist. <p>This option is useful when writing a test case template that uses multiple actors, and some actors should use a different set of instructions than the others. For example, if privileged instructions should be blocked for low-privilege actors.</p> <p>Priority</p> <p>This list has priority over the global <code>instruction_blocklist</code> and modifies the instruction pool for the specific actor.</p> Syntax <pre><code>actors:\n  - &lt;actor_name&gt;:\n      instruction_blocklist:\n        - &lt;instruction1&gt;\n        - &lt;instruction2&gt;\n        ...\n</code></pre>"},{"location":"ref/config/#fault_blocklist","title":"<code>fault_blocklist</code>","text":"<code>[]</code> Actor-specific fault blocklist. <p>For example, when using <code>user-to-kernel-access</code>, you typically want to add it to the kernel actor's <code>fault_blocklist</code> to prevent the kernel from accessing its own memory (which would not be a cross-privilege access).</p> <p>Priority</p> <p>This list has priority over the global <code>generator_faults_allowlist</code> and modifies the fault-inducing instrumentation for the specific actor.</p> SyntaxAvailable Options <pre><code>actors:\n  - &lt;actor_name&gt;:\n      fault_blocklist:\n        - &lt;fault1&gt;\n        - &lt;fault2&gt;\n        ...\n</code></pre> <p>See <code>generator_faults_allowlist</code> for the list of available faults.</p>"},{"location":"ref/config/#data-generator-configuration","title":"Data Generator Configuration","text":""},{"location":"ref/config/#data_generator","title":"<code>data_generator</code>","text":"<p> <code>random</code> Select the method of test case data generation.</p> SyntaxAvailable OptionsOptions Explained <pre><code>data_generator: &lt;type&gt;\n</code></pre> <p><code>random</code></p> <ul> <li><code>random</code> - generate random input data for the test cases. This is the only supported option at the moment.</li> </ul>"},{"location":"ref/config/#data_generator_seed","title":"<code>data_generator_seed</code>","text":"<p> <code>10</code> Seed of the test case data generator. If set to zero, a random seed will be used for each run.</p> Syntax <pre><code>data_generator_seed: &lt;seed&gt;\n</code></pre>"},{"location":"ref/config/#data_generator_entropy_bits","title":"<code>data_generator_entropy_bits</code>","text":"<p> <code>16</code> Entropy of the random values created by the data generator.</p> SyntaxAllowed Values <pre><code>data_generator_entropy_bits: &lt;bits&gt;\n</code></pre> <p>Integer in the range <code>[1, 31]</code></p>"},{"location":"ref/config/#input_gen_probability_of_special_value","title":"<code>input_gen_probability_of_special_value</code>","text":"<p> <code>0.05</code> When set to a non-zero value, the data generator will occasionally produce special values (such as zero or MAX_INT) alongside random values, with the frequency controlled by this probability. These special values help exercise fast-path optimizations in the microarchitecture.</p> SyntaxAllowed Values <pre><code>input_gen_probability_of_special_value: &lt;probability&gt;\n</code></pre> <p>Float in the range <code>[0.0, 1.0]</code></p>"},{"location":"ref/config/#inputs_per_class","title":"<code>inputs_per_class</code>","text":"<p> <code>2</code> Number of inputs generated for each input class via input boosting (aka Contract-Driven Input Generation). For the explanation of the input classes and the generation algorithm, see this paper, Section 4.D. Contract-driven Input Generator.</p> Syntax <pre><code>inputs_per_class: &lt;count&gt;\n</code></pre>"},{"location":"ref/config/#contract-configuration","title":"Contract Configuration","text":""},{"location":"ref/config/#contract_execution_clause","title":"<code>contract_execution_clause</code>","text":"<p> <code>['seq']</code> The execution clause of the contract. Multiple clauses can be combined to form a more permissive contract.</p> SyntaxAvailable OptionsOptions Explained <pre><code>contract_execution_clause:\n  - &lt;clause&gt;\n</code></pre> <p><code>seq</code> | <code>no_speculation</code> | <code>seq-assist</code> | <code>cond</code> | <code>conditional_br_misprediction</code> | <code>bpas</code> | <code>nullinj-fault</code> | <code>nullinj-assist</code> | <code>delayed-exception-handling</code> | <code>div-zero</code> | <code>div-overflow</code> | <code>meltdown</code> | <code>fault-skip</code> | <code>noncanonical</code> | <code>vspec-ops-div</code> | <code>vspec-ops-memory-faults</code> | <code>vspec-ops-memory-assists</code> | <code>vspec-ops-gp</code> | <code>vspec-all-div</code> | <code>vspec-all-memory-faults</code> | <code>vspec-all-memory-assists</code></p> <ul> <li><code>seq</code> - sequential execution.</li> <li><code>no_speculation</code> - sequential execution. Synonym for <code>seq</code>.</li> <li><code>seq-assist</code> - sequential execution with possible microcode assists.</li> <li><code>cond</code> - permitted misprediction of conditional branches.</li> <li><code>conditional_br_misprediction</code> - permitted misprediction of conditional branches. Synonym for <code>cond</code>.</li> <li><code>bpas</code> - permitted speculative store bypass</li> <li><code>nullinj-fault</code> - page faults are permitted to speculatively return zero.</li> <li><code>nullinj-assist</code> - microcode assists are permitted to speculatively return zero.</li> <li><code>delayed-exception-handling</code> - upon an exception or a fault, data-independent instructions that follow the exception are allowed to execute speculatively.</li> <li><code>meltdown</code> - permission-based page faults are permitted to speculatively return the value in the memory.</li> <li><code>fault-skip</code> - upon a fault, the faulting instruction is speculatively skipped.</li> <li><code>noncanonical</code> - permitted speculative non-canonical memory accesses.</li> <li><code>vspec*</code> - experimental contracts for value speculation. See this paper for details.</li> <li><code>div-zero</code> - experimental contract; do not use.</li> <li><code>div-overflow</code> - experimental contract; do not use.</li> </ul>"},{"location":"ref/config/#contract_observation_clause","title":"<code>contract_observation_clause</code>","text":"<p> <code>ct</code> The observation clause of the contract. In most cases, the default value should be used.</p> SyntaxAvailable OptionsOptions Explained <pre><code>contract_observation_clause: &lt;clause&gt;\n</code></pre> <p><code>none</code> | <code>l1d</code> | <code>memory</code> | <code>pc</code> | <code>ct</code> | <code>loads+stores+pc</code> | <code>ct-nonspecstore</code> | <code>ctr</code> | <code>arch</code> | <code>tct</code> | <code>tcto</code> | <code>ct-ni</code></p> <ul> <li><code>none</code> - the model observes nothing. Useful for testing the fuzzer.</li> <li><code>l1d</code> - the model observes the addresses of data accesses, adjusted to imitate the L1D cache trace. Has very few real applications, and should be generally avoided.</li> <li><code>memory</code> - the model observes the addresses of data accesses.</li> <li><code>ct</code> (constant time tracer) - the model observes the addresses of data accesses and the control flow.</li> <li><code>loads+stores+pc</code> - the model observes the addresses of data accesses and the control flow. Synonym for <code>ct</code>.</li> <li><code>ct-nonspecstore</code> - the model observes the addresses of data accesses and the control flow, but does not observe the addresses of stores during speculation.</li> <li><code>ctr</code> - the model observes the addresses of data accesses and the control flow, as well as the values of the general-purpose registers.</li> <li><code>arch</code> - the model observes the addresses of data accesses and the control flow, as well as the values loaded from memory. This clause imitates the security guarantees provided by secure speculation mechanisms like STT.</li> <li><code>tct</code> (truncated constant time tracer) - the model observes address of the memory access and of the program counter at cache line granularity.</li> <li><code>tcto</code> (truncated constant time tracer with overflows) - the model address of the memory access and of the program counter at cache line granularity + observe cache line overflows.</li> <li><code>ct-ni</code> - (only available in multi-actor context) when executing actors with <code>observer: false</code>, the model observes the same data as as with <code>ct</code>. When executing actors with <code>observer: true</code>, the model observes complete memory of the actor as well as their register values.</li> </ul>"},{"location":"ref/config/#model_backend","title":"<code>model_backend</code>","text":"<p> <code>unicorn</code> The backend used to implement the contract model.</p> SyntaxAvailable OptionsOptions Explained <pre><code>model_backend: &lt;backend&gt;\n</code></pre> <p><code>dummy</code> | <code>unicorn</code> | <code>dynamorio</code></p> <ul> <li><code>unicorn</code> - use Unicorn-based implementation of the model. This backend is more mature and feature-rich, but it supports a considerably smaller set of instruction than DynamoRIO (essentially, only the base x86 or ARM instruction sets, without any extensions).</li> <li><code>dynamorio</code> - use DynamoRIO-based implementation of the model. This backend is less mature and supports fewer contracts and features than Unicorn, but it can handle a much larger set of instructions, including complex extensions like AVX-512 on x86-64. It is also generally faster than Unicorn, especially when testing large test case or running with many inputs per test case.</li> <li><code>dummy</code> - use a dummy model. This model always returns the same (empty) contract trace, and as such will not produce meaningful results. This option is useful, however, when root-causing violations, because it allows to collect hardware traces without running the model, hence allowing to trace instructions that are not supported by any of the backends.</li> </ul>"},{"location":"ref/config/#model_min_nesting","title":"<code>model_min_nesting</code>","text":"<code>1</code> Minimum number of nested mispredictions in the model. This value is used to generate the contract traces on the fast path of the fuzzer. Chose a small value when speculation is rare, and a larger value when speculation is common. <p>This option is a pure performance optimization. It only impacts the speed of fuzzing, and not its correctness.</p> Syntax <pre><code>model_min_nesting: &lt;depth&gt;\n</code></pre>"},{"location":"ref/config/#model_max_nesting","title":"<code>model_max_nesting</code>","text":"<code>30</code> Maximum number of nested mispredictions in the model. This value is used to generate the contract traces on the slow path of the fuzzer, i.e., when a potential violation is detected and the fuzzer tries to check if it is a true positive. <p>In contrast to <code>model_min_nesting</code>, this option could cause false positives if set too low. Thus, it is advisable to set it to a sufficiently high value to cover all possible nested mispredictions in the test cases. Leave the default unless you are sure that a lower value is sufficient.</p> Syntax <pre><code>model_max_nesting: &lt;depth&gt;\n</code></pre>"},{"location":"ref/config/#model_max_spec_window","title":"<code>model_max_spec_window</code>","text":"<code>250</code> Size of the speculation window in the model. <p>This option sets a trade-off between accuracy and performance. A larger speculation window avoids potential false positives due to inaccurate modelling of the speculation, but it also slows down the model execution. Leave the default unless you are sure that a different value is needed.</p> Syntax <pre><code>model_max_spec_window: &lt;size&gt;\n</code></pre>"},{"location":"ref/config/#executor-configuration","title":"Executor Configuration","text":""},{"location":"ref/config/#executor","title":"<code>executor</code>","text":"<p> ISA-specific version of the executor to use. The default value is auto-detected based on <code>cpuinfo</code>. Should be changed only if the auto-detection fails.</p> SyntaxAvailable Options <pre><code>executor: &lt;type&gt;\n</code></pre> <p><code>x86-64-intel</code> | <code>x86-64-amd</code> | <code>arm64</code></p>"},{"location":"ref/config/#executor_mode","title":"<code>executor_mode</code>","text":"<p> <code>P+P</code> Method of collecting hardware traces in the executor. The method determines the contents of hardware traces.</p> SyntaxAvailable OptionsOptions Explained <pre><code>executor_mode: &lt;mode&gt;\n</code></pre> <p><code>P+P</code> | <code>F+R</code> | <code>E+R</code> | <code>PP+P</code> | <code>TSC</code></p> <ul> <li><code>P+P</code> - prime and probe side-channel attack. The hardware traces contain the cache sets that were accessed during the execution of the test case.</li> <li><code>F+R</code> - flush and reload side-channel attack. The hardware traces contain the memory addresses that were accessed during the execution of the test case.</li> <li><code>E+R</code> - evict and reload side-channel attack. The hardware traces contain the cache sets that were accessed during the execution of the test case.</li> <li><code>PP+P</code> - partial prime and probe (i.e., leave a subset of cache lines unprimed). The hardware traces contain the cache sets that were accessed during the execution of the test case.</li> <li><code>TSC</code> - use <code>RDTSCP</code> instruction to measure the execution time of test cases. The hardware traces contain the execution time, in cycles.</li> </ul>"},{"location":"ref/config/#executor_warmups","title":"<code>executor_warmups</code>","text":"<p> <code>5</code> Number of warmup rounds executed before starting to collect hardware traces.</p> Syntax <pre><code>executor_warmups: &lt;count&gt;\n</code></pre>"},{"location":"ref/config/#executor_sample_sizes","title":"<code>executor_sample_sizes</code>","text":"<p> <code>[10, 50, 100, 500]</code> A list of sample sizes to be used during the measurements.</p> <p>Clarification</p> <p>Executor normally performs measurements multiple times for each test case in order to collect a sample of hardware traces. This allows Revizor to tolerate noise and non-determinism in the measurements by applying statistical methods for comparing the traces.</p> <p>For performance reasons, Revizor does not immediately use a large sample size. Instead, it starts with a small sample, collects the traces, and checks if a violation is detected. If no violation is detected, the executor assumes that the test case is safe, and moves on to the next one. If a violation is detected, however, the executor tries to reproduce it with larger sample sizes.</p> <p>This option defines the list of sample sizes through which Revizor will iterate in this process. To make it sensible, the list should be sorted in ascending order with a reasonable gap between the sizes.</p> Syntax <pre><code>executor_sample_sizes:\n  - &lt;sample_size1&gt;\n  - &lt;sample_size2&gt;\n  ...\n</code></pre>"},{"location":"ref/config/#executor_filtering_repetitions","title":"<code>executor_filtering_repetitions</code>","text":"<p> <code>10</code> The sample size to be used by the speculation and observation filters.</p> Syntax <pre><code>executor_filtering_repetitions: &lt;count&gt;\n</code></pre>"},{"location":"ref/config/#executor_taskset","title":"<code>executor_taskset</code>","text":"<p> <code>0</code> The CPU core ID which the executor will use for running test cases. That is, the executor process will be pinned to this core.</p> Syntax <pre><code>executor_taskset: &lt;core_id&gt;\n</code></pre>"},{"location":"ref/config/#enable_pre_run_flush","title":"<code>enable_pre_run_flush</code>","text":"<p> <code>True</code> If enabled, the executor will do its best to flush the microarchitectural state before running test cases.</p> Syntax <pre><code>enable_pre_run_flush: &lt;True|False&gt;\n</code></pre>"},{"location":"ref/config/#analyser-configuration","title":"Analyser Configuration","text":""},{"location":"ref/config/#analyser","title":"<code>analyser</code>","text":"<p> <code>chi2</code> The type of the analyser that is used to compare hardware traces against contract traces.</p> SyntaxAvailable OptionsOptions Explained <pre><code>analyser: &lt;type&gt;\n</code></pre> <p><code>chi2</code> | <code>mwu</code> | <code>sets</code> | <code>bitmaps</code></p> <ul> <li><code>sets</code> - combine the hardware traces for each input into a set. A violation is reported if two inputs in the same contract-equivalence class have different sets of hardware traces.</li> <li><code>bitmaps</code> - combine the hardware traces for each input into a bitmap. A violation is reported if two inputs in the same contract-equivalence class have different bitmaps of hardware traces.</li> <li><code>chi2</code> - use the chi-squared homogeneity test to compare the hardware traces of inputs in the same contract-equivalence class. This test effectively checks if the hardware traces from two different inputs come from the same distribution. A violation is reported if the test fails.</li> <li><code>mwu</code> - [experimental; both false positives and negatives are possible] use the Mann-Whitney U test to compare the hardware traces of inputs in the same contract-equivalence class. This test effectively checks if the hardware traces from two different inputs come from the same distribution. A violation is reported if the test fails.</li> </ul>"},{"location":"ref/config/#analyser_subsets_is_violation","title":"<code>analyser_subsets_is_violation</code>","text":"<p> <code>False</code> This option is relevant only for the <code>sets</code> and <code>bitmaps</code> analysers. If enabled, the analyser will not label hardware traces as mismatching if they form a subset relation.</p> Syntax <pre><code>analyser_subsets_is_violation: &lt;True|False&gt;\n</code></pre>"},{"location":"ref/config/#analyser_outliers_threshold","title":"<code>analyser_outliers_threshold</code>","text":"<p> <code>0.1</code> This option is relevant only for the <code>sets</code> and <code>bitmaps</code> analysers. The analyser will ignore the hardware traces that appear in less than this percentage of the sampled traces.</p> Syntax <pre><code>analyser_outliers_threshold: &lt;threshold&gt;\n</code></pre>"},{"location":"ref/config/#analyser_stat_threshold","title":"<code>analyser_stat_threshold</code>","text":"<code>0.5</code> This option is relevant only for the <code>chi2</code> and <code>mwu</code> analysers. The threshold for the statistical tests. If a pair of hardware traces has the (normalized) statistics below the threshold, then the traces are considered equivalent. For the chi2 test, the threshold is applied to the <code>statistics / (len(htrace1) + len(htrace2))</code>. <p>For the mwu test, the threshold is applied to the p-value.</p> Syntax <pre><code>analyser_stat_threshold: &lt;threshold&gt;\n</code></pre>"},{"location":"ref/config/#miscellaneous-configuration","title":"Miscellaneous Configuration","text":""},{"location":"ref/config/#coverage_type","title":"<code>coverage_type</code>","text":"<p> <code>none</code> The type of coverage tracking.</p> SyntaxAvailable OptionsOptions Explained <pre><code>coverage_type: &lt;type&gt;\n</code></pre> <p><code>none</code> | <code>model_instructions</code></p> <ul> <li><code>none</code> - disable coverage tracking.</li> <li><code>model_instructions</code> - track how many times the model executed each instruction in the target ISA.</li> </ul>"},{"location":"ref/config/#minimizer_retries","title":"<code>minimizer_retries</code>","text":"<p> <code>1</code> Number of minimization retries. When the minimizer performs a check to reduce a test case, each check is attempted this number of times and it succeeds if at least one check is successful.</p> Syntax <pre><code>minimizer_retries: &lt;count&gt;\n</code></pre>"},{"location":"ref/config/#unique-x86-64-options","title":"Unique x86-64 Options","text":""},{"location":"ref/config/#x86_executor_enable_ssbp_patch","title":"<code>x86_executor_enable_ssbp_patch</code>","text":"<p> <code>True</code> Enable a microcode patch against Speculative Store Bypass, if available.</p> Syntax <pre><code>x86_executor_enable_ssbp_patch: &lt;True|False&gt;\n</code></pre>"},{"location":"ref/config/#x86_executor_enable_prefetcher","title":"<code>x86_executor_enable_prefetcher</code>","text":"<p> <code>False</code> Enable all prefetchers, if the software controls are available.</p> Syntax <pre><code>x86_executor_enable_prefetcher: &lt;True|False&gt;\n</code></pre>"},{"location":"ref/config/#x86_disable_div64","title":"<code>x86_disable_div64</code>","text":"<p> <code>True</code> Do not generate 64-bit division instructions. Useful for avoiding certain types of speculation that are specific to 64-bit division.</p> Syntax <pre><code>x86_disable_div64: &lt;True|False&gt;\n</code></pre>"},{"location":"ref/config/#x86_enable_hpa_gpa_collisions","title":"<code>x86_enable_hpa_gpa_collisions</code>","text":"<p> <code>False</code> When a test case contains at least one guest actor, allocate its memory in the guest physical address space to match the corresponding host physical addresses of the main actor. Useful for testing Foreshadow-like leaks.</p> Syntax <pre><code>x86_enable_hpa_gpa_collisions: &lt;True|False&gt;\n</code></pre>"},{"location":"ref/config/#x86_generator_align_locks","title":"<code>x86_generator_align_locks</code>","text":"<p> <code>True</code> When generating memory accesses with locks, apply instrumentation to align the locks to 8 bytes. Useful for avoiding faults on unaligned accesses.</p> Syntax <pre><code>x86_generator_align_locks: &lt;True|False&gt;\n</code></pre>"},{"location":"ref/config/#whats-next","title":"What's Next?","text":"<ul> <li>Command Line Interface - CLI options and modes</li> <li>demo/big-fuzz.yaml - Comprehensive example configuration</li> <li>demo/ - Example configurations for various scenarios</li> </ul>"},{"location":"ref/macros/","title":"Macros","text":"<p>This document provides a complete reference for all macros available in Revizor.</p> <p>Related Documentation</p> <p>This document is intended as a reference; if you're looking for a practical guide on how to use the <code>macros</code>, please refer to How-To: Use Macros.</p>"},{"location":"ref/macros/#overview","title":"Overview","text":"<p>Macros are special pseudo-instructions in assembly test cases that appear as labels with the <code>.macro</code> prefix. They are dynamically expanded into actual implementations during execution by the model and executor. Macros enable complex operations like domain transitions, measurement control, and random code generation within test cases.</p> <p>Macros accept up to four static arguments. Arguments are strictly static (either a constant integer or a string); dynamic values (registers, memory addresses) are not supported.</p> SyntaxExample <pre><code>.macro.&lt;macro_name&gt;.&lt;argument1&gt;.&lt;argument2&gt;.&lt;argument3&gt;.&lt;argument4&gt;:\n</code></pre> <pre><code>; Macro to switch execution to\n; a function called `main` that belongs to the actor `actor_2`\n.macro.switch.user.function_user_0:\n</code></pre>"},{"location":"ref/macros/#measurement-macros","title":"Measurement Macros","text":"<p>Control the start and end of hardware and contract trace collection.</p>"},{"location":"ref/macros/#measurement_start","title":"<code>measurement_start</code>","text":"<p>Begins hardware and contract trace collection. Instructions before this macro are executed but not included in the contract/hardware traces.</p> SyntaxArguments <pre><code>.macro.measurement_start:\n\n; alternative\n.macro.measurement_start.&lt;label&gt;:\n</code></pre> <ol> <li><code>label</code> (optional): Unique identifier if the macro is used multiple times</li> </ol>"},{"location":"ref/macros/#measurement_end","title":"<code>measurement_end</code>","text":"<p>Ends hardware and contract trace collection. Instructions after this macro are executed but not included in the contract/hardware traces.</p> SyntaxArguments <pre><code>.macro.measurement_end:\n\n; alternative\n.macro.measurement_end.&lt;label&gt;:\n</code></pre> <ol> <li><code>label</code> (optional): Unique identifier if the macro is used multiple times</li> </ol>"},{"location":"ref/macros/#transition-macros","title":"Transition Macros","text":"<p>Switch between different actors and privilege levels, including kernel-user and host-guest transitions.</p>"},{"location":"ref/macros/#set_h2g_target","title":"<code>set_h2g_target</code>","text":"<p>Sets the VM entry point for host-to-guest transitions.</p> SyntaxArguments <pre><code>.macro.set_h2g_target.&lt;actor_name&gt;.&lt;function_name&gt;:\n</code></pre> <ul> <li><code>actor_name</code>: Target guest actor identifier</li> <li><code>function_name</code>: Entry point function in guest actor</li> </ul>"},{"location":"ref/macros/#set_g2h_target","title":"<code>set_g2h_target</code>","text":"<p>Sets the VM exit point for guest-to-host transitions.</p> SyntaxArguments <pre><code>.macro.set_g2h_target.&lt;actor_name&gt;.&lt;function_name&gt;:\n</code></pre> <ul> <li><code>actor_name</code>: Target host actor identifier</li> <li><code>function_name</code>: Landing point function in host actor</li> </ul>"},{"location":"ref/macros/#switch_h2g","title":"<code>switch_h2g</code>","text":"<p>Performs host-to-guest transition (VM entry). The entry and exit point must be set beforehand using <code>set_h2g_target</code> and <code>set_g2h_target</code> macros.</p> SyntaxArguments <pre><code>.macro.switch_h2g.&lt;actor_name&gt;.&lt;label&gt;:\n</code></pre> <ul> <li><code>actor_name</code>: Target guest actor identifier</li> <li><code>label</code> (optional): Unique identifier if the macro is used multiple times</li> </ul>"},{"location":"ref/macros/#landing_h2g","title":"<code>landing_h2g</code>","text":"<p>Marks the guest landing point after host-to-guest transition. This macro works together with <code>switch_h2g</code> to ensure complete restoration of the execution context.</p> SyntaxArguments <pre><code>.macro.landing_h2g.&lt;label&gt;:\n</code></pre> <ul> <li><code>label</code> (optional): Unique identifier if the macro is used multiple times</li> </ul>"},{"location":"ref/macros/#switch_g2h","title":"<code>switch_g2h</code>","text":"<p>Performs guest-to-host transition (VM exit). The entry and exit point must be set beforehand using <code>set_h2g_target</code> and <code>set_g2h_target</code> macros.</p> SyntaxArguments <pre><code>.macro.switch_g2h.&lt;actor_name&gt;.&lt;label&gt;:\n</code></pre> <ul> <li><code>actor_name</code>: Target host actor identifier</li> <li><code>label</code> (optional): Unique identifier if the macro is used multiple times</li> </ul>"},{"location":"ref/macros/#landing_g2h","title":"<code>landing_g2h</code>","text":"<p>Marks the host landing point after guest-to-host transition. This macro works together with <code>switch_g2h</code> to ensure complete restoration of the execution context.</p> SyntaxArguments <pre><code>.macro.landing_g2h.&lt;label&gt;:\n</code></pre> <ul> <li><code>label</code> (optional): Unique identifier if the macro is used multiple times</li> </ul>"},{"location":"ref/macros/#set_k2u_target","title":"<code>set_k2u_target</code>","text":"<p>Sets the user mode entry point for kernel-to-user transitions.</p> SyntaxArguments <pre><code>.macro.set_k2u_target.&lt;actor_name&gt;.&lt;function_name&gt;:\n</code></pre> <ul> <li><code>actor_name</code>: Target user-mode actor identifier</li> <li><code>function_name</code>: Entry point function in user actor</li> </ul>"},{"location":"ref/macros/#set_u2k_target","title":"<code>set_u2k_target</code>","text":"<p>Sets the kernel mode entry point for user-to-kernel transitions.</p> SyntaxArguments <pre><code>.macro.set_u2k_target.&lt;actor_name&gt;.&lt;function_name&gt;:\n</code></pre> <ul> <li><code>actor_name</code>: Target kernel-mode actor identifier</li> <li><code>function_name</code>: Entry point function in kernel actor</li> </ul>"},{"location":"ref/macros/#switch_k2u","title":"<code>switch_k2u</code>","text":"<p>Performs kernel-to-user transition (privilege level drop). The entry and exit point must be set beforehand using <code>set_k2u_target</code> and <code>set_u2k_target</code> macros.</p> SyntaxArguments <pre><code>.macro.switch_k2u.&lt;actor_name&gt;.&lt;label&gt;:\n</code></pre> <ul> <li><code>actor_name</code>: Target user actor identifier</li> <li><code>label</code> (optional): Unique identifier if the macro is used multiple times</li> </ul>"},{"location":"ref/macros/#switch_u2k","title":"<code>switch_u2k</code>","text":"<p>Performs user-to-kernel transition (privilege level escalation). The entry and exit point must be set beforehand using <code>set_k2u_target</code> and <code>set_u2k_target</code> macros.</p> SyntaxArguments <pre><code>.macro.switch_u2k.&lt;actor_name&gt;.&lt;label&gt;:\n</code></pre> <ul> <li><code>actor_name</code>: Target kernel actor identifier</li> <li><code>label</code> (optional): Unique identifier if the macro is used multiple times</li> </ul>"},{"location":"ref/macros/#landing_k2u","title":"<code>landing_k2u</code>","text":"<p>Marks the user-mode landing point after kernel-to-user transition.  This macro works together with <code>switch_k2u</code> to ensure complete restoration of the execution context.</p> SyntaxArguments <pre><code>.macro.landing_k2u.&lt;label&gt;:\n</code></pre> <ul> <li><code>label</code> (optional): Unique identifier if the macro is used multiple times</li> </ul>"},{"location":"ref/macros/#landing_u2k","title":"<code>landing_u2k</code>","text":"<p>Marks the kernel-mode landing point after user-to-kernel transition.  This macro works together with <code>switch_u2k</code> to ensure complete restoration of the execution context.</p> SyntaxArguments <pre><code>.macro.landing_u2k.&lt;label&gt;:\n</code></pre> <ul> <li><code>label</code> (optional): Unique identifier if the macro is used multiple times</li> </ul>"},{"location":"ref/macros/#fault-handling-macros","title":"Fault Handling Macros","text":"<p>Define exception and interrupt handlers within test cases.</p>"},{"location":"ref/macros/#fault_handler","title":"<code>fault_handler</code>","text":"<p>Specifies the control flow target for exceptions and interrupts. When an exception occurs, control transfers to this location. If not defined, the executor uses a default handler that jumps to the test case exit point.</p> SyntaxArguments <pre><code>.macro.fault_handler:\n</code></pre> <ul> <li>None</li> </ul>"},{"location":"ref/macros/#environment-configuration-macros","title":"Environment Configuration Macros","text":"<p>Change the execution environment from within a test case.</p>"},{"location":"ref/macros/#set_data_permissions","title":"set_data_permissions","text":"<p>Configures data permission on the faulty page of the current actor by modifying the page table entry (PTE) permissions.</p> SyntaxArguments <pre><code>.macro.set_data_permissions.&lt;set_mask&gt;.&lt;clear_mask&gt;:\n</code></pre> <ul> <li><code>set_mask</code>: 16-bit bitmask specifying which permission bits to set (ORed with the faulty page's PTE)</li> <li><code>clear_mask</code>: 16-bit bitmask specifying which permission bits to clear (ANDed with the faulty page's PTE)</li> </ul>"},{"location":"ref/macros/#generation-macros","title":"Generation Macros","text":"<p>Define automatically-generated points within a template. Available only in the Template Fuzzing Mode</p> <p>In contrast to the rest of the macros, generation macros are used by the generator instead of the executor or model. By the point the executor/model run the test case, these macros are expected to have been already expanded into actual code.</p>"},{"location":"ref/macros/#random_instructions","title":"<code>random_instructions</code>","text":"<p>Generates N random instructions during template expansion. Used in template fuzzing mode to insert randomized code sequences.</p> SyntaxArguments <pre><code>.macro.random_instructions.&lt;num_instructions&gt;.&lt;avg_mem_accesses&gt;.&lt;label&gt;:\n</code></pre> <ul> <li><code>num_instructions</code>: Number of random instructions to generate</li> <li><code>avg_mem_accesses</code>: Average number of memory accesses. Average means that when a large-enough number of test cases are generated, the mean number of memory accesses per expansion of this macro will approximate this value.</li> <li><code>label</code> (optional): Unique identifier if the macro is used multiple times</li> </ul>"},{"location":"ref/macros/#whats-next","title":"What's Next?","text":"<ul> <li>How to Use Macros - Detailed usage guide and implementation details</li> <li>How to Use Templates - Template-based testing</li> <li>Actors - Multi-domain testing concepts</li> </ul> <p>Examples:</p> <ul> <li>demo/tsa-l1d/template.asm - TSA-L1D attack template with actor transitions</li> <li>demo/tsa-sq/template.asm - TSA-SQ attack template with actor transitions</li> </ul>"},{"location":"ref/minimization-passes/","title":"Minimization Passes","text":"<p>This document provides a detailed list of all available minimization features (passes) supported in the <code>minimize</code> execution mode of Revizor. These passes are used to simplify randomly generated violation artifacts to enable human analysis.</p> <p>Related Documentation</p> <p>This document is intended as a reference; if you're looking for a practical guide on how to use the <code>minimize</code> mode, please refer to How-To: Minimize Violation.</p>"},{"location":"ref/minimization-passes/#types-of-passes","title":"Types of Passes","text":"<p><code>minimize</code> mode supports three types of passes:</p> <ul> <li>program passes modify the program</li> <li>input passes modify the input sequence</li> <li>analysis passes provide additional information about the violation, usually by adding comments to the program.</li> </ul>"},{"location":"ref/minimization-passes/#program-passes","title":"Program Passes","text":""},{"location":"ref/minimization-passes/#-enable-instruction-pass","title":"<code>--enable-instruction-pass</code>","text":"Enables the instruction minimization pass that iteratively removes instructions from the program while preserving the violation."},{"location":"ref/minimization-passes/#-enable-simplification-pass","title":"<code>--enable-simplification-pass</code>","text":"Enables the instruction simplification pass that replaces complex instructions with simpler ones while preserving the violation."},{"location":"ref/minimization-passes/#-enable-nop-pass","title":"<code>--enable-nop-pass</code>","text":"Enables the NOP replacement pass that iteratively replaces instructions with NOPs of the same size while preserving the violation."},{"location":"ref/minimization-passes/#-enable-constant-pass","title":"<code>--enable-constant-pass</code>","text":"Enables the constant simplification pass that replaces immediate arguments of instructions with 0s while preserving the violation."},{"location":"ref/minimization-passes/#-enable-mask-pass","title":"<code>--enable-mask-pass</code>","text":"Enables the mask simplification pass that reduces the size of the instrumentation masks while preserving the violation."},{"location":"ref/minimization-passes/#-enable-label-pass","title":"<code>--enable-label-pass</code>","text":"Enables the label removal pass that removes unused labels from the assembly file."},{"location":"ref/minimization-passes/#-enable-fence-pass","title":"<code>--enable-fence-pass</code>","text":"Enables the fence insertion pass that adds LFENCEs after instructions while preserving the violation."},{"location":"ref/minimization-passes/#input-passes","title":"Input Passes","text":""},{"location":"ref/minimization-passes/#-enable-input-seq-pass","title":"<code>--enable-input-seq-pass</code>","text":"Enables the input sequence minimization pass that removes inputs from the original generated sequence while preserving the violation."},{"location":"ref/minimization-passes/#-enable-input-diff-pass","title":"<code>--enable-input-diff-pass</code>","text":"Enables the violating input difference minimization pass that operates on the pair of (contract-equivalent) inputs that triggered the violation and attempts to minimize the difference between the two inputs. It does so by iterating over all bytes in the inputs, and (1) attempting to replace each byte with zero, and if it fails, (2) copying the byte from the first input to the second input."},{"location":"ref/minimization-passes/#analysis-passes","title":"Analysis Passes","text":""},{"location":"ref/minimization-passes/#-enable-source-analysis","title":"<code>--enable-source-analysis</code>","text":"Enables the speculation source identification pass that analyzes the program to identify suspected sources of speculation, and adds the corresponding comments to the assembly file. Note that the analysis is not guaranteed to be correct, and it may produce false results."},{"location":"ref/minimization-passes/#-enable-comment-pass","title":"<code>--enable-comment-pass</code>","text":"Enables the violation comment pass that adds comments to the assembly file with details about the violation."},{"location":"ref/modes/","title":"Execution Modes","text":"<p>Revizor supports several modes of operation, each targeting a different use cases. The selection of the mode is described in the CLI documentation. Below is a brief description of each mode.</p>"},{"location":"ref/modes/#overview","title":"Overview","text":"Mode CLI Key Use Case Description Fuzzing fuzz General Testing Test a CPU against a contract model. Test cases generated randomly Template Fuzzing tfuzz Targeted Testing Test a CPU against a contract model. Test cases generated based on a template Reproduce reproduce Reproducing a Violation Reproduce a violation found by fuzzing OR run a manually-written test case Minimization minimize Simplification of a Violation Simplify a test case by applying a series of simplification passes to the test case program and its inputs Trace Analysis analyse External Integration Analyze pre-recorded traces for violations Generation generate External Integration Only generate test cases, without testing them ISA Spec Install download_spec Tool Installation Call a script that downloads the instruction set specification"},{"location":"ref/modes/#fuzz","title":"<code>fuzz</code>","text":"Syntax <pre><code>$ rvzr fuzz [OPTIONS]\n</code></pre> <p>Main fuzzing mode of Revizor. In this mode, Revizor randomly generates test cases and executes them on the target CPU and the model, records the corresponding traces, and checks if the hardware traces contain the same (or less) information as the contract traces. That is, it implements Model-Based Relational Testing approach.</p> <p>Use case: Broad testing of CPU behavior against contract specifications.</p>"},{"location":"ref/modes/#tfuzz","title":"<code>tfuzz</code>","text":"Syntax <pre><code>$ rvzr tfuzz [OPTIONS]\n</code></pre> <p>Similar to the fuzzing mode, but test cases are generated based on a template. For details on templates, see the template fuzzing how-to guide.</p> <p>Use case: Targeted testing of specific scenarios, microarchitectural patches, or actor interactions.</p>"},{"location":"ref/modes/#reproduce","title":"<code>reproduce</code>","text":"Syntax <pre><code>$ rvzr reproduce [OPTIONS]\n</code></pre> In this mode, Revizor loads and executes a specific test case data and inputs from files. Performs single fuzzing round with the provided test case and inputs, and reports the results. Test cases can be violations from previous fuzzing runs or manually-written test programs. <p>Use cases:</p> <ul> <li>Checking reproducibility: Testing if a violation artifact can be consistently reproduced on other CPUs or configurations.</li> <li>Verification of a violation: Confirming that a violation is genuine and not a false positive.</li> <li>Manual testing: Executing a custom test case written by the user.</li> <li>Root-causing: Checking the impact of manual modifications to a test case.</li> </ul>"},{"location":"ref/modes/#minimize","title":"<code>minimize</code>","text":"Syntax <pre><code>$ rvzr minimize [OPTIONS]\n</code></pre> <p>In this mode, Revizor applies simplification passes to a violation test case, reducing program and input complexity while preserving the violation behavior.</p> <p>Use case: Simplify violations for root cause analysis.</p>"},{"location":"ref/modes/#analyse","title":"<code>analyse</code>","text":"Syntax <pre><code>$ rvzr analyse [OPTIONS]\n</code></pre> <p>In this mode, Revizor analyzes pre-recorded contract and hardware traces for violations without executing test cases. Accepts trace files as input and applies the configured analyser to detect contract violations.</p> <p>Use case: Integration with external tools that perform trace collection separately from Revizor.</p>"},{"location":"ref/modes/#generate","title":"<code>generate</code>","text":"Syntax <pre><code>$ rvzr generate [OPTIONS]\n</code></pre> Generates test cases without execution. Outputs test programs and inputs to them. Use case: Integration with external tools that use Revizor's test case generation capabilities."},{"location":"ref/modes/#download_spec","title":"<code>download_spec</code>","text":"Syntax <pre><code>$ rvzr download_spec [OPTIONS]\n</code></pre> This mode is only used when Revizor is being set up. Downloads, parses, and stores instruction set specifications in JSON format. Use case: Tool installation and ISA specification management."},{"location":"ref/modes/#whats-next","title":"What's Next?","text":"<ul> <li>Command Line Interface - How to run Revizor in different modes</li> <li>Minimization Passes - Available passes for the <code>minimize</code> mode</li> </ul>"},{"location":"ref/registers/","title":"Register Allocation","text":"<p>The test cases are executed in a sandboxed environment, where some of the registers are reserved for internal use, and some are available for use in the test cases. Below is a list of registers and their purpose.</p> <p>Advanced Topic</p> <p>This is an advanced topic describing internal implementation details of Revizor. You are unlikely to need this information unless you are extending or modifying Revizor's core components.</p>"},{"location":"ref/registers/#r15","title":"<code>R15</code>","text":"<p>Contains the base address of the UTILITY area in the sandbox.</p> <p>If the test case does not enter a VM, the register value remains constant during the execution of the test cases. Otherwise, the register value is updated to point to the UTILITY area of the currently active VM when the <code>switch_h2g</code> macro is called, and it is restored to the original value when the <code>switch_g2h</code> macro is called.</p> <p>The register is used by internal functions, such as the implementation of Prime+Probe.</p>"},{"location":"ref/registers/#r14","title":"<code>R14</code>","text":"<p>Contains the base address of the current actor's sandbox (namely, it points to the base of the actor's MAIN area).</p> <p>At the beginning of the test case execution, the register is set to the base address of the MAIN area of the first actor (actor <code>main</code>). The register value is updated to point to the MAIN area of the currently active actor when a macro from the <code>landing_*</code> group of macros is called. It is also updated by the <code>fault_handler</code> macro.</p> <p>The register is used in test cases as a part of the sandboxing mechanism. For example, all generated memory accesses are relative to the value stored in <code>R14</code>, and have the form of <code>[R14 + offset]</code>.</p>"},{"location":"ref/registers/#r13-htrace_register-constant-in-the-kernel-module","title":"<code>R13</code> (<code>HTRACE_REGISTER</code> constant in the kernel module)","text":"<p>Contains either intermediate or final result of the hardware trace measurements.</p> <p>Before entering the test case, the register is set to 0. When a <code>measurement_start</code> macro is executed, the register is (optionally) set to the starting value, such a initial reading of time stamp counter when the <code>TSC</code> mode is used. When a <code>measurement_end</code> macro is executed, the register is updated with the final value of the measurement and contains the resulting hardware trace.</p>"},{"location":"ref/registers/#r12-status_register-constant-in-the-kernel-module","title":"<code>R12</code> (<code>STATUS_REGISTER</code> constant in the kernel module)","text":"<p>Contains a compressed status of the test case execution:</p> <p>Bits[0:7] contain a measurement status. At the beginning of the test case execution, the bits are set to 0. When <code>measurement_start</code> macro is executed, the bits are set to 1. When <code>measurement_end</code> macro is executed, the bits are set to 2. If the measurement status is not 2 at the end of the test case execution, the kernel module will report an error.</p> <p>Bits[8:31] are unused.</p> <p>Bits[32:63] contain a counter of SMI (System Management Interrupt) events. The counter is set automatically before entering the test case (<code>READ_SMI_START</code>), and updated when the test case finishes (<code>READ_SMI_END</code>). If the difference between the readings is not 0, the kernel module will report an error.</p>"},{"location":"ref/registers/#r11","title":"<code>R11</code>","text":"<p>The register is used as a temporary buffer by some of the macros.</p> <p>Before entering the test case, the register is set to 0. When certain macros are executed (e.g., <code>set_k2u_target</code>), the register will contain temporary values. The register should not be used in the test case, as the temporary value may be consumed by latter macros.</p>"},{"location":"ref/registers/#r10-r9-r8","title":"<code>R10, R9, R8</code>","text":"<p>Stores the values of performance counters. <code>R10</code> stores the value of performance counter #1, <code>R9</code> stores the value of performance counter #2, and <code>R8</code> stores the value of performance counter #3.</p> <p>Before entering the test case, the registers are set to 0. When a <code>measurement_start</code> macro is executed, the registers are (optionally) set to the starting values. When a <code>measurement_end</code> macro is executed, the registers are updated with the final values of the measurements.</p>"},{"location":"ref/registers/#other-general-purpose-registers","title":"Other General Purpose Registers","text":"<p>The remaining registers (<code>rax</code>, <code>rcx</code>, <code>rdx</code>, <code>rsi</code>, <code>rdi</code>, <code>rflags</code>) are available for use in the test cases and can be modified freely. A special case are <code>rsp</code> and <code>rbp</code>, which can be used in the test cases, but their values must always remain within the sandbox (see Sandbox).</p>"},{"location":"ref/registers/#vector-registers","title":"Vector Registers","text":"<p>Vector registers (<code>xmm0</code>-<code>xmm15</code>) are also available for use in the test cases. However, only <code>xmm0-xmm7</code> are initialized with input-based values, and the remaining registers are always zero-initialized.</p> <p>Large-size vector registers (<code>ymm</code> and <code>zmm</code>) are not supported.</p>"},{"location":"ref/runtime-statistic/","title":"Fuzzing Statistics","text":"<p>This document provides a complete reference on how to interpret the runtime statistics output of Revizor. These statistics are generated during fuzzing campaigns and provide insights into the performance and behavior of the fuzzer.</p> <p>The runtime statistics are essentially printed twice: once during the fuzzing campaign, in a form of a continuously-updated progress log, and once at the end of the campaign, in a summarized report. The statistics in both places have the same meaning, but the final report includes cumulative totals for the entire campaign.</p>"},{"location":"ref/runtime-statistic/#runtime-statistics-fields","title":"Runtime Statistics Fields","text":"<p>A typical runtime statistics output looks like this:</p> <pre><code>17    ( 2%)| Stats: Cls:100/100,In:200,R:7,SF:10,OF:7,Fst:0,CN:0,CT:0,P1:0,CS:0,P2:0,V:0&gt; Priming  27\n</code></pre> <p>This line is continuously updated on each iteration of the fuzzer (after each test case is executed).</p> <p>The fields are as follows:</p> <ul> <li><code>17    ( 2%)</code> - The current test case number and progress towards the total number of test cases.</li> <li><code>Cls:100/100</code> - The average number of unique equivalence classes per test case. The left number is number of \"effective\" classes (those that have at least two hardware inputs), while the right number is total classes observed. In a well-functioning campaign, these numbers should be equal. See contract equivalence class in the glossary.</li> <li><code>In:200</code> - The number of inputs per test case. Normally, this number is equal to <code>-i</code> parameter passed times <code>inputs_per_class</code> configuration option.</li> <li><code>R:7</code> - Average number of hardware tracing samples per input. See Trace Analysis - Statistical Comparison for more details.</li> <li><code>SF:10,OF:7,Fst:0,CN:0,CT:0,P1:0,CS:0,P2:0</code> - The number of test cases that have been filtered by each stage of the false-positive elimination pipeline.<ul> <li><code>SF</code> - Number of test cases filtered by the speculation filter.</li> <li><code>OF</code> - Number of test cases filtered by the observation filter.</li> <li><code>Fst</code> - Number of test cases filtered after fast-path execution.</li> <li><code>CN</code> - Number of test cases filtered out when model nesting was increased from 1 (fast path) to <code>max_model_nesting</code>.</li> <li><code>CT</code> - Number of test cases that had taint mistakes.</li> <li><code>P1</code> - Number of test cases filtered out by priming stage with the minimal sample size.</li> <li><code>CS</code> - Number of test cases filtered out when the sample size was increased to a non-minimal value.</li> <li><code>P2</code> - Number of test cases filtered out by priming stage with the non-minimal sample size.</li> </ul> </li> <li><code>V:0</code> - The number of detected violations so far (can be non-zero when running with <code>--nonstop</code> flag).</li> <li><code>Priming  27</code> - Current stage of the false-positive elimination pipeline.</li> </ul>"},{"location":"ref/runtime-statistic/#final-summary-report","title":"Final Summary Report","text":"<p>A typical final summary report looks like this:</p> <pre><code>================================ Statistics ===================================\n\nTest Cases: 18\nInputs per test case: 200.0\nViolations: 1\nEffectiveness:\n  Total Cls: 98.0\n  Effective Cls: 98.0\nDiscarded Test Cases:\n  Speculation Filter: 10\n  Observation Filter: 7\n  Fast Path: 0\n  Max Nesting Check: 0\n  Tainting Check: 0\n  Early Priming Check: 0\n  Large Sample Check: 0\n  Priming Check: 0\n\nDuration: 40.5\nFinished at 15:40:23\n</code></pre> <p>This section summarizes overall statistics from the fuzzing campaign. The fields are similar to those explained in the runtime output section above:</p> <ul> <li><code>Test Cases</code> - Total number of test cases executed during the campaign.</li> <li><code>Inputs per test case</code> - Average number of inputs executed per test case.</li> <li><code>Violations</code> - Total number of violations detected during the campaign (may &gt;1 when running with <code>--nonstop</code> flag).</li> <li><code>Effectiveness</code> - The average number of unique equivalence classes per test case. <code>Total Cls</code> is number of \"effective\" classes (those that have at least two hardware inputs), while <code>Effective Cls</code> is total classes observed. In a well-functioning campaign, these numbers should be equal. See contract equivalence class in the glossary.</li> <li><code>Discarded Test Cases</code> - The number of test cases that have been filtered by each stage of the false-positive elimination pipeline.</li> <li><code>Duration</code> - Total duration of the fuzzing campaign in seconds.</li> <li><code>Finished at</code> - Timestamp when the fuzzing campaign completed.</li> </ul>"},{"location":"ref/sandbox/","title":"Test Case Sandbox","text":"<p>This document describes the isolated environment for executing test cases, which is referred to as the sandbox. The sandbox contains the test case code and data, and the test case code is confined to access memory only within the sandbox.</p> <p>The sandbox is implemented by all modules that execute test cases, including the executor (kernel module) and all model backends (Unicorn, DynamoRIO). To ensure that the executions are consistent across all modules, the sandbox is structured in the same way in all the modules.</p> <p>This document describes the memory layout of the sandbox, the initialization of the sandbox memory, and the fault isolation mechanism.</p>"},{"location":"ref/sandbox/#memory-layout","title":"Memory Layout","text":"<p>The sandbox memory is divided into two main areas: the data sandbox and the code sandbox. Each actor in the test case has its own sub-area for its data and code, and the layout of these areas is the same for all actors.</p>"},{"location":"ref/sandbox/#data-layout","title":"Data Layout","text":"<p>The data area of a test case in a sandbox is organized as follows:</p> Offset Actor ID Area Name Size, B 0x0 ACTOR 0 Macro Stack 0x40 0x40 Underflow Pad 0xfc0 0x1000 Main Area 0x1000 0x2000 Faulty Area 0x1000 0x3000 GPR Area 0x40 0x3040 SIMD Area 0x100 0x3140 Overflow Pad 0xec0 0x4000 ACTOR 1 Macro Stack 0x40 0x4040 Underflow Pad 0xfc0 0x5000 Main Area 0x1000 0x6000 Faulty Area 0x1000 0x7000 GPR Area 0x40 0x7040 SIMD Area 0x100 0x7140 Overflow Pad 0xec0 ... ... ... ... <p>The data area is divided into the following regions:</p> <ul> <li>Main and Faulty Areas: These are the two regions of memory that are accessible by the test case code.   This is enforced by the test case generator, which instruments all memory accesses to ensure that they fall within these regions (see code-generation for more details).   Both areas are initialized with the input data from the RBDF.   The main area always has default permissions (RW), while the faulty area has permissions can be configured to cause a fault when accessed.   This configuration originates from the config file.</li> <li>GPR and SIMD Areas: These regions store the values that will be used by the modules to initialize the general-purpose registers (GPR) and SIMD registers before executing the test case and when switching between actors. Both areas are initialized with the input data from the RBDF.   The order of registers is: <code>rax</code>, <code>rbx</code>, <code>rcx</code>, <code>rdx</code>, <code>rsi</code>, <code>rdi</code>, <code>flags</code>, <code>rsp</code> for GPRs, and <code>xmm0</code> to <code>xmm7</code> for SIMD registers.</li> <li>Over- and Underflow Pads: These two zero-initialized regions surround the actors' data areas, and their purpose is to determinize the hardware traces on the executor.   Namely, they are needed for the cases when the CPU speculatively bypasses the sandboxing instrumentation inserted by the test case generator, and the bypass leads to an out-of-bounds memory access.   As the pads are zero-initialized, the bypassed memory accesses will produce deterministic results.</li> <li>Macro stack: This region is used to implement complex macros (e.g., VMENTER) that need to save and restore data on the stack with a guarantee that this data won't be corrupted by the following (randomly-generated) instructions (see macros for more details.)</li> </ul>"},{"location":"ref/sandbox/#code-layout","title":"Code Layout","text":"<p>The code area of a test case in a sandbox is organized as follows:</p> Offset Actor ID Area Name Size, B 0x0 ACTOR 0 Main Code Area 0x2000 0x2000 Macro Code Area 0x1000 0x3000 ACTOR 1 Main Code Area 0x2000 0x5000 Macro Code Area 0x1000 ... ... ... ... <p>The code area is divided into two regions:</p> <ul> <li>Main Code Area: This region contains the binary of the actor's code.   The code comes from the RCDF file.   The first instruction in the code area of actor 0 is the entry point of the test case, and the last instruction of actor 0 is the exit point of the test case.</li> <li>Macro Code Area: This region contains code of the expanded macros for each actor.   (see macros for more details on the macro expansion process.)</li> </ul>"},{"location":"ref/sandbox/#references","title":"References","text":"<ul> <li>Executor: rvzr/executor_km/include/sandbox_manager.h</li> <li>Unicorn backend: rvzr/sandbox.py</li> </ul>"},{"location":"ref/sandbox/#sandbox-initialization","title":"Sandbox Initialization","text":"<p>The sandbox is initialized based on the test case code (normally in RCBD format) and the input data (normally in RDBF format). The following diagram shows the mapping between the RCBF/RDBF files and the sandbox memory layout:</p> <pre><code>                                        |--------------------|\n                   zero initialized -&gt;  | MACRO STACK        |\n                                        |--------------------|\n                   zero initialized -&gt;  | UNDERFLOW PAD      |\n                                        |--------------------|\n      RDBF.data[actor_id].main_area -&gt;  | MAIN AREA          |\n                                        |--------------------|\n    RDBF.data[actor_id].faulty_area -&gt;  | FAULTY AREA        |\n                                        |--------------------|\nRDBF.data[actor_id].reg_init_region -&gt;  | GPR AREA           |\n                                        |--------------------|\nRDBF.data[actor_id].reg_init_region -&gt;  | SIMD AREA          |\n                                        |--------------------|\n                   zero initialized -&gt;  | OVERFLOW PAD       |\n                                        |--------------------|\n\n\n     RCBF.tc_section[actor_id].code -&gt;  | MAIN CODE AREA     |\n                                        |--------------------|\n     expanded macro code (executor) -&gt;  | MACRO CODE AREA    |\n</code></pre>"},{"location":"ref/sandbox/#fault-isolation","title":"Fault Isolation","text":"<p>UNDER CONSTRUCTION</p>"},{"location":"topics/actors/","title":"Actors","text":"<p>Actors represent distinct security domains within a test case. They could be thought as sub-test-cases, each with its own code, data, execution context, and privilege level.</p> <p>The main use case for actors is to test interactions and isolation boundaries between security domains. A typical example would be testing kernel-to-user isolation by defining a two-actor test case: one actor runs in kernel mode (the \"main\" actor), and the other runs in user mode (the \"user\" actor). The user actor attempts to observe information about the main actor's execution, simulating an attacker trying to leak sensitive kernel data.</p> <p>By using this mechanism, Revizor can stress-test isolation boundaries by executing lots of randomly generated code on both sides of the boundary and checking for secret-dependent observations on the attacker side. This mechanism discovered several critical vulnerabilities in production CPUs, most notably Transient Scheduler Attacks in AMD processors, and enables testing of mitigations for Meltdown, Foreshadow, and MDS.</p>"},{"location":"topics/actors/#what-is-an-actor","title":"What is an Actor?","text":"<p>An actor consists of three components:</p> <ul> <li>Code region associated with a specific execution context</li> <li>Private data memory with configurable permissions and properties</li> <li>Execution context defined by CPU mode (host/guest), privilege level (kernel/user), and system configuration</li> </ul> <p>Every test case starts with a default actor called <code>main</code> that runs in host kernel mode. This actor can transition to other actors using dedicated <code>switch_*</code> macros.</p>"},{"location":"topics/actors/#actor-configuration","title":"Actor Configuration","text":"<p>Actors are defined in the configuration file under the <code>actors</code> section:</p> <pre><code>actors:\n  - main:                       # Default main actor\n    - mode: \"host\"              # Always host for main;\n                                # changing to \"guest\" will produce an error\n    - privilege_level: \"kernel\" # Always kernel for main;\n                                # changing to \"user\" will produce an error\n\n  - user:                       # Example user-mode actor\n    - mode: \"host\"\n    - privilege_level: \"user\"\n    - data_properties:          # Custom page table properties of the faulty page\n      - writable: false         # Faulty page of the user actor is read-only\n</code></pre> <p>Related Documentation</p> <p>See the configuration documentation for a full list of available options.</p>"},{"location":"topics/actors/#actor-templates","title":"Actor Templates","text":"<p>Multi-actor execution requires template-based mode. Templates define actors along with their code and data sections.</p> <p>Transitions between actors use dedicated macros for setting entry and exit points, switching contexts, and defining landing locations. Macros are available for kernel-user transitions (<code>.set_k2u_target</code>, <code>.switch_k2u</code>, etc.) and host-guest transitions (<code>.set_h2g_target</code>, <code>.switch_h2g</code>, etc.).</p> <p>Related Documentation</p> <p>See Macro Reference for detailed descriptions of all transition macros.</p>"},{"location":"topics/actors/#actor-non-interference-contract","title":"Actor Non-Interference Contract","text":"<p>Revizor uses the Actor Non-Interference contract to verify isolation between security domains. The contract designates one or more actors as observers (attackers) and verifies that observer execution does not depend on data from victim actors.</p> <p>The contract permits leakage of victim memory access addresses and control flow, but prohibits leakage of data values. This design filters cache-based leakage typically considered benign in modern systems while detecting unexpected microarchitectural leaks. Victim actors follow the ct-seq contract, while observers can expose all their own data.</p> <p>A violation occurs when observer traces depend on victim data beyond permitted address and control-flow information.</p> <p>Additional Reading</p> <p>The Actor Non-Interference contract is explained in detail in the paper called Enter, Exit, Page Fault, Leak: Testing Isolation Boundaries for Microarchitectural Leaks.</p>"},{"location":"topics/actors/#example-usage","title":"Example Usage","text":"<p>The following example demonstrates kernel-to-user isolation testing with the Actor Non-Interference contract.</p> <p>Template with kernel and user actors:</p> <pre><code>.intel_syntax noprefix\n\n# ---------------- Main (Kernel) Actor ---------\n.section .data.main\n.function_main_0:\n    # Set up user transition\n    .macro.set_k2u_target.user.function_user_0:\n    .macro.set_u2k_target.main.function_main_1:\n\n    # Generate random kernel code\n    .macro.random_instructions.32.0:\n\n    # Transition to user mode\n    .macro.switch_k2u.user.0:\n\n.function_main_1:\n    .macro.landing_u2k.main_1:\n    # Back in kernel, clean up and exit\n    nop\n\n.test_case_exit:\n\n# ---------------- User Actor -----------------\n.section .data.user\n.function_user_0:\n    .macro.landing_k2u.user_0:\n\n    # Start measurement in user mode\n    .macro.measurement_start:\n\n    # Generate random user code\n    .macro.random_instructions.16.1:\n\n    # End measurement\n    .macro.measurement_end:\n\n    # Return to kernel\n    .macro.switch_u2k.main.0:\n</code></pre> <p>Configuration file:</p> <pre><code>actors:\n  - main:\n      mode: host\n      privilege_level: kernel\n  - user:\n      mode: host\n      privilege_level: user\n      observer: true              # User is the attacker\n      data_properties:\n        writable: false           # Trigger page faults on writes\n\ncontract_observation_clause: load+store+pc\ncontract_execution_clause: noninterference\n</code></pre> <p>In this configuration, the user actor attempts to observe information from the kernel (main actor). The contract specifies that the user can observe memory addresses and control flow (load+store+pc) but not data values. Any leakage beyond this triggers a violation.</p>"},{"location":"topics/contracts/","title":"Contracts","text":"<p>A speculation contract is a formal specification of known microarchitectural leakage in CPUs. A contract serves to provide a precise and unambiguous documentation of all known sources of side-channel leaks on a given CPU (or a family of CPUs). For example, if a contract targets a modern Intel or AMD CPU, it will typically include a specification of the leaks caused by cache side channels and by various speculative vulnerabilities such as Spectre and Meltdown.</p> <p>Contracts emerged as a solution to a fundamental problem: modern CPUs have complex microarchitectural optimizations that create side channels, but these mechanisms are often proprietary and poorly documented. Contracts provide a systematic way to reason about these leaks without requiring complete knowledge of the underlying hardware.</p> <p>In the context of Revizor, contracts serve as a reference model against which the actual CPU behavior is compared; any deviation from the contract indicates a previously-unknown microarchitectural behavior, which may represent a security vulnerability.</p>"},{"location":"topics/contracts/#contract-structure","title":"Contract Structure","text":"<p>A speculation contract consists of two types of clauses that together describe the information a program exposes during execution.</p> <p>The observation clause specifies what data becomes observable for each instruction. For example, a contract might declare that load and store instructions expose their target addresses. This models the information an attacker could learn by monitoring a cache-based side channel such as Prime+Probe. The observation clause captures side effects without specifying the attack mechanism.</p> <p>The execution clause specifies how hardware optimizations affect program execution. For speculative execution, the clause describes which instructions execute transiently even when they should not execute architecturally. For instance, the clause might specify that conditional branches temporarily take the wrong target. The execution clause models optimization behavior without describing the implementation details.</p> <p>Contracts intentionally overestimate leakage. Rather than precisely modeling what leaks occur, contracts capture everything that could potentially leak given the specified hardware behaviors. This conservative approach ensures that contracts remain valid even when the exact timing or conditions of leaks are unknown.</p>"},{"location":"topics/contracts/#example-contracts","title":"Example Contracts","text":"<p>The <code>CT-SEQ</code> contract models a CPU with caching but no speculation. It represents a baseline level of leakage present in any cached architecture where memory operations leave observable traces but instructions execute in program order.</p> <p>Below is a pseudo-code representation of the <code>CT-SEQ</code> contract:</p> <pre><code>CT-SEQ:\n  observation_clause:\n    load(address)  -&gt; expose(address)\n    store(address) -&gt; expose(address)\n    * -&gt; none  # all other instructions expose no information\n  execution_clause:\n    * -&gt; none  # no optimizations; all instructions execute in program order\n</code></pre> <p>The <code>CT-COND</code> contract extends <code>CT-SEQ</code> by adding speculative execution of branches. The observation clause remains the same, but the execution clause permits conditional jumps to mispredict their targets and speculatively execute wrong-path instructions. This contract models Spectre-style vulnerabilities where misprediction causes transient execution that leaves observable cache footprints.</p> <pre><code>CT-COND:\n  observation_clause:\n    load(address)  -&gt; expose(address)\n    store(address) -&gt; expose(address)\n    * -&gt; none\n  execution_clause:\n    jump.cond(target) -&gt;  # emulate branch misprediction\n        jump.inverted_cond(target)\n    * -&gt; none\n</code></pre> <p>More complex contracts can model other optimizations. A contract for exception handling might allow faulting user-to-kernel loads to transiently return privileged values before the fault is architecturally recognized, this modelling Meltdown-style vulnerabilities:</p> <pre><code>CT-MELTDOWN:\n  observation_clause:\n    load(address)  -&gt; expose(address)\n    store(address) -&gt; expose(address)\n    * -&gt; none\n  execution_clause:\n    jump.cond(target) -&gt;\n        jump.inverted_cond(target)\n    load(address) -&gt;  # transiently return kernel data thus emulating Meltdown\n        if (in_user_mode() &amp;&amp; is_kernel_address(address)) {\n            return load_privileged(address)\n        }\n    * -&gt; none\n</code></pre>"},{"location":"topics/contracts/#contract-traces","title":"Contract Traces","text":"<p>When a program executes according to a contract, it produces a contract trace. The trace is a sequence of all observations specified by the observation clause during the execution path determined by the execution clause. For <code>CT-SEQ</code>, the trace contains load and store addresses in program order. For <code>CT-COND</code>, the trace includes addresses from speculatively executed instructions on mispredicted paths.</p> <p>Contract traces are deterministic and noise-free, unlike actual hardware measurements. This property makes them suitable as a reference for comparison. A program executed repeatedly with the same inputs always produces the same contract trace, even though real hardware traces may vary due to timing effects and concurrent activity.</p> <p>For example, consider the following program:</p> <pre><code># addr1 = 0x100; addr2 = 0x200;\n# *addr1 = 1;    *addr2 = 2\nload rax, [addr1]  # expose(0x100)\ncmp rax, 0         # 1 != 0\nje label_zero      # speculatively mispredicted under CT-COND\n    load rbx, [addr2]  # expose(0x200) under CT-COND (but not under CT-SEQ)\nlabel_zero:\n</code></pre> <p>When this program is executed under <code>CT-SEQ</code>, only one load occurs (line 3), producing the trace:</p> <pre><code>ctrace_seq = [ mem:0x100 ]\n</code></pre> <p>However, under <code>CT-COND</code>, the mispredicted branch causes the second load (line 6) to execute, thus producing a trace with two observations:</p> <pre><code>ctrace_cond = [ mem:0x100, mem:0x200 ]\n</code></pre>"},{"location":"topics/contracts/#contract-compliance","title":"Contract Compliance","text":"<p>A CPU complies with a contract when the information it leaks never exceeds what the contract permits. More formally, compliance means that whenever two inputs produce identical contract traces, they must also produce indistinguishable hardware traces given the same initial microarchitectural state. This definition ensures that an attacker observing hardware cannot learn more than the contract allows.</p> <p>Compliance does not require that hardware traces match contract traces exactly. The contract might expose complete addresses while hardware only leaks cache set indices. The contract might include data from speculative paths that hardware does not actually execute. These differences are acceptable as long as the information content of hardware traces does not exceed contract traces.</p> <p>A violation occurs when two inputs produce identical contract traces but distinguishable hardware traces. This indicates that hardware leaks information not captured by the contract, revealing an unexpected microarchitectural behavior. The violating program serves as evidence of a potential security vulnerability.</p>"},{"location":"topics/contracts/#contract-evolution","title":"Contract Evolution","text":"<p>Contracts are not static specifications. When Revizor discovers a violation, the user is free to update the contract to reflect the newly observed behavior. This way a contract serves as a \"filter\" that allows us to automatically distinguish between the leaks that we already know about (and thus aren't interested in detecting) versus the leaks that are genuinely new and that we may want to investigate further.</p> <p>Moreover, the process may go both ways: if the hardware behavior is determined to be a bug, and the vendor issues a patch, the contract may be updated to remove the previously-allowed leakage, which in turn will allow Revizor to detect regressions if the patch is later undone or incompletely applied.</p> <p>This iterative process gradually refines contracts to match actual hardware behavior. Initial contracts are based on public documentation and known vulnerabilities. Testing reveals gaps where hardware leaks more than expected. After investigation, either the contract expands or the hardware receives a patch. Over time, the contract converges toward a complete specification of the CPU's microarchitectural leakage.</p> <p>The contract framework also enables testing of proposed mitigations. Before deploying a patch, vendors can verify its effectiveness by running Revizor with the updated configuration. If violations persist, the mitigation is incomplete. This proactive approach helps prevent the deployment of ineffective patches that provide false security.</p>"},{"location":"topics/contracts/#whats-next","title":"What's Next?","text":"<ul> <li>See the primer for a deeper dive into non-interference and contract-based testing.</li> <li>See the model documentation for details on how Revizor implements contracts.</li> </ul>"},{"location":"topics/models/","title":"Leakage Models","text":"<p>A leakage model is an executable implementation of a speculation contract. The model takes a program and inputs, executes them according to contract rules, and produces contract traces that represent the information expected to leak. Models enable automated testing by providing a reference against which real hardware behavior can be compared.</p> <pre><code>flowchart LR\n    P[Program]\n    I[Input 1 ... N]\n    M[Model]\n    CT[CTrace 1 ... N]\n\n    P --&gt; M\n    I --&gt; M\n    M --&gt; CT\n\n    style M fill:#e1f5ff,stroke:#333,stroke-width:2px\n    style P fill:#ffe1e1,stroke:#333,stroke-width:1px\n    style I fill:#ffe1e1,stroke:#333,stroke-width:1px\n    style CT fill:#e1ffe1,stroke:#333,stroke-width:1px</code></pre> <p>Models solve a practical problem in security testing. Contracts specify what should leak in abstract terms, but to test hardware, we need concrete predictions for specific programs. The model bridges this gap by simulating program execution under contract assumptions and recording observable effects as they occur.</p>"},{"location":"topics/models/#implementing-contracts","title":"Implementing Contracts","text":"<p>A model implements contracts through two specialized components: the Tracer and the Speculator. These components monitor instruction execution through hook functions and modify behavior according to contract rules.</p> <pre><code>flowchart LR\n    A0[Start&lt;/br&gt;Program&lt;/br&gt;Execution] --&gt; A\n    A[Next&lt;/br&gt;Instruction] --&gt;B{Select Hook}\n    B --&gt;|Instruction has&lt;/br&gt;observation clause?| D[Tracer]\n    B --&gt;|Instruction has&lt;/br&gt;execution clause?| E[Speculator]\n    B --&gt;|Model in&lt;/br&gt;speculative mode?| F[Speculator]\n    D --&gt;G[Record&lt;/br&gt;observations] --&gt; Z\n    E --&gt;H1[Checkpoint]--&gt;H[Emulate&lt;/br&gt;speculation] --&gt; I[Enter&lt;/br&gt;speculative&lt;/br&gt;mode] --&gt; Z\n    F --&gt;J{Termination&lt;/br&gt;condition&lt;/br&gt;met?}\n    J --&gt;|Yes| X[Rollback] --&gt; Z\n    J --&gt;|No| Z\n    Z[Execute&lt;/br&gt;Instruction] --&gt;A\n\n    style D fill:#e1ffe1,stroke:#333\n    style G fill:#e1ffe1,stroke:#333\n    style E fill:#ffe1e1,stroke:#333\n    style F fill:#ffe1e1,stroke:#333\n    style H1 fill:#ffe1e1,stroke:#333\n    style H fill:#ffe1e1,stroke:#333\n    style I fill:#ffe1e1,stroke:#333\n    style X fill:#fff4e1,stroke:#333\n    style Z fill:#e1f5ff,stroke:#333</code></pre> <p>The Tracer implements the observation clause. It monitors execution of each instruction and records contract-relevant information. When an instruction with a non-trivial observation clause executes, the model invokes the corresponding Tracer hook. For example, when a load instruction executes under a contract that exposes memory addresses, the Tracer hook records the target address. The Tracer accumulates these observations into a contract trace that represents all information exposed during execution.</p> <p>The Speculator implements the execution clause. It modifies the behavior of instructions with non-trivial execution clauses to simulate microarchitectural optimizations. When such an instruction executes, the model invokes the Speculator hook, which takes a checkpoint of the program state and modifies the instruction's behavior. This puts the model into speculative mode. For example, when a conditional branch executes under a contract that permits misprediction, the Speculator checkpoints the state, flips the branch condition, and continues on the wrong path.</p> <p>While in speculative mode, the model checks for termination conditions after each instruction. When a condition is met, such as the speculation window expiring or encountering a serializing instruction, the model exits speculative mode and rolls back to the most recent checkpoint. This restores architectural state and resumes correct execution. Speculation can be nested, with one speculative region triggering another before the first completes. The Speculator manages a stack of checkpoints to handle nested speculation correctly.</p> <p>The hook-based architecture allows models to implement contracts without modifying the core execution engine. Whenever the model executes an instruction, it checks whether the instruction has non-trivial observation or execution clauses. If observation clauses are present, Tracer hooks are invoked. If execution clauses are present, Speculator hooks are invoked. The model also calls hooks to check speculation termination conditions when in speculative mode. This separation of concerns makes it straightforward to implement different contracts by providing different Tracer and Speculator implementations.</p>"},{"location":"topics/models/#model-backends","title":"Model Backends","text":"<p>Revizor supports two model backends that implement contracts using different techniques. Both provide the same interface and produce equivalent contract traces, but they differ in implementation approach and performance characteristics.</p> <p>The Unicorn backend uses CPU emulation to execute programs. Unicorn is a CPU emulator derived from QEMU that supports multiple architectures. The model extends Unicorn with hooks that intercept instruction execution and memory accesses. When an instruction executes, the hook checks whether the contract requires recording an observation or triggering speculation. For speculation, the model uses Unicorn's snapshot and restore capabilities to implement checkpoint-rollback.</p> <p>The DynamoRIO backend uses dynamic binary instrumentation to execute programs. DynamoRIO inserts instrumentation code directly into the program at runtime. Before each instruction, the model injects a callback that checks contract rules. For speculation, the model manipulates register state to simulate wrong-path execution and uses checkpoints to restore architectural state when speculation ends. Because the program runs natively on the host CPU, execution is faster than emulation.</p> <p>The choice between backends involves trade-offs. The DynamoRIO backend is generally preferable as it offers better performance and it inherently supports all instructions that can be executed on the host CPU. However, this backend is more recent and may not support all contract features and platforms as robustly as the Unicorn backend. Therefore, the Unicorn backend remains available for use cases where the DynamoRIO backend is not yet suitable.</p>"},{"location":"topics/models/#trace-representation","title":"Trace Representation","text":"<p>Contract traces are sequences of typed observations. Each observation records one piece of information that leaked during execution. The trace preserves the order in which observations occurred, capturing temporal aspects of information flow (although this could be overridden by the Tracer if the contract prescribes so).</p> <p>An observation has a type and a value. Types include memory addresses, branch targets, load/store values, register contents, or any other observable information. The contract determines which types appear in traces. CT-SEQ traces contain only memory addresses and branch targets. A contract modeling MDS might include data values. The type system allows precise specification of what information the contract permits.</p>"},{"location":"topics/models/#accuracy-and-limitations","title":"Accuracy and Limitations","text":"<p>Models approximate real hardware behavior, and this approximation introduces both capabilities and limitations. Understanding these boundaries is important for interpreting test results.</p> <p>Models implement contracts conservatively but not precisely. The contract specifies bounds on leakage, and the model respects these bounds while making implementation choices. For branch speculation, the contract might say branches can mispredict, but not specify when or how often. A model that speculatively executes every branch overapproximates reality but remains consistent with the contract. This conservatism means models may predict leakage that never occurs, but they should not miss leakage that does occur.</p> <p>Instruction support varies between backends and real hardware. Some instructions are complex or poorly documented, making them difficult to emulate correctly. Unicorn covers most common instructions but may have gaps or emulation bugs. When the model encounters unsupported instructions, it typically halts with an error. This conservative behavior prevents incorrect predictions but limits which test cases can be executed.</p> <p>Models do not aim to capture all microarchitectural details. Real CPUs have dozens of optimizations including out-of-order execution, store buffers, prefetchers, and speculative memory disambiguation. Contracts and models abstract away most of these details and focus instead on the information observable through side channels, rather than trying to describe the mechanisms that produce the leakage. This abstraction simplifies model implementation and focuses testing on the most relevant aspects.</p>"},{"location":"topics/models/#performance-considerations","title":"Performance Considerations","text":"<p>Model performance directly affects testing throughput. Revizor must execute thousands or millions of test cases to achieve good coverage, and model execution dominates the time budget. Faster models enable more comprehensive testing within a given time frame.</p> <p>The highest impact on performance comes from the complexity of the execution clause in the contract. Simple contracts with minimal speculation (e.g., <code>CT-SEQ</code>) execute quickly, while contracts with extensive speculation incur significant overhead due to increase in the number of executed instructions.</p> <p>Backend choice also impacts performance. DynamoRIO typically outperforms Unicorn, especially for larger test cases or when executing with many inputs per test case (&gt; 100s). However, DynamoRIO has a higher startup overhead, making it less efficient for very small test cases or when executing with few inputs per test case (&lt; 10s). The performance crossover point depends on the specific fuzzing scenario.</p>"},{"location":"topics/models/#whats-next","title":"What's Next?","text":"<ul> <li>See the contracts documentation for details on contract specifications.</li> <li>See the internals documentation for implementation details.</li> <li>See Unicorn backend and DynamoRIO backend for backend-specific information.</li> </ul>"},{"location":"topics/test-case-generation/","title":"Test Case Generation","text":"<p>Test case generation is the process of creating executable programs that probe CPU microarchitectural behavior. Revizor generates test cases either randomly or from user-defined templates, then instruments them to prevent unwanted faults, and finally compiles them into binaries suitable for execution. The test cases serve as inputs to both the leakage model and the hardware executor, enabling comparison of expected and observed microarchitectural behavior.</p> <p>The generator must balance two competing requirements. First, it needs to produce diverse test cases that explore many different microarchitectural conditions and instruction sequences. This diversity is essential for thorough coverage of the CPU's behavior space. Second, when testing specific scenarios like domain transitions or mitigation effectiveness, it must generate programs with precise structures while still varying the surrounding context. This balance distinguishes Revizor's approach from simple random testing.</p>"},{"location":"topics/test-case-generation/#generation-modes","title":"Generation Modes","text":"<p>Revizor supports two distinct modes of test case generation, each suited to different testing scenarios.</p> <p>Random generation creates test cases from scratch without any predefined structure. The generator builds a program by selecting instructions randomly from a configured pool, creating control flow by inserting conditional and unconditional branches, and allocating memory accesses to random addresses. This mode maximizes exploration of the instruction space and frequently discovers unexpected interactions between instructions. Random generation excels at finding vulnerabilities in single execution domains where no specific instruction sequence is required. However, it struggles with scenarios requiring precise setup, such as triggering specific page faults or transitioning between security domains.</p> <p>Template-based generation starts from a user-written assembly file that defines the overall structure of the test case. The template specifies where random code should be inserted, which domain transitions to perform, and how actors should interact. The generator parses the template, expands special macros that mark randomization points, fills those points with random instructions, and instruments the result. Templates enable testing of specific scenarios while maintaining randomization where it matters. For example, a template can ensure that a kernel-to-user transition occurs at a specific point while randomizing the instructions executed in each domain.</p> <p>The distinction matters because microarchitectural vulnerabilities often depend on precise conditions. Consider testing whether a CPU leaks kernel data to user space. Random generation might occasionally produce programs that transition to user mode, but the probability is low and the surrounding context may not trigger the vulnerability. A template guarantees the transition occurs and controls the operations performed before and after it, dramatically increasing the likelihood of discovering leakage.</p>"},{"location":"topics/test-case-generation/#instrumentation-passes","title":"Instrumentation Passes","text":"<p>Generated test cases, whether random or template-based, are not immediately ready for execution. They may contain instruction sequences that trigger unwanted faults, use undefined register values, or violate architectural constraints. Instrumentation passes transform test cases into safe, executable forms while preserving the properties being tested.</p> <p>Instrumentation operates on the structured representation of test cases. Each pass implements a specific transformation by walking the instruction hierarchy and modifying it according to its rules. Passes run in sequence, with each pass seeing the output of previous passes. This pipeline architecture allows complex transformations to be built from simple components.</p> <p>One critical example of a pass is the sandboxing pass, which instruments memory accesses to ensure they target valid addresses within the test case's allocated memory. Accesses to unmapped addresses cause page faults. While some test cases intentionally trigger faults, most do not, and random generation can easily produce invalid addresses. The pass analyzes memory operands, identifies potentially invalid accesses, and masks the instruction operands to bound them within the sandbox.</p> <p>Another example is a pass that prevents division by zero. Divisions by zero and division overflows trigger exceptions on x86-64, which may be undesirable in a fuzzing campaign that does not focus on this specific type of exception. Yet random generator will commonly trigger them, especially the division overflows. This pass mitigates this issue by scanning the instruction stream for division instructions, and it instruments the division operands to ensure they are non-zero and within safe ranges.</p> <p>The passes are designed to introduce minimal microarchitectural side effects, to avoid interfering with the properties being tested. For example, the instrumentation code primarily uses arithmetic and logical operations that do not have any known speculative effects, and the instructions operate primarily on registers rather than memory. This careful design ensures that the instrumentation does not inadvertently create or mask vulnerabilities (or at least minimizes the chances of doing so).</p>"},{"location":"topics/test-case-generation/#test-case-structure","title":"Test Case Structure","text":"<p>A test case is represented internally as a hierarchy of nested components. The following diagram illustrates this hierarchical structure:</p> <pre><code>graph TD\n    TC[TestCaseProgram]\n    TC --&gt; CS1[CodeSection: main]\n    TC --&gt; CS2[CodeSection: user]\n\n    CS1 --&gt; F1[Function: .function_0]\n    CS2 --&gt; F2[Function: .function_user_0]\n\n    F1 --&gt; BB1[BasicBlock: entry]\n    F1 --&gt; BB2[BasicBlock: .label_1]\n    F1 --&gt; BB3[BasicBlock: exit]\n\n    BB1 --&gt; I1[Instruction: mov rax, rbx]\n    BB1 --&gt; I2[Instruction: add rax, 1]\n    BB1 --&gt; T1[Terminator: jmp .label_1]\n\n    BB2 --&gt; I3[Instruction: ...]\n    BB2 --&gt; T2[Terminator: ret]\n\n    F2 --&gt; BB4[BasicBlock: entry]\n    BB4 --&gt; I4[Instruction: ...]\n\n    style TC fill:#e1f5ff\n    style CS1 fill:#ffe1e1\n    style CS2 fill:#ffe1e1\n    style F1 fill:#fff4e1\n    style F2 fill:#fff4e1\n    style BB1 fill:#e1ffe1\n    style BB2 fill:#e1ffe1\n    style BB3 fill:#e1ffe1\n    style BB4 fill:#e1ffe1</code></pre> <p>At the top level, a TestCaseProgram contains one or more CodeSections. Each CodeSection belongs to a single Actor and holds the code that executes in that actor's context. In single-actor fuzzing, only one section exists. In multi-actor testing, each actor gets its own section with its own code and data.</p> <p>Within each CodeSection, code is organized into Functions. A Function consists of multiple BasicBlocks connected by control flow. The first block is the entry point, and execution proceeds through the blocks following branches and jumps. This structure mirrors conventional compiler intermediate representations, making it straightforward to apply standard analysis and transformation techniques.</p> <p>Each BasicBlock contains a sequence of Instructions terminated by zero or more control flow instructions. Regular instructions execute sequentially, while terminators (branches, jumps, returns) determine which block executes next. Instructions themselves are high-level representations that capture the operation, operands, and dependencies. They are not raw bytes but structured objects that can be analyzed and modified by instrumentation passes.</p> <p>This hierarchical design serves several purposes. It allows instrumentation passes to operate at different levels of granularity, from modifying individual instructions to restructuring entire functions. It makes the structure explicit, eliminating the need to repeatedly parse assembly text. It enables efficient copying and modification when expanding templates. Most importantly, it provides a common representation used throughout the fuzzing pipeline, from generation through model execution to hardware measurement.</p>"},{"location":"topics/test-case-generation/#macro-placeholders","title":"Macro Placeholders","text":"<p>Macro placeholders are the key mechanism for combining fixed structure with randomization. They appear in templates as special labels that get expanded during test case generation. A macro looks like an assembly label but carries semantic meaning. For example, <code>.macro.random_instructions.64:</code> tells the generator to insert 64 randomly chosen instructions at that point.</p> <pre><code>graph LR\n    subgraph \"Template (Before Expansion)\"\n        T1[\".section .main&lt;br/&gt;.function_0:\"]\n        T2[\".macro.random_instructions.3:\"]\n        T3[\"mov rax, [rbx]\"]\n    end\n\n    subgraph \"Expanded Test Case\"\n        E1[\".section .main&lt;br/&gt;.function_0:\"]\n        E2[\"add rax, rbx\"]\n        E3[\"mov [rdi], rcx\"]\n        E4[\"cmp rax, 0\"]\n        E5[\"mov rax, [rbx]\"]\n    end\n\n    T1 --&gt; E1\n    T2 -.expands to.-&gt; E2\n    T2 -.expands to.-&gt; E3\n    T2 -.expands to.-&gt; E4\n    T3 --&gt; E5\n\n    style T2 fill:#ffe1e1\n    style E2 fill:#e1ffe1\n    style E3 fill:#e1ffe1\n    style E4 fill:#e1ffe1</code></pre> <p>The critical insight is that macros defer decisions. A template author specifies where randomization should occur without specifying the exact instructions. This preserves the ability to test many different instruction sequences while maintaining the overall structure.</p> <p>Macros also enable progressive refinement of test cases. An initial template might use a single random macro to generate a large instruction sequence. If that discovers a violation, the user can refine the template to add more structure around the violation, narrowing the search space. The macro system makes this iteration efficient because templates remain concise and readable.</p> <p>Related Documentation</p> <p>For a complete list of available macros and their specifications, refer to the Macro Reference.</p> <p>For a how-to guide on using macros, see How-To: Use Macros.</p>"},{"location":"topics/test-case-generation/#template-structure-and-expansion","title":"Template Structure and Expansion","text":"<pre><code>flowchart LR\n    T[Template File] --&gt; P[Parse Template]\n    C[Config File] --&gt; P\n    P --&gt; R[Fill Random&lt;br/&gt;Instructions]\n    R --&gt; IP[Instrumentation&lt;br/&gt;Passes]\n    IP --&gt; PR[Print to&lt;br/&gt;Assembly]\n    PR --&gt; AS[Assemble]\n    AS --&gt; B[Binary&lt;br/&gt;Test Case]\n\n    style T fill:#e1f5ff\n    style C fill:#e1f5ff\n    style R fill:#ffe1e1\n    style IP fill:#fff4e1\n    style B fill:#e1ffe1</code></pre> <p>Templates use standard assembly syntax with macro extensions. This design choice means templates are valid assembly files that can be processed by conventional tools. Comments, labels, directives, and instructions follow normal assembly conventions. Only the macro pseudo-instructions are specific to Revizor.</p> <p>Template expansion proceeds in several phases. First, the generator parses the template using a standard assembly parser extended to recognize macros. Parsing produces the hierarchical test case structure described earlier, with macros represented as special instruction types. Next, the generator walks the structure and expands the <code>random_instructions</code> macro placeholders to random instruction sequences. Finally, instrumentation passes run, the test case is printed back to assembly, and the assembler produces an object file.</p> <p>Related Documentation</p> <p>For detailed instructions on writing and using templates, refer to How-To: Use Templates.</p>"},{"location":"topics/test-case-generation/#generation-performance","title":"Generation Performance","text":"<p>Generation performance affects overall fuzzing throughput, although it usually has a low impact on the overall process compared to the executor and the model. Generation may dominate the execution time only in the rare case where the other components are extremely fast, such as when testing very small test cases with a small (&lt;10) number of inputs.</p> <p>Both random and template-based generation modes have similar performance as the template is re-used across all generation requests after the first expansion.</p>"},{"location":"topics/test-case-generation/#whats-next","title":"What's Next?","text":"<ul> <li>Configuration Reference: Generator configuration options</li> <li>Actors: Security domains represented in test cases</li> <li>Binary Formats: File formats for test case binaries</li> <li>How-To: Use Macros: Guide on using macros in templates</li> <li>How-To: Use Templates: Guide on writing and using templates</li> <li>Code Generation: Implementation details of code generation and instrumentation</li> </ul>"},{"location":"topics/trace-analysis/","title":"Trace Analysis","text":"<p>This document describes Revizor's trace analysis techniques for detecting microarchitectural contract violations by comparing contract traces with hardware traces.</p> <p>Trace analysis is the core mechanism of Model-Based Relational Testing. It compares contract traces (predicted leakage from the model) with hardware traces (observed leakage from real CPU) to detect microarchitectural contract violations.</p>"},{"location":"topics/trace-analysis/#contract-compliance-property","title":"Contract Compliance Property","text":"<p>The fundamental property being tested is contract compliance: if two inputs produce the same contract trace, they must produce the same hardware trace for all microarchitectural states.</p> <p>Formally, a CPU complies with a speculation contract if, for all possible programs P, all input pairs (I\u2081, I\u2082), and all initial microarchitectural states Ctx:</p> <pre><code>ContractTrace(P, I\u2081) = ContractTrace(P, I\u2082)\n  \u27f9\nHardwareTrace(P, I\u2081, Ctx) = HardwareTrace(P, I\u2082, Ctx)\n</code></pre> <p>If this property is violated, the CPU is leaking information beyond what the contract predicts. A violation indicates that the contract is incomplete or that the CPU has an unexpected side channel. See the primer for theoretical foundations.</p> <p>Revizor approximates this property by randomly sampling the space of programs, inputs, and microarchitectural states, and checking for violations based on collected traces. The following sections describe how this check is implemented in practice.</p>"},{"location":"topics/trace-analysis/#problem-statement","title":"Problem Statement","text":"<p>The trace analysis task boils down to the following problem:</p> Given <ul> <li>A test program P</li> <li>A sequence of inputs I\u2081 \u2026 I\u2099</li> <li>A sequence of contract traces CTrace\u2081 \u2026 CTrace\u2099 (one per input, produced by the model)</li> <li>A sequence of hardware traces HTrace\u2081 \u2026 HTrace\u2099 (one per input, produced by the executor)</li> </ul> Objective Detect if there exist any input pairs (I\u1d62, I\u2c7c) such that <pre><code>CTrace\u1d62 = CTrace\u2c7c but HTrace\u1d62 \u2260 HTrace\u2c7c\n</code></pre>"},{"location":"topics/trace-analysis/#deterministic-trace-comparison","title":"Deterministic Trace Comparison","text":"<p>To detect contract violations, we need to check the above property for all tested inputs. Checking each input pair separately would be extremely inefficient (O(N\u00b2) complexity). Instead, we use an equivalence-class-based algorithm that groups inputs by their contract traces and checks hardware trace consistency within each group:</p> <ol> <li>Bundle measurements: Create tuples <code>(Input ID, Input, CTrace, HTrace)</code> for each execution</li> <li>Group by contract trace: Partition measurements into contract equivalence classes where    all measurements share the same <code>CTrace</code></li> <li>Check hardware traces: Within each contract equivalence class, verify all hardware traces    are identical</li> <li>Report violations: If a contract equivalence class contains different hardware traces,    report a violation</li> </ol> <pre><code>flowchart LR\n    B[Bundle measurements]\n    B --&gt; C[Group by CTrace&lt;br/&gt;]\n    C --&gt; D{For each EqClass}\n    D --&gt; E[Compare hardware traces]\n    E --&gt; F{All identical?}\n    F --&gt;|Yes| G[Mark class OK]\n    F --&gt;|No| H[Record violation]\n    G --&gt; I{More classes?}\n    H --&gt; I\n    I --&gt;|Yes| D\n    I --&gt;|No| J[End]\n\n    classDef good fill:#c3f3d9,stroke:#2b7b4b,color:#000;\n    classDef bad fill:#f9d5d5,stroke:#b61b1b,color:#000;\n    class G good\n    class H bad\n</code></pre> Example <p>Suppose we test 4 inputs and get:</p> <pre><code>I0: CTrace=A, HTrace=X\nI1: CTrace=A, HTrace=X\nI2: CTrace=B, HTrace=Y\nI3: CTrace=A, HTrace=Z\n</code></pre> <p>Contract equivalence classes:</p> <pre><code>- Class [CTrace=A]: I0, I1, I3\n- Class [CTrace=B]: I2\n</code></pre> <p>Analysis:</p> <ul> <li>Class <code>[CTrace=A]</code> contains three measurements with HTraces <code>{X, X, Z}</code></li> <li>Since X \u2260 Z, this is a violation</li> <li>Inputs <code>I0</code> and <code>I1</code> behaved identically (<code>HTrace=X</code>) but input <code>I3</code> behaved differently (<code>HTrace=Z</code>), despite having the same contract trace=A</li> <li>Accordingly, we found a violation: <code>I0</code> and <code>I3</code> have the same contract trace (<code>A = A</code>) while the hardware traces differ (<code>X \u2260 Z</code>)</li> </ul>"},{"location":"topics/trace-analysis/#statistical-trace-comparison","title":"Statistical Trace Comparison","text":""},{"location":"topics/trace-analysis/#the-problem-of-noise","title":"The Problem of Noise","text":"<p>Real hardware measurements are noisy. Even if we execute the same program with the same input repeatedly, we might get different hardware traces each time, due to factors like timing variations  in microcode execution, cache state changes from uncontrollable sources, non-controlled  hardware optimizations, etc.</p> <p>These discrepancies may cause false positives if we directly use the deterministic algorithm, because the differences between the hardware traces may be caused by noise, not by genuine information leakage.</p> Example <p>Suppose we test only two of the inputs from the previous example, but the second measurement produces a slightly different hardware trace due to noise:</p> <pre><code>I0: CTrace=A, HTrace=X\nI1: CTrace=A, HTrace=X'\n</code></pre> <p>The resulting analysis will produce a false violation:</p> <ul> <li>Contract equivalence class <code>[CTrace=A]: I0, I1</code></li> <li>Hardware traces: <code>{X, X'}</code></li> <li>Since <code>X \u2260 X'</code>, we incorrectly report a violation, even though both inputs are actually safe and the difference is just noise.</li> </ul>"},{"location":"topics/trace-analysis/#solution-sampling-and-statistical-analysis","title":"Solution: Sampling and Statistical Analysis","text":"<p>To address this, we treat hardware traces as samples from a distribution rather than single deterministic values. Instead of comparing individual hardware traces, we compare the distributions of hardware traces produced by each input. This replaces the deterministic equality check <code>HardwareTrace(P, I\u2081, Ctx) = HardwareTrace(P, I\u2082, Ctx)</code> with a statistical test that determines if two samples are drawn from the same distribution.</p> <p>To implement this, we modify the measurement process: instead of collecting one hardware trace per input, Revizor collects multiple samples per input. Each <code>HTrace</code> object contains an array of measurement samples. For example, with sample size N=10:</p> <pre><code>I0: CTrace=A, HTrace=[X, X, X', X, X, X', X, X, X, X]\nI1: CTrace=A, HTrace=[X, X', X, X, X, X, X', X, X, X]\n</code></pre> <p>Now we must compare distributions rather than individual values, and the question becomes: \"Are these two samples drawn from the same distribution?\"</p>"},{"location":"topics/trace-analysis/#chi-squared-test-for-categorical-data","title":"Chi-Squared Test for Categorical Data","text":"<p>Hardware traces are categorical data (no natural ordering), so Revizor uses Pearson's \u03c7\u00b2 homogeneity test.</p> <p>Given two samples <code>t\u2081</code> and <code>t\u2082</code> of hardware traces, the test computes:</p> <pre><code>\u03c7\u00b2 = \u03a3 (obs\u2081(t) - expected(t))\u00b2 / expected(t)\n   + \u03a3 (obs\u2082(t) - expected(t))\u00b2 / expected(t)\n</code></pre> <p>where:</p> <ul> <li><code>obs\u2081(t)</code> = count of trace <code>t</code> in sample 1</li> <li><code>obs\u2082(t)</code> = count of trace <code>t</code> in sample 2</li> <li><code>expected(t) = (obs\u2081(t) + obs\u2082(t)) / 2</code> = average count</li> </ul> <p>The \u03c7\u00b2 statistic is normalized by total sample size to make it comparable across different sample sizes.</p> <p>Decision rule: If <code>\u03c7\u00b2/N &lt; threshold</code>, accept that the samples come from the same distribution (no violation).</p> <p>The threshold is configurable (default 0.05) and can be tuned based on expected noise levels via <code>analyser_stat_threshold</code> config parameter.</p> <p>The following examples illustrate how the \u03c7\u00b2 test distinguishes between noise and real violations.</p> No violationReal violation <pre><code>I0: CTrace=A, HTrace=[X(8 times), X'(2 times)]\nI1: CTrace=A, HTrace=[X(7 times), X'(3 times)]\n</code></pre> <p>The distributions are similar (mostly X with some noise X'). \u03c7\u00b2 test will show they're equivalent:</p> <pre><code>obs\u2081(X) = 8, obs\u2081(X') = 2\nobs\u2082(X) = 7, obs\u2082(X') = 3\nexpected(X) = (8 + 7) / 2 = 7.5\nexpected(X') = (2 + 3) / 2 = 2.5\n\u03c7\u00b2 = (8 - 7.5)\u00b2/7.5 + (2 - 2.5)\u00b2/2.5 + (7 - 7.5)\u00b2/7.5 + (3 - 2.5)\u00b2/2.5\n   = 0.2666\n\u03c7\u00b2/N = 0.2666/10 = 0.02666\n\u03c7\u00b2/N &lt; 0.05 \u2192 accept equivalence (no violation)\n</code></pre> <pre><code>I0: CTrace=A, HTrace=[X(5 times), X'(1 time), Y(4 times)]\nI1: CTrace=A, HTrace=[X(5 times), X'(1 time), Z(4 times)]\n</code></pre> <p>The distributions are clearly different (X vs Y). \u03c7\u00b2 test will reject equivalence \u2192 violation: <pre><code>obs\u2081(X) = 5, obs\u2081(X') = 1, obs\u2081(Y) = 4\nobs\u2082(X) = 5, obs\u2082(X') = 1, obs\u2082(Z) = 4\nexpected(X) = (5 + 5) / 2 = 5\nexpected(X') = (1 + 1) / 2 = 1\nexpected(Y) = (4 + 0) / 2 = 2\nexpected(Z) = (0 + 4) / 2 = 2\n\u03c7\u00b2 = (5 - 5)\u00b2/5 + (1 - 1)\u00b2/1 + (4 - 2)\u00b2/2 + (0 - 2)\u00b2/2\n   + (5 - 5)\u00b2/5 + (1 - 1)\u00b2/1 + (0 - 2)\u00b2/2 + (4 - 2)\u00b2/2\n   = 8\n\u03c7\u00b2/N = 8/10 = 0.8\n\u03c7\u00b2/N &gt; 0.05 \u2192 reject equivalence (violation)\n</code></pre></p>"},{"location":"topics/trace-analysis/#adaptive-sample-sizing","title":"Adaptive Sample Sizing","text":"<p>For performance reasons, Revizor does not immediately use a large sample size. Instead, it starts with a small sample, collects the traces, and checks if a violation is detected. If no violation is detected, the executor assumes that the test case is safe, and moves on to the next one. If a violation is detected, however, the executor tries to reproduce it with larger sample sizes.</p> <p>Example adaptive strategy:</p> <pre><code>for N in [15, 40, 160, 320]:\n    collect N samples per input\n    if violation detected:\n        continue\n    else:\n        return \"no violation\"\nreturn \"violation detected\"\n</code></pre> <p>The exact sample sizes and thresholds are configurable via <code>executor_sample_sizes</code> config parameter.</p>"},{"location":"topics/trace-analysis/#whats-next","title":"What's Next?","text":"<ul> <li>Configuration Options - Configure analyzer parameters</li> <li>Model-Based Relational Testing - Theoretical foundations</li> <li>Analyser Architecture - Implementation   details</li> </ul>"}]}